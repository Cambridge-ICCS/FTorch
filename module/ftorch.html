<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>ftorch &ndash; FTorch</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha256-tG5mcZUtJsZvyKAxYLVXrmjKBVLd6VpVccqz/r4ypFE=" crossorigin="anonymous"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="../page/index.html">Other documentation</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>ftorch
      <small>Module</small>
      
    </h1>
      <div class="container p-2 mb-4 bg-light border rounded-3">
    <div class="row align-items-center justify-content-between" id="info-bar">
      <div class="col">
        <ul class="list-inline" style="margin-bottom:0px;display:inline">
            <li class="list-inline-item" id="meta-license"><i class="fa fa-legal"></i> <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a></li>

            <li class="list-inline-item" id="statements"><i class="fa fa-list-ol"></i>
              <a data-bs-toggle="tooltip"
                 data-bs-placement="bottom" data-html="true"
                 title="100.0% of total for modules and submodules.">216 statements</a>
            </li>

            <li class="list-inline-item" id="source-file">
              <i class="fa fa-code"></i>
              <a href="../src/ftorch.f90"> Source File</a>
            </li>
        </ul>
      </div>
      <div class="col">
        <nav aria-label="breadcrumb">
          <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='../sourcefile/ftorch.f90.html'>ftorch.f90</a></li>
            <li class="breadcrumb-item active" aria-current="page">ftorch</li>
          </ol>
        </nav>
      </div>
    </div>
  </div>
  <script>
    $(function () {
    $('[data-bs-toggle="tooltip"]').tooltip()
    })
  </script>

  </div>

  <div class="row">
    <div class="col-md-3">
        <div id="sidebar">
      <h3>Contents</h3>
  
  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#enums-0"
         aria-expanded="false" aria-controls="enums-0">
         <h4 class="card-header bg-primary text-white">Enumerations</h4>
      </a>
      <div id="enums-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/ftorch.html#enum-__unnamed__"><em>unnamed</em></a>
            <a class="list-group-item" href="../module/ftorch.html#enum-__unnamed__~2"><em>unnamed</em></a>
        </div>
      </div>
    </div>

  
  
  
  
  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#inters-0"
         aria-expanded="false" aria-controls="inters-0">
         <h4 class="card-header bg-primary text-white">Interfaces</h4>
      </a>
      <div id="inters-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/ftorch.html#interface-torch_tensor_from_array">torch_tensor_from_array</a>
        </div>
      </div>
    </div>

  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#types-0"
         aria-expanded="false" aria-controls="types-0">
         <h4 class="card-header bg-primary text-white">Derived Types</h4>
      </a>
      <div id="types-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/ftorch.html#type-torch_module">torch_module</a>
            <a class="list-group-item" href="../module/ftorch.html#type-torch_tensor">torch_tensor</a>
        </div>
      </div>
    </div>

      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#funcs-0"
         aria-expanded="false" aria-controls="funcs-0">
         <h4 class="card-header bg-primary text-white">Functions</h4>
      </a>
      <div id="funcs-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/ftorch.html#proc-t_t_from_array">t_t_from_array</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_module_load">torch_module_load</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_from_array_c_double">torch_tensor_from_array_c_double</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_from_array_c_float">torch_tensor_from_array_c_float</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_from_blob">torch_tensor_from_blob</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_ones">torch_tensor_ones</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_zeros">torch_tensor_zeros</a>
        </div>
      </div>
    </div>

      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#subs-0"
         aria-expanded="false" aria-controls="subs-0">
         <h4 class="card-header bg-primary text-white">Subroutines</h4>
      </a>
      <div id="subs-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_module_delete">torch_module_delete</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_module_forward">torch_module_forward</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_delete">torch_tensor_delete</a>
            <a class="list-group-item" href="../module/ftorch.html#proc-torch_tensor_print">torch_tensor_print</a>
        </div>
      </div>
    </div>

  
  
  
  
  
  
  


  </div>

    </div>

    <div class="col-md-9" id='text'>
      <p>The ftorch module containing wrappers to access libtorch</p>
<br>          <div class="card mb-4">
      <h3 class="card-header card-title bg-light">Uses</h3>
      <div class="card-body">
        <ul class="list-group list-group-flush">
            <li class="list-group-item">
              <ul class="list-inline">
                  <li class="list-inline-item"><a href='http://fortranwiki.org/fortran/show/iso_c_binding'>iso_c_binding</a></li>
              </ul>
            </li>
        </ul>
      </div>
    </div>

      
      <br>



        <section>
          <h2>Enumerations</h2>
              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="enum-__unnamed__"></span><h3>enum, bind(c)</h3></div>
    <div class="card-body">
      <h4>Enumerators</h4>
      <table class="table table-striped varlist">
        <tbody>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kUInt8</strong></td><td> = </td><td>0</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kInt8</strong></td><td> = </td><td>1</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kInt16</strong></td><td> = </td><td>2</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kInt32</strong></td><td> = </td><td>3</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kInt64</strong></td><td> = </td><td>4</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kFloat16</strong></td><td> = </td><td>5</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kFloat32</strong></td><td> = </td><td>6</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kFloat64</strong></td><td> = </td><td>7</td><td></td>
            </tr>
        </tbody>
      </table>
    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="enum-__unnamed__~2"></span><h3>enum, bind(c)</h3></div>
    <div class="card-body">
      <h4>Enumerators</h4>
      <table class="table table-striped varlist">
        <tbody>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kCPU</strong></td><td> = </td><td>0</td><td></td>
            </tr>
            <tr>
              <td>enumerator</td><td>::</td>
              <td><strong>torch_kCUDA</strong></td><td> = </td><td>1</td><td></td>
            </tr>
        </tbody>
      </table>
    </div>
  </div>

        </section>
        <br>

        <section>
          <h2>Interfaces</h2>
              <div class="card">
    <div class="card-header bg-light codesum">
      <span class="anchor" id="interface-torch_tensor_from_array"></span>
      <h3>public        interface <a href='../interface/torch_tensor_from_array.html'>torch_tensor_from_array</a> 
      </h3>
    </div>
    <ul class="list-group">
          <li class="list-group-item">
                <h3>
    public  function <a href='../proc/torch_tensor_from_array_c_float.html'>torch_tensor_from_array_c_float</a>(data_arr, tensor_shape, device) result(tensor)  

    </h3>
    
  

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data_arr~3"></span>
              real(kind=c_float),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_arr</strong>(*)</td>
            <td>
<p>Fortran array of data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~6"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(:)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~6"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

          </li>
          <li class="list-group-item">
                <h3>
    public  function <a href='../proc/torch_tensor_from_array_c_double.html'>torch_tensor_from_array_c_double</a>(data_arr, tensor_shape, device) result(tensor)  

    </h3>
    
  

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data_arr~2"></span>
              real(kind=c_double),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_arr</strong>(*)</td>
            <td>
<p>Fortran array of data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~5"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(:)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~5"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

          </li>
    </ul>
  </div>

        </section>
        <br>


        <section>
          <h2>Derived Types</h2>
              <div class="card">
    <div class="card-header codesum">
      <span class="anchor" id="type-torch_module"></span>
      <h3>
        type, public&nbsp;::&nbsp;
        <a href='../type/torch_module.html'>torch_module</a>
        
      </h3>
    </div>
    <div class="card-body">
      <p>Type for holding a torch neural net (nn.Module).</p>

        <h4>Components</h4>
          <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Visibility</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
<th></th><th scope="col">Initial</th>        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-p"></span>
              type(c_ptr),
            </td>
              <td>public</td>
            <td>
              
            </td>
            <td>::</td>
            <td><strong>p</strong></td>
<td> =</td>
                <td>c_null_ptr</td>
            <td>
<p>pointer to the neural net module in memory</p>
            </td>
        </tr>
    </tbody>
  </table>




    </div>
  </div>

              <div class="card">
    <div class="card-header codesum">
      <span class="anchor" id="type-torch_tensor"></span>
      <h3>
        type, public&nbsp;::&nbsp;
        <a href='../type/torch_tensor.html'>torch_tensor</a>
        
      </h3>
    </div>
    <div class="card-body">
      <p>Type for holding a torch tensor.</p>

        <h4>Components</h4>
          <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Visibility</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
<th></th><th scope="col">Initial</th>        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-p~2"></span>
              type(c_ptr),
            </td>
              <td>public</td>
            <td>
              
            </td>
            <td>::</td>
            <td><strong>p</strong></td>
<td> =</td>
                <td>c_null_ptr</td>
            <td>
<p>pointer to the tensor in memory</p>
            </td>
        </tr>
    </tbody>
  </table>




    </div>
  </div>

        </section>
        <br>

        <section>
          <h2>Functions</h2>
              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-t_t_from_array"></span><h3>public  function <a href='../proc/t_t_from_array.html'>t_t_from_array</a>(data_arr, tensor_shape, dtype, device) result(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>This routine will take an (i, j, k) array and return an (k, j, i) tensor
it is invoked from a set of interfaces <code>torch_tensor_from_array_dtype</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data_arr"></span>
              type(c_ptr),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>data_arr</strong></td>
            <td>
<p>Pointer to data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~2"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(:)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-dtype~2"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>dtype</strong></td>
            <td>
<p>Data type of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~2"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_module_load"></span><h3>public  function <a href='../proc/torch_module_load.html'>torch_module_load</a>(filename) result(module)  
</h3></div>
    <div class="card-body">
          
  <p>Loads a Torch Script module (pre-trained PyTorch model saved with Torch Script)</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-filename"></span>
              character(len=*),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>filename</strong></td>
            <td>
<p>Filename of Torch Script module</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_module.html'>torch_module</a>)</small>
    </h4>
    <p>Returned deserialized module</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_c_double"></span><h3>public  function <a href='../proc/torch_tensor_from_array_c_double.html'>torch_tensor_from_array_c_double</a>(data_arr, tensor_shape, device) result(tensor)  
</h3></div>
    <div class="card-body">
          
  

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data_arr~2"></span>
              real(kind=c_double),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_arr</strong>(*)</td>
            <td>
<p>Fortran array of data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~5"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(:)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~5"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_c_float"></span><h3>public  function <a href='../proc/torch_tensor_from_array_c_float.html'>torch_tensor_from_array_c_float</a>(data_arr, tensor_shape, device) result(tensor)  
</h3></div>
    <div class="card-body">
          
  

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data_arr~3"></span>
              real(kind=c_float),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_arr</strong>(*)</td>
            <td>
<p>Fortran array of data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~6"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(:)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~6"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_blob"></span><h3>public  function <a href='../proc/torch_tensor_from_blob.html'>torch_tensor_from_blob</a>(data, ndims, tensor_shape, dtype, device, layout) result(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Exposes the given data as a tensor without taking ownership of the original data.
This routine will take an (i, j, k) array and return an (k, j, i) tensor.</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-data"></span>
              type(c_ptr),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>data</strong></td>
            <td>
<p>Pointer to data</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-ndims"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>ndims</strong></td>
            <td>
<p>Number of dimensions of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(*)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-dtype"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>dtype</strong></td>
            <td>
<p>Data type of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(*)</td>
            <td>
<p>Layout for strides for accessing data</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_ones"></span><h3>public  function <a href='../proc/torch_tensor_ones.html'>torch_tensor_ones</a>(ndims, tensor_shape, dtype, device) result(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Returns a tensor filled with the scalar value 1.</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-ndims~3"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>ndims</strong></td>
            <td>
<p>Number of dimensions of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~3"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(*)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-dtype~3"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>dtype</strong></td>
            <td>
<p>Data type of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~3"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_zeros"></span><h3>public  function <a href='../proc/torch_tensor_zeros.html'>torch_tensor_zeros</a>(ndims, tensor_shape, dtype, device) result(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Returns a tensor filled with the scalar value 0.</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-ndims~4"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>ndims</strong></td>
            <td>
<p>Number of dimensions of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor_shape~4"></span>
              integer(kind=c_int64_t),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor_shape</strong>(*)</td>
            <td>
<p>Shape of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-dtype~4"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>dtype</strong></td>
            <td>
<p>Data type of the tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device~4"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device</strong></td>
            <td>
<p>Device on which the tensor will live on (torch_kCPU or torch_kGPU)</p>
            </td>
        </tr>
    </tbody>
  </table>

    <h4>
    Return Value
    <small>type(<a href='../type/torch_tensor.html'>torch_tensor</a>)</small>
    </h4>
    <p>Returned tensor</p>

    </div>
  </div>

        </section>
        <br>

        <section>
          <h2>Subroutines</h2>
              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_module_delete"></span><h3>public  subroutine <a href='../proc/torch_module_delete.html'>torch_module_delete</a>(module)  
</h3></div>
    <div class="card-body">
          
  <p>Deallocates a Torch Script module</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-module~3"></span>
              type(<a href='../type/torch_module.html'>torch_module</a>),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>module</strong></td>
            <td>
<p>Module</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_module_forward"></span><h3>public  subroutine <a href='../proc/torch_module_forward.html'>torch_module_forward</a>(module, input_tensors, n_inputs, output_tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Performs a forward pass of the module with the input tensors</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-module~2"></span>
              type(<a href='../type/torch_module.html'>torch_module</a>),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>module</strong></td>
            <td>
<p>Module</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-input_tensors"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              dimension(:)
            </td>
            <td>::</td>
            <td><strong>input_tensors</strong></td>
            <td>
<p>Array of Input tensors</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-n_inputs"></span>
              integer(kind=c_int)
            </td>
<td></td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>n_inputs</strong></td>
            <td>
<p>Number of tensors in <code>input_tensors</code></p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-output_tensor"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>output_tensor</strong></td>
            <td>
<p>Returned output tensors</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_delete"></span><h3>public  subroutine <a href='../proc/torch_tensor_delete.html'>torch_tensor_delete</a>(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Deallocates a tensor.</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~6"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Input tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

              <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_print"></span><h3>public  subroutine <a href='../proc/torch_tensor_print.html'>torch_tensor_print</a>(tensor)  
</h3></div>
    <div class="card-body">
          
  <p>Prints the contents of a tensor.</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~5"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Input tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

        </section>
        <br>



    </div>
  </div>

      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col"><p>FTorch was developed by ICCS Cambridge<br>&copy; 2023 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>