var tipuesearch = {"pages":[{"title":" FTorch ","text":"FTorch Brief description Presentations License Projects using FTorch Brief description It is desirable to be able to run machine learning (ML) models directly in Fortran.\nML models are often trained in some other language (say, Python) using a popular frameworks (say, PyTorch) and saved.\nWe want to run inference on this model without having to call a Python executable.\nTo achieve this we use the existing Torch C++ interface, libtorch. FTorch provides a library enabling a user to directly couple their PyTorch models to Fortran code.\nThere are also installation instructions for the library and examples of performing coupling. We support running on both CPU and GPU, and have tested the library on UNIX and Windows based operating systems Presentations The following presentations contain information about FTorch: Reducing the overheads for coupling PyTorch machine learning models to Fortran ML & DL Seminars, LSCE, IPSL, Paris - November 2023 Slides - Recording Reducing the Overhead of Coupled Machine Learning Models between Python and Fortran RSECon23, Swansea - September 2023 Slides - Recording License The FTorch source code, related files and documentation are\ndistributed under an MIT License which can be viewed here . Projects using FTorch The following projects make use of FTorch. If you use our library in your work please let us know. M2LInES CAM-ML -\n  Using FTorch to couple a neural net parameterisation of convection to the CAM\n  atmospheric model in CESM. DataWave CAM-GW -\n  Using FTorch to couple neural net parameterisations of gravity waves to the CAM\n  atmospheric model. MiMA Machine Learning -\n  Using FTorch to couple a neural net parameterisation of gravity waves to the MiMA\n  atmospheric model.\n  See Mansfield and Sheshadri (2024) - DOI: 10.1029/2024MS004292 Convection parameterisations in ICON -\n  Implementing machine learnt convection parameterisations in the ICON atmospheric model.\n  See Heuer et al (2023) - DOI: 10.48550/arXiv.2311.03251 Developer Info ICCS Cambridge","tags":"home","loc":"index.html"},{"title":"torch_model – FTorch ","text":"type, public :: torch_model Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net in memory Source Code type torch_model type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net in memory end type torch_model","tags":"","loc":"type/torch_model.html"},{"title":"torch_tensor – FTorch ","text":"type, public :: torch_tensor Type for holding a Torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Type-Bound Procedures procedure, public :: get_rank public  function get_rank (self) result(rank) Determines the rank of a tensor. Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=int32) rank of tensor procedure, public :: get_shape public  function get_shape (self) result(sizes) Determines the shape of a tensor. Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=c_long_long), pointer, (:) Pointer to tensor data Source Code type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory contains procedure :: get_rank procedure :: get_shape end type torch_tensor","tags":"","loc":"type/torch_tensor.html"},{"title":"assert_allclose_real32_1d – FTorch","text":"public  function assert_allclose_real32_1d(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_allclose_real32_1d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ), dimension (:) :: got !! The array of values to be tested real ( kind = real32 ), intent ( in ), dimension (:) :: expect !! The array of expected values real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real32_1d","tags":"","loc":"proc/assert_allclose_real32_1d.html"},{"title":"assert_allclose_real32_2d – FTorch","text":"public  function assert_allclose_real32_2d(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_allclose_real32_2d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ), dimension (:,:) :: got !! The array of values to be tested real ( kind = real32 ), intent ( in ), dimension (:,:) :: expect !! The array of expected values real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real32_2d","tags":"","loc":"proc/assert_allclose_real32_2d.html"},{"title":"assert_allclose_real64_1d – FTorch","text":"public  function assert_allclose_real64_1d(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_allclose_real64_1d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ), dimension (:) :: got !! The array of values to be tested real ( kind = real64 ), intent ( in ), dimension (:) :: expect !! The array of expected values real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real64_1d","tags":"","loc":"proc/assert_allclose_real64_1d.html"},{"title":"assert_allclose_real64_2d – FTorch","text":"public  function assert_allclose_real64_2d(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_allclose_real64_2d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ), dimension (:,:) :: got !! The array of values to be tested real ( kind = real64 ), intent ( in ), dimension (:,:) :: expect !! The array of expected values real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real64_2d","tags":"","loc":"proc/assert_allclose_real64_2d.html"},{"title":"assert_isclose_real32 – FTorch","text":"public  function assert_isclose_real32(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in) :: got The value to be tested real(kind=real32), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_isclose_real32 ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ) :: got !! The value to be tested real ( kind = real32 ), intent ( in ) :: expect !! The expected value real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if test_pass = ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if end function assert_isclose_real32","tags":"","loc":"proc/assert_isclose_real32.html"},{"title":"assert_isclose_real64 – FTorch","text":"public  function assert_isclose_real64(got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in) :: got The value to be tested real(kind=real64), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Source Code function assert_isclose_real64 ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ) :: got !! The value to be tested real ( kind = real64 ), intent ( in ) :: expect !! The expected value real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if test_pass = ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if end function assert_isclose_real64","tags":"","loc":"proc/assert_isclose_real64.html"},{"title":"test_print – FTorch","text":"public  subroutine test_print(test_name, message, test_pass) Print the result of a test to the terminal Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: test_name Name of the test being run character(len=*), intent(in) :: message Message to print logical, intent(in) :: test_pass Result of the assertion Source Code subroutine test_print ( test_name , message , test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run character ( len =* ), intent ( in ) :: message !! Message to print logical , intent ( in ) :: test_pass !! Result of the assertion character ( len = 15 ) :: report if ( test_pass ) then report = char ( 27 ) // '[32m' // 'PASSED' // char ( 27 ) // '[0m' else report = char ( 27 ) // '[31m' // 'FAILED' // char ( 27 ) // '[0m' end if write ( * , '(A, \" :: [\", A, \"] \", A)' ) report , trim ( test_name ), trim ( message ) end subroutine test_print","tags":"","loc":"proc/test_print.html"},{"title":"assert_allclose – FTorch","text":"public interface assert_allclose Module Procedures public  function assert_allclose_real32_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real32_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass?","tags":"","loc":"interface/assert_allclose.html"},{"title":"assert_isclose – FTorch","text":"public interface assert_isclose Module Procedures public  function assert_isclose_real32 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in) :: got The value to be tested real(kind=real32), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_isclose_real64 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in) :: got The value to be tested real(kind=real64), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass?","tags":"","loc":"interface/assert_isclose.html"},{"title":"get_rank – FTorch","text":"public  function get_rank(self) result(rank) Determines the rank of a tensor. Type Bound torch_tensor Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=int32) rank of tensor Source Code function get_rank ( self ) result ( rank ) class ( torch_tensor ), intent ( in ) :: self integer ( kind = int32 ) :: rank !! rank of tensor interface function torch_tensor_get_rank_c ( tensor ) result ( rank ) & bind ( c , name = 'torch_tensor_get_rank' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: rank end function torch_tensor_get_rank_c end interface rank = torch_tensor_get_rank_c ( self % p ) end function get_rank","tags":"","loc":"proc/get_rank.html"},{"title":"get_shape – FTorch","text":"public  function get_shape(self) result(sizes) Uses iso_c_binding Determines the shape of a tensor. Type Bound torch_tensor Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=c_long_long), pointer, (:) Pointer to tensor data Source Code function get_shape ( self ) result ( sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_long , c_long_long , c_ptr class ( torch_tensor ), intent ( in ) :: self #ifdef UNIX integer ( kind = c_long ), pointer :: sizes (:) !! Pointer to tensor data #else integer ( kind = c_long_long ), pointer :: sizes (:) !! Pointer to tensor data #endif integer ( kind = int32 ) :: ndims ( 1 ) type ( c_ptr ) :: cptr interface function torch_tensor_get_sizes_c ( tensor ) result ( sizes ) & bind ( c , name = 'torch_tensor_get_sizes' ) use , intrinsic :: iso_c_binding , only : c_int , c_long , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor type ( c_ptr ) :: sizes end function torch_tensor_get_sizes_c end interface ndims ( 1 ) = self % get_rank () cptr = torch_tensor_get_sizes_c ( self % p ) call c_f_pointer ( cptr , sizes , ndims ) end function get_shape","tags":"","loc":"proc/get_shape.html"},{"title":"torch_tensor_get_device_index – FTorch","text":"public  function torch_tensor_get_device_index(tensor) result(device_index) Uses iso_c_binding Determines the device index of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Return Value integer(kind=c_int) Device index of tensor Source Code function torch_tensor_get_device_index ( tensor ) result ( device_index ) use , intrinsic :: iso_c_binding , only : c_int type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor integer ( c_int ) :: device_index !! Device index of tensor interface function torch_tensor_get_device_index_c ( tensor ) result ( device_index ) & bind ( c , name = 'torch_tensor_get_device_index' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: device_index end function torch_tensor_get_device_index_c end interface device_index = torch_tensor_get_device_index_c ( tensor % p ) end function torch_tensor_get_device_index","tags":"","loc":"proc/torch_tensor_get_device_index.html"},{"title":"torch_model_delete – FTorch","text":"public  subroutine torch_model_delete(model) Deallocates a TorchScript model Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Torch Model to deallocate Source Code subroutine torch_model_delete ( model ) type ( torch_model ), intent ( in ) :: model !! Torch Model to deallocate interface subroutine torch_jit_model_delete_c ( model ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: model end subroutine torch_jit_model_delete_c end interface call torch_jit_model_delete_c ( model % p ) end subroutine torch_model_delete","tags":"","loc":"proc/torch_model_delete.html"},{"title":"torch_model_forward – FTorch","text":"public  subroutine torch_model_forward(model, input_tensors, output_tensors, requires_grad) Uses iso_c_binding Performs a forward pass of the model with the input tensors Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Model type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors type( torch_tensor ), intent(in), dimension(:) :: output_tensors Returned output tensors logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_model_forward ( model , input_tensors , output_tensors , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int , c_loc type ( torch_model ), intent ( in ) :: model !! Model type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ), dimension (:) :: output_tensors !! Returned output tensors logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor integer ( ftorch_int ) :: i integer ( c_int ) :: n_inputs integer ( c_int ) :: n_outputs type ( c_ptr ), dimension ( size ( input_tensors )), target :: input_ptrs type ( c_ptr ), dimension ( size ( output_tensors )), target :: output_ptrs interface subroutine torch_jit_model_forward_c ( model , input_tensors , n_inputs , & output_tensors , n_outputs , requires_grad ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int implicit none type ( c_ptr ), value , intent ( in ) :: model type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensors integer ( c_int ), value , intent ( in ) :: n_outputs logical ( c_bool ), value , intent ( in ) :: requires_grad end subroutine torch_jit_model_forward_c end interface n_inputs = size ( input_tensors ) n_outputs = size ( output_tensors ) if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do ! Assign array of pointers to the output tensors do i = 1 , n_outputs output_ptrs ( i ) = output_tensors ( i )% p end do call torch_jit_model_forward_c ( model % p , c_loc ( input_ptrs ), n_inputs , & c_loc ( output_ptrs ), n_outputs , & logical ( requires_grad_value , c_bool )) end subroutine torch_model_forward","tags":"","loc":"proc/torch_model_forward.html"},{"title":"torch_model_load – FTorch","text":"public  subroutine torch_model_load(model, filename, device_type, device_index, requires_grad, is_training) Uses iso_c_binding Loads a TorchScript nn.module (pre-trained PyTorch model saved with TorchScript) Arguments Type Intent Optional Attributes Name type( torch_model ), intent(out) :: model Returned deserialized model character(len=*), intent(in) :: filename Filename of saved TorchScript model integer(kind=c_int), intent(in), optional :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor logical, intent(in), optional :: is_training Whether gradients need to be computed for the created tensor Source Code subroutine torch_model_load ( model , filename , device_type , device_index , & requires_grad , is_training ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_null_char type ( torch_model ), intent ( out ) :: model !! Returned deserialized model character ( * ), intent ( in ) :: filename !! Filename of saved TorchScript model integer ( c_int ), optional , intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor logical , optional , intent ( in ) :: is_training !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_type_value integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor logical :: is_training_value !! Whether the model is being trained, rather than evaluated interface function torch_jit_load_c ( filename , device_type , device_index , & requires_grad , is_training ) result ( model ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_bool , c_char , c_int , c_ptr implicit none character ( c_char ), intent ( in ) :: filename ( * ) integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad logical ( c_bool ), value , intent ( in ) :: is_training type ( c_ptr ) :: model end function torch_jit_load_c end interface ! Process optional arguments if ( present ( device_type )) then device_type_value = device_type else device_type_value = torch_kCPU endif if ( present ( device_index )) then device_index_value = device_index else if ( device_type_value == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if if (. not . present ( is_training )) then is_training_value = . false . else is_training_value = is_training end if ! Need to append c_null_char at end of filename model % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char , & device_type_value , device_index_value , & logical ( requires_grad_value , c_bool ), & logical ( is_training_value , c_bool )) end subroutine torch_model_load","tags":"","loc":"proc/torch_model_load.html"},{"title":"torch_tensor_array_delete – FTorch","text":"public  subroutine torch_tensor_array_delete(tensor_array) Deallocates an array of tensors. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout), dimension(:) :: tensor_array Source Code subroutine torch_tensor_array_delete ( tensor_array ) type ( torch_tensor ), dimension (:), intent ( inout ) :: tensor_array integer ( ftorch_int ) :: i ! use bounds rather than (1, N) because it's safer do i = lbound ( tensor_array , dim = 1 ), ubound ( tensor_array , dim = 1 ) call torch_tensor_delete ( tensor_array ( i )) end do end subroutine torch_tensor_array_delete","tags":"","loc":"proc/torch_tensor_array_delete.html"},{"title":"torch_tensor_delete – FTorch","text":"public  subroutine torch_tensor_delete(tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout) :: tensor Source Code subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( inout ) :: tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete","tags":"","loc":"proc/torch_tensor_delete.html"},{"title":"torch_tensor_from_array_int16_1d – FTorch","text":"public  subroutine torch_tensor_from_array_int16_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int16_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_1d","tags":"","loc":"proc/torch_tensor_from_array_int16_1d.html"},{"title":"torch_tensor_from_array_int16_2d – FTorch","text":"public  subroutine torch_tensor_from_array_int16_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int16_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_2d","tags":"","loc":"proc/torch_tensor_from_array_int16_2d.html"},{"title":"torch_tensor_from_array_int16_3d – FTorch","text":"public  subroutine torch_tensor_from_array_int16_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int16_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_3d","tags":"","loc":"proc/torch_tensor_from_array_int16_3d.html"},{"title":"torch_tensor_from_array_int16_4d – FTorch","text":"public  subroutine torch_tensor_from_array_int16_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int16_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_4d","tags":"","loc":"proc/torch_tensor_from_array_int16_4d.html"},{"title":"torch_tensor_from_array_int16_5d – FTorch","text":"public  subroutine torch_tensor_from_array_int16_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int16_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_5d","tags":"","loc":"proc/torch_tensor_from_array_int16_5d.html"},{"title":"torch_tensor_from_array_int32_1d – FTorch","text":"public  subroutine torch_tensor_from_array_int32_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int32_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_1d","tags":"","loc":"proc/torch_tensor_from_array_int32_1d.html"},{"title":"torch_tensor_from_array_int32_2d – FTorch","text":"public  subroutine torch_tensor_from_array_int32_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int32_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_2d","tags":"","loc":"proc/torch_tensor_from_array_int32_2d.html"},{"title":"torch_tensor_from_array_int32_3d – FTorch","text":"public  subroutine torch_tensor_from_array_int32_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int32_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_3d","tags":"","loc":"proc/torch_tensor_from_array_int32_3d.html"},{"title":"torch_tensor_from_array_int32_4d – FTorch","text":"public  subroutine torch_tensor_from_array_int32_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int32_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_4d","tags":"","loc":"proc/torch_tensor_from_array_int32_4d.html"},{"title":"torch_tensor_from_array_int32_5d – FTorch","text":"public  subroutine torch_tensor_from_array_int32_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int32_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_5d","tags":"","loc":"proc/torch_tensor_from_array_int32_5d.html"},{"title":"torch_tensor_from_array_int64_1d – FTorch","text":"public  subroutine torch_tensor_from_array_int64_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int64_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_1d","tags":"","loc":"proc/torch_tensor_from_array_int64_1d.html"},{"title":"torch_tensor_from_array_int64_2d – FTorch","text":"public  subroutine torch_tensor_from_array_int64_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int64_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_2d","tags":"","loc":"proc/torch_tensor_from_array_int64_2d.html"},{"title":"torch_tensor_from_array_int64_3d – FTorch","text":"public  subroutine torch_tensor_from_array_int64_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int64_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_3d","tags":"","loc":"proc/torch_tensor_from_array_int64_3d.html"},{"title":"torch_tensor_from_array_int64_4d – FTorch","text":"public  subroutine torch_tensor_from_array_int64_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int64_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_4d","tags":"","loc":"proc/torch_tensor_from_array_int64_4d.html"},{"title":"torch_tensor_from_array_int64_5d – FTorch","text":"public  subroutine torch_tensor_from_array_int64_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int64_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_5d","tags":"","loc":"proc/torch_tensor_from_array_int64_5d.html"},{"title":"torch_tensor_from_array_int8_1d – FTorch","text":"public  subroutine torch_tensor_from_array_int8_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int8_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_1d","tags":"","loc":"proc/torch_tensor_from_array_int8_1d.html"},{"title":"torch_tensor_from_array_int8_2d – FTorch","text":"public  subroutine torch_tensor_from_array_int8_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int8_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_2d","tags":"","loc":"proc/torch_tensor_from_array_int8_2d.html"},{"title":"torch_tensor_from_array_int8_3d – FTorch","text":"public  subroutine torch_tensor_from_array_int8_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int8_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_3d","tags":"","loc":"proc/torch_tensor_from_array_int8_3d.html"},{"title":"torch_tensor_from_array_int8_4d – FTorch","text":"public  subroutine torch_tensor_from_array_int8_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int8_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_4d","tags":"","loc":"proc/torch_tensor_from_array_int8_4d.html"},{"title":"torch_tensor_from_array_int8_5d – FTorch","text":"public  subroutine torch_tensor_from_array_int8_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_int8_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_5d","tags":"","loc":"proc/torch_tensor_from_array_int8_5d.html"},{"title":"torch_tensor_from_array_real32_1d – FTorch","text":"public  subroutine torch_tensor_from_array_real32_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real32_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_1d","tags":"","loc":"proc/torch_tensor_from_array_real32_1d.html"},{"title":"torch_tensor_from_array_real32_2d – FTorch","text":"public  subroutine torch_tensor_from_array_real32_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real32_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_2d","tags":"","loc":"proc/torch_tensor_from_array_real32_2d.html"},{"title":"torch_tensor_from_array_real32_3d – FTorch","text":"public  subroutine torch_tensor_from_array_real32_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real32_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_3d","tags":"","loc":"proc/torch_tensor_from_array_real32_3d.html"},{"title":"torch_tensor_from_array_real32_4d – FTorch","text":"public  subroutine torch_tensor_from_array_real32_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real32_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_4d","tags":"","loc":"proc/torch_tensor_from_array_real32_4d.html"},{"title":"torch_tensor_from_array_real32_5d – FTorch","text":"public  subroutine torch_tensor_from_array_real32_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real32_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_5d","tags":"","loc":"proc/torch_tensor_from_array_real32_5d.html"},{"title":"torch_tensor_from_array_real64_1d – FTorch","text":"public  subroutine torch_tensor_from_array_real64_1d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real64_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_1d","tags":"","loc":"proc/torch_tensor_from_array_real64_1d.html"},{"title":"torch_tensor_from_array_real64_2d – FTorch","text":"public  subroutine torch_tensor_from_array_real64_2d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real64_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_2d","tags":"","loc":"proc/torch_tensor_from_array_real64_2d.html"},{"title":"torch_tensor_from_array_real64_3d – FTorch","text":"public  subroutine torch_tensor_from_array_real64_3d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real64_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_3d","tags":"","loc":"proc/torch_tensor_from_array_real64_3d.html"},{"title":"torch_tensor_from_array_real64_4d – FTorch","text":"public  subroutine torch_tensor_from_array_real64_4d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real64_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_4d","tags":"","loc":"proc/torch_tensor_from_array_real64_4d.html"},{"title":"torch_tensor_from_array_real64_5d – FTorch","text":"public  subroutine torch_tensor_from_array_real64_5d(tensor, data_in, layout, c_device_type, device_index, requires_grad) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 5 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_array_real64_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_5d","tags":"","loc":"proc/torch_tensor_from_array_real64_5d.html"},{"title":"torch_tensor_from_blob – FTorch","text":"public  subroutine torch_tensor_from_blob(tensor, data, ndims, tensor_shape, layout, dtype, device_type, device_index, requires_grad) Uses iso_c_binding Exposes the given data as a tensor without taking ownership of the original data.\n This routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_from_blob ( tensor , data , ndims , tensor_shape , layout , dtype , & device_type , device_index , & requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , & device_type , device_index_value , & requires_grad_value ) end subroutine torch_tensor_from_blob","tags":"","loc":"proc/torch_tensor_from_blob.html"},{"title":"torch_tensor_ones – FTorch","text":"public  subroutine torch_tensor_ones(tensor, ndims, tensor_shape, dtype, device_type, device_index, requires_grad) Uses iso_c_binding Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_ones ( tensor , ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr implicit none integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_ones_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device_type , & device_index_value , requires_grad_value ) end subroutine torch_tensor_ones","tags":"","loc":"proc/torch_tensor_ones.html"},{"title":"torch_tensor_print – FTorch","text":"public  subroutine torch_tensor_print(tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Source Code subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print","tags":"","loc":"proc/torch_tensor_print.html"},{"title":"torch_tensor_to_array_int16_1d – FTorch","text":"public  subroutine torch_tensor_to_array_int16_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int16_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_1d","tags":"","loc":"proc/torch_tensor_to_array_int16_1d.html"},{"title":"torch_tensor_to_array_int16_2d – FTorch","text":"public  subroutine torch_tensor_to_array_int16_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int16_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_2d","tags":"","loc":"proc/torch_tensor_to_array_int16_2d.html"},{"title":"torch_tensor_to_array_int16_3d – FTorch","text":"public  subroutine torch_tensor_to_array_int16_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int16_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_3d","tags":"","loc":"proc/torch_tensor_to_array_int16_3d.html"},{"title":"torch_tensor_to_array_int16_4d – FTorch","text":"public  subroutine torch_tensor_to_array_int16_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int16_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_4d","tags":"","loc":"proc/torch_tensor_to_array_int16_4d.html"},{"title":"torch_tensor_to_array_int16_5d – FTorch","text":"public  subroutine torch_tensor_to_array_int16_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int16_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_5d","tags":"","loc":"proc/torch_tensor_to_array_int16_5d.html"},{"title":"torch_tensor_to_array_int32_1d – FTorch","text":"public  subroutine torch_tensor_to_array_int32_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int32_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_1d","tags":"","loc":"proc/torch_tensor_to_array_int32_1d.html"},{"title":"torch_tensor_to_array_int32_2d – FTorch","text":"public  subroutine torch_tensor_to_array_int32_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int32_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_2d","tags":"","loc":"proc/torch_tensor_to_array_int32_2d.html"},{"title":"torch_tensor_to_array_int32_3d – FTorch","text":"public  subroutine torch_tensor_to_array_int32_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int32_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_3d","tags":"","loc":"proc/torch_tensor_to_array_int32_3d.html"},{"title":"torch_tensor_to_array_int32_4d – FTorch","text":"public  subroutine torch_tensor_to_array_int32_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int32_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_4d","tags":"","loc":"proc/torch_tensor_to_array_int32_4d.html"},{"title":"torch_tensor_to_array_int32_5d – FTorch","text":"public  subroutine torch_tensor_to_array_int32_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int32_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_5d","tags":"","loc":"proc/torch_tensor_to_array_int32_5d.html"},{"title":"torch_tensor_to_array_int64_1d – FTorch","text":"public  subroutine torch_tensor_to_array_int64_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int64_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_1d","tags":"","loc":"proc/torch_tensor_to_array_int64_1d.html"},{"title":"torch_tensor_to_array_int64_2d – FTorch","text":"public  subroutine torch_tensor_to_array_int64_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int64_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_2d","tags":"","loc":"proc/torch_tensor_to_array_int64_2d.html"},{"title":"torch_tensor_to_array_int64_3d – FTorch","text":"public  subroutine torch_tensor_to_array_int64_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int64_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_3d","tags":"","loc":"proc/torch_tensor_to_array_int64_3d.html"},{"title":"torch_tensor_to_array_int64_4d – FTorch","text":"public  subroutine torch_tensor_to_array_int64_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int64_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_4d","tags":"","loc":"proc/torch_tensor_to_array_int64_4d.html"},{"title":"torch_tensor_to_array_int64_5d – FTorch","text":"public  subroutine torch_tensor_to_array_int64_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int64_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_5d","tags":"","loc":"proc/torch_tensor_to_array_int64_5d.html"},{"title":"torch_tensor_to_array_int8_1d – FTorch","text":"public  subroutine torch_tensor_to_array_int8_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int8_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_1d","tags":"","loc":"proc/torch_tensor_to_array_int8_1d.html"},{"title":"torch_tensor_to_array_int8_2d – FTorch","text":"public  subroutine torch_tensor_to_array_int8_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int8_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_2d","tags":"","loc":"proc/torch_tensor_to_array_int8_2d.html"},{"title":"torch_tensor_to_array_int8_3d – FTorch","text":"public  subroutine torch_tensor_to_array_int8_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int8_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_3d","tags":"","loc":"proc/torch_tensor_to_array_int8_3d.html"},{"title":"torch_tensor_to_array_int8_4d – FTorch","text":"public  subroutine torch_tensor_to_array_int8_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int8_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_4d","tags":"","loc":"proc/torch_tensor_to_array_int8_4d.html"},{"title":"torch_tensor_to_array_int8_5d – FTorch","text":"public  subroutine torch_tensor_to_array_int8_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_int8_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_5d","tags":"","loc":"proc/torch_tensor_to_array_int8_5d.html"},{"title":"torch_tensor_to_array_real32_1d – FTorch","text":"public  subroutine torch_tensor_to_array_real32_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real32_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_1d","tags":"","loc":"proc/torch_tensor_to_array_real32_1d.html"},{"title":"torch_tensor_to_array_real32_2d – FTorch","text":"public  subroutine torch_tensor_to_array_real32_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real32_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_2d","tags":"","loc":"proc/torch_tensor_to_array_real32_2d.html"},{"title":"torch_tensor_to_array_real32_3d – FTorch","text":"public  subroutine torch_tensor_to_array_real32_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real32_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_3d","tags":"","loc":"proc/torch_tensor_to_array_real32_3d.html"},{"title":"torch_tensor_to_array_real32_4d – FTorch","text":"public  subroutine torch_tensor_to_array_real32_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real32_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_4d","tags":"","loc":"proc/torch_tensor_to_array_real32_4d.html"},{"title":"torch_tensor_to_array_real32_5d – FTorch","text":"public  subroutine torch_tensor_to_array_real32_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real32_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_5d","tags":"","loc":"proc/torch_tensor_to_array_real32_5d.html"},{"title":"torch_tensor_to_array_real64_1d – FTorch","text":"public  subroutine torch_tensor_to_array_real64_1d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 1 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real64_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_1d","tags":"","loc":"proc/torch_tensor_to_array_real64_1d.html"},{"title":"torch_tensor_to_array_real64_2d – FTorch","text":"public  subroutine torch_tensor_to_array_real64_2d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 2 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real64_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_2d","tags":"","loc":"proc/torch_tensor_to_array_real64_2d.html"},{"title":"torch_tensor_to_array_real64_3d – FTorch","text":"public  subroutine torch_tensor_to_array_real64_3d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 3 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real64_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_3d","tags":"","loc":"proc/torch_tensor_to_array_real64_3d.html"},{"title":"torch_tensor_to_array_real64_4d – FTorch","text":"public  subroutine torch_tensor_to_array_real64_4d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 4 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real64_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_4d","tags":"","loc":"proc/torch_tensor_to_array_real64_4d.html"},{"title":"torch_tensor_to_array_real64_5d – FTorch","text":"public  subroutine torch_tensor_to_array_real64_5d(tensor, data_out, sizes) Uses iso_fortran_env iso_c_binding Return the array data associated with a Torch tensor of rank 5 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank Source Code subroutine torch_tensor_to_array_real64_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_5d","tags":"","loc":"proc/torch_tensor_to_array_real64_5d.html"},{"title":"torch_tensor_zeros – FTorch","text":"public  subroutine torch_tensor_zeros(tensor, ndims, tensor_shape, dtype, device_type, device_index, requires_grad) Uses iso_c_binding Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor Source Code subroutine torch_tensor_zeros ( tensor , ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr implicit none integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_zeros_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device_type , & device_index_value , requires_grad_value ) end subroutine torch_tensor_zeros","tags":"","loc":"proc/torch_tensor_zeros.html"},{"title":"torch_delete – FTorch","text":"public interface torch_delete Interface for deleting generic torch objects Module Procedures public  subroutine torch_model_delete (model) Deallocates a TorchScript model Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Torch Model to deallocate public  subroutine torch_tensor_delete (tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout) :: tensor public  subroutine torch_tensor_array_delete (tensor_array) Deallocates an array of tensors. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout), dimension(:) :: tensor_array","tags":"","loc":"interface/torch_delete.html"},{"title":"torch_from_blob_c – FTorch","text":"interface public  function torch_from_blob_c(data, ndims, tensor_shape, strides, dtype, device_type, device_index, requires_grad) result(tensor_p) bind(c, name = 'torch_from_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: data integer(kind=c_int), intent(in), value :: ndims integer(kind=c_int64_t), intent(in) :: tensor_shape (*) integer(kind=c_int64_t), intent(in) :: strides (*) integer(kind=c_int), intent(in), value :: dtype integer(kind=c_int), intent(in), value :: device_type integer(kind=c_int), intent(in), value :: device_index logical(kind=c_bool), intent(in), value :: requires_grad Return Value type(c_ptr)","tags":"","loc":"interface/torch_from_blob_c.html"},{"title":"torch_tensor_from_array – FTorch","text":"public interface torch_tensor_from_array Interface for directing torch_tensor_from_array to possible input types and ranks Module Procedures public  subroutine torch_tensor_from_array_int8_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor","tags":"","loc":"interface/torch_tensor_from_array.html"},{"title":"torch_tensor_to_array – FTorch","text":"public interface torch_tensor_to_array Interface for directing torch_tensor_to_array to possible input types and ranks Module Procedures public  subroutine torch_tensor_to_array_int8_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank","tags":"","loc":"interface/torch_tensor_to_array.html"},{"title":"torch_to_blob_c – FTorch","text":"interface public  function torch_to_blob_c(tensor, dtype) result(data) bind(c, name = 'torch_to_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: tensor integer(kind=c_int), intent(in), value :: dtype Return Value type(c_ptr)","tags":"","loc":"interface/torch_to_blob_c.html"},{"title":"ftorch_test_utils – FTorch","text":"Utils module for FTorch containing assertions for testing License\n   FTorch is released under an MIT license.\n   See the LICENSE file for details. Uses iso_fortran_env Interfaces public        interface assert_allclose public  function assert_allclose_real32_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real32_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public        interface assert_isclose public  function assert_isclose_real32 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in) :: got The value to be tested real(kind=real32), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_isclose_real64 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in) :: got The value to be tested real(kind=real64), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Functions public  function assert_allclose_real32_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real32_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real32), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_1d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 1D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_allclose_real64_2d (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64-valued 2D arrays coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), dimension(:,:) :: got The array of values to be tested real(kind=real64), intent(in), dimension(:,:) :: expect The array of expected values character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_isclose_real32 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real32 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in) :: got The value to be tested real(kind=real32), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real32), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? public  function assert_isclose_real64 (got, expect, test_name, rtol, print_result) result(test_pass) Asserts that two real64 values coincide to a given relative tolerance Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in) :: got The value to be tested real(kind=real64), intent(in) :: expect The expected value character(len=*), intent(in) :: test_name Name of the test being run real(kind=real64), intent(in), optional :: rtol Optional relative tolerance (defaults to 1e-5) logical, intent(in), optional :: print_result Optionally print test result to screen (defaults to .true.) Return Value logical Did the assertion pass? Subroutines public  subroutine test_print (test_name, message, test_pass) Print the result of a test to the terminal Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: test_name Name of the test being run character(len=*), intent(in) :: message Message to print logical, intent(in) :: test_pass Result of the assertion","tags":"","loc":"module/ftorch_test_utils.html"},{"title":"ftorch – FTorch","text":"Main module for FTorch containing types and procedures.\n Generated from ftorch.fypp using the fypp Fortran preprocessor . License\n   FTorch is released under an MIT license.\n   See the LICENSE file for details. Uses iso_fortran_env iso_c_binding Variables Type Visibility Attributes Name Initial integer, public, parameter :: ftorch_int = int32 Enumerations enum, bind(c) Enumerators enumerator :: torch_kUInt8 = 0 enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 Description Enumerator for Torch data types\n From c_torch.h (torch_data_t)\n Note that 0 torch_kUInt8 and 5 torch_kFloat16 are not sypported in Fortran enum, bind(c) Enumerators enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 Description Enumerator for Torch devices\n From c_torch.h (torch_device_t) Interfaces public        interface torch_delete Interface for deleting generic torch objects public  subroutine torch_model_delete (model) Deallocates a TorchScript model Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Torch Model to deallocate public  subroutine torch_tensor_delete (tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout) :: tensor public  subroutine torch_tensor_array_delete (tensor_array) Deallocates an array of tensors. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout), dimension(:) :: tensor_array interface public  function torch_from_blob_c(data, ndims, tensor_shape, strides, dtype, device_type, device_index, requires_grad) result(tensor_p) bind(c, name = 'torch_from_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: data integer(kind=c_int), intent(in), value :: ndims integer(kind=c_int64_t), intent(in) :: tensor_shape (*) integer(kind=c_int64_t), intent(in) :: strides (*) integer(kind=c_int), intent(in), value :: dtype integer(kind=c_int), intent(in), value :: device_type integer(kind=c_int), intent(in), value :: device_index logical(kind=c_bool), intent(in), value :: requires_grad Return Value type(c_ptr) public        interface torch_tensor_from_array Interface for directing torch_tensor_from_array to possible input types and ranks public  subroutine torch_tensor_from_array_int8_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public        interface torch_tensor_to_array Interface for directing torch_tensor_to_array to possible input types and ranks public  subroutine torch_tensor_to_array_int8_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank interface public  function torch_to_blob_c(tensor, dtype) result(data) bind(c, name = 'torch_to_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: tensor integer(kind=c_int), intent(in), value :: dtype Return Value type(c_ptr) Derived Types type, public :: torch_model Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net in memory type, public :: torch_tensor Type for holding a Torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Type-Bound Procedures procedure, public :: get_rank procedure, public :: get_shape Functions public  function get_rank (self) result(rank) Determines the rank of a tensor. Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=int32) rank of tensor public  function get_shape (self) result(sizes) Determines the shape of a tensor. Arguments Type Intent Optional Attributes Name class( torch_tensor ), intent(in) :: self Return Value integer(kind=c_long_long), pointer, (:) Pointer to tensor data public  function torch_tensor_get_device_index (tensor) result(device_index) Determines the device index of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Return Value integer(kind=c_int) Device index of tensor Subroutines public  subroutine torch_model_delete (model) Deallocates a TorchScript model Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Torch Model to deallocate public  subroutine torch_model_forward (model, input_tensors, output_tensors, requires_grad) Performs a forward pass of the model with the input tensors Arguments Type Intent Optional Attributes Name type( torch_model ), intent(in) :: model Model type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors type( torch_tensor ), intent(in), dimension(:) :: output_tensors Returned output tensors logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_model_load (model, filename, device_type, device_index, requires_grad, is_training) Loads a TorchScript nn.module (pre-trained PyTorch model saved with TorchScript) Arguments Type Intent Optional Attributes Name type( torch_model ), intent(out) :: model Returned deserialized model character(len=*), intent(in) :: filename Filename of saved TorchScript model integer(kind=c_int), intent(in), optional :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor logical, intent(in), optional :: is_training Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_array_delete (tensor_array) Deallocates an array of tensors. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout), dimension(:) :: tensor_array public  subroutine torch_tensor_delete (tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(inout) :: tensor public  subroutine torch_tensor_from_array_int16_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int16_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int16), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_int8_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=int8), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real32_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real32), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_1d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_2d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_3d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_4d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_array_real64_5d (tensor, data_in, layout, c_device_type, device_index, requires_grad) Return a Torch tensor pointing to data_in array of rank 5 containing data of type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor real(kind=real64), intent(in), target :: data_in (:,:,:,:,:) Input data that tensor will point at integer(kind=ftorch_int), intent(in) :: layout (5) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_from_blob (tensor, data, ndims, tensor_shape, layout, dtype, device_type, device_index, requires_grad) Exposes the given data as a tensor without taking ownership of the original data.\n This routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_ones (tensor, ndims, tensor_shape, dtype, device_type, device_index, requires_grad) Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_print (tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor public  subroutine torch_tensor_to_array_int16_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int16_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int16 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int16), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_int8_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type int8 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor integer(kind=int8), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real32_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real32 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real32), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_1d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 1 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:) Pointer to tensor data integer, intent(in), optional :: sizes (1) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_2d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 2 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:) Pointer to tensor data integer, intent(in), optional :: sizes (2) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_3d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 3 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (3) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_4d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 4 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (4) Number of entries for each rank public  subroutine torch_tensor_to_array_real64_5d (tensor, data_out, sizes) Return the array data associated with a Torch tensor of rank 5 and data type real64 Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Returned tensor real(kind=real64), intent(out), pointer :: data_out (:,:,:,:,:) Pointer to tensor data integer, intent(in), optional :: sizes (5) Number of entries for each rank public  subroutine torch_tensor_zeros (tensor, ndims, tensor_shape, dtype, device_type, device_index, requires_grad) Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(out) :: tensor Returned tensor integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad Whether gradients need to be computed for the created tensor","tags":"","loc":"module/ftorch.html"},{"title":"ftorch_test_utils.f90 – FTorch","text":"Source Code !| Utils module for FTorch containing assertions for testing ! !  * License !    FTorch is released under an MIT license. !    See the [LICENSE](https://github.com/Cambridge-ICCS/FTorch/blob/main/LICENSE) !    file for details. module ftorch_test_utils use , intrinsic :: iso_fortran_env , only : real32 , real64 implicit none interface assert_isclose module procedure assert_isclose_real32 module procedure assert_isclose_real64 end interface interface assert_allclose module procedure assert_allclose_real32_1d module procedure assert_allclose_real32_2d module procedure assert_allclose_real64_1d module procedure assert_allclose_real64_2d end interface contains !> Print the result of a test to the terminal subroutine test_print ( test_name , message , test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run character ( len =* ), intent ( in ) :: message !! Message to print logical , intent ( in ) :: test_pass !! Result of the assertion character ( len = 15 ) :: report if ( test_pass ) then report = char ( 27 ) // '[32m' // 'PASSED' // char ( 27 ) // '[0m' else report = char ( 27 ) // '[31m' // 'FAILED' // char ( 27 ) // '[0m' end if write ( * , '(A, \" :: [\", A, \"] \", A)' ) report , trim ( test_name ), trim ( message ) end subroutine test_print !> Asserts that two real32 values coincide to a given relative tolerance function assert_isclose_real32 ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ) :: got !! The value to be tested real ( kind = real32 ), intent ( in ) :: expect !! The expected value real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if test_pass = ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if end function assert_isclose_real32 !> Asserts that two real64 values coincide to a given relative tolerance function assert_isclose_real64 ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ) :: got !! The value to be tested real ( kind = real64 ), intent ( in ) :: expect !! The expected value real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if test_pass = ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if end function assert_isclose_real64 !> Asserts that two real32-valued 1D arrays coincide to a given relative tolerance function assert_allclose_real32_1d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ), dimension (:) :: got !! The array of values to be tested real ( kind = real32 ), intent ( in ), dimension (:) :: expect !! The array of expected values real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real32_1d !> Asserts that two real32-valued 2D arrays coincide to a given relative tolerance function assert_allclose_real32_2d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real32 ), intent ( in ), dimension (:,:) :: got !! The array of values to be tested real ( kind = real32 ), intent ( in ), dimension (:,:) :: expect !! The array of expected values real ( kind = real32 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real32 ) :: relative_error real ( kind = real32 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real32_2d !> Asserts that two real64-valued 1D arrays coincide to a given relative tolerance function assert_allclose_real64_1d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ), dimension (:) :: got !! The array of values to be tested real ( kind = real64 ), intent ( in ), dimension (:) :: expect !! The array of expected values real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real64_1d !> Asserts that two real64-valued 2D arrays coincide to a given relative tolerance function assert_allclose_real64_2d ( got , expect , test_name , rtol , print_result ) result ( test_pass ) character ( len =* ), intent ( in ) :: test_name !! Name of the test being run real ( kind = real64 ), intent ( in ), dimension (:,:) :: got !! The array of values to be tested real ( kind = real64 ), intent ( in ), dimension (:,:) :: expect !! The array of expected values real ( kind = real64 ), intent ( in ), optional :: rtol !! Optional relative tolerance (defaults to 1e-5) logical , intent ( in ), optional :: print_result !! Optionally print test result to screen (defaults to .true.) logical :: test_pass !! Did the assertion pass? character ( len = 80 ) :: message real ( kind = real64 ) :: relative_error real ( kind = real64 ) :: rtol_value integer :: shape_error logical :: print_result_value if (. not . present ( rtol )) then rtol_value = 1.0e-5 else rtol_value = rtol end if if (. not . present ( print_result )) then print_result_value = . true . else print_result_value = print_result end if ! Check the shapes of the arrays match shape_error = maxval ( abs ( shape ( got ) - shape ( expect ))) test_pass = ( shape_error == 0 ) if ( test_pass ) then test_pass = all ( abs ( got - expect ) <= rtol_value * abs ( expect )) if ( print_result_value ) then write ( message , '(\"relative tolerance = \", E11.4)' ) rtol_value call test_print ( test_name , message , test_pass ) end if else if ( print_result_value ) then call test_print ( test_name , \"Arrays have mismatching shapes.\" , test_pass ) endif end function assert_allclose_real64_2d end module ftorch_test_utils","tags":"","loc":"sourcefile/ftorch_test_utils.f90.html"},{"title":"ftorch.F90 – FTorch","text":"Source Code !| Main module for FTorch containing types and procedures. !  Generated from `ftorch.fypp` using the [fypp Fortran preprocessor](https://fypp.readthedocs.io/en/stable/index.html). ! !  * License !    FTorch is released under an MIT license. !    See the [LICENSE](https://github.com/Cambridge-ICCS/FTorch/blob/main/LICENSE) !    file for details. module ftorch use , intrinsic :: iso_c_binding , only : c_int , c_int8_t , c_int16_t , c_int32_t , c_int64_t , & c_float , c_double , c_char , c_ptr , c_null_ptr , c_f_pointer use , intrinsic :: iso_fortran_env , only : int8 , int16 , int32 , int64 , real32 , real64 implicit none integer , parameter :: ftorch_int = int32 ! set integer size for FTorch library !> Type for holding a torch neural net (nn.Module). type torch_model type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net in memory end type torch_model !> Type for holding a Torch tensor. type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory contains procedure :: get_rank procedure :: get_shape end type torch_tensor !| Enumerator for Torch data types !  From c_torch.h (torch_data_t) !  Note that 0 `torch_kUInt8` and 5 `torch_kFloat16` are not sypported in Fortran enum , bind ( c ) enumerator :: torch_kUInt8 = 0 ! not supported in Fortran enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 ! not supported in Fortran enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 end enum !| Enumerator for Torch devices !  From c_torch.h (torch_device_t) enum , bind ( c ) enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 end enum !> Interface for directing `torch_tensor_from_array` to possible input types and ranks interface torch_tensor_from_array module procedure torch_tensor_from_array_int8_1d module procedure torch_tensor_from_array_int8_2d module procedure torch_tensor_from_array_int8_3d module procedure torch_tensor_from_array_int8_4d module procedure torch_tensor_from_array_int8_5d module procedure torch_tensor_from_array_int16_1d module procedure torch_tensor_from_array_int16_2d module procedure torch_tensor_from_array_int16_3d module procedure torch_tensor_from_array_int16_4d module procedure torch_tensor_from_array_int16_5d module procedure torch_tensor_from_array_int32_1d module procedure torch_tensor_from_array_int32_2d module procedure torch_tensor_from_array_int32_3d module procedure torch_tensor_from_array_int32_4d module procedure torch_tensor_from_array_int32_5d module procedure torch_tensor_from_array_int64_1d module procedure torch_tensor_from_array_int64_2d module procedure torch_tensor_from_array_int64_3d module procedure torch_tensor_from_array_int64_4d module procedure torch_tensor_from_array_int64_5d module procedure torch_tensor_from_array_real32_1d module procedure torch_tensor_from_array_real32_2d module procedure torch_tensor_from_array_real32_3d module procedure torch_tensor_from_array_real32_4d module procedure torch_tensor_from_array_real32_5d module procedure torch_tensor_from_array_real64_1d module procedure torch_tensor_from_array_real64_2d module procedure torch_tensor_from_array_real64_3d module procedure torch_tensor_from_array_real64_4d module procedure torch_tensor_from_array_real64_5d end interface !> Interface for directing `torch_tensor_to_array` to possible input types and ranks interface torch_tensor_to_array module procedure torch_tensor_to_array_int8_1d module procedure torch_tensor_to_array_int8_2d module procedure torch_tensor_to_array_int8_3d module procedure torch_tensor_to_array_int8_4d module procedure torch_tensor_to_array_int8_5d module procedure torch_tensor_to_array_int16_1d module procedure torch_tensor_to_array_int16_2d module procedure torch_tensor_to_array_int16_3d module procedure torch_tensor_to_array_int16_4d module procedure torch_tensor_to_array_int16_5d module procedure torch_tensor_to_array_int32_1d module procedure torch_tensor_to_array_int32_2d module procedure torch_tensor_to_array_int32_3d module procedure torch_tensor_to_array_int32_4d module procedure torch_tensor_to_array_int32_5d module procedure torch_tensor_to_array_int64_1d module procedure torch_tensor_to_array_int64_2d module procedure torch_tensor_to_array_int64_3d module procedure torch_tensor_to_array_int64_4d module procedure torch_tensor_to_array_int64_5d module procedure torch_tensor_to_array_real32_1d module procedure torch_tensor_to_array_real32_2d module procedure torch_tensor_to_array_real32_3d module procedure torch_tensor_to_array_real32_4d module procedure torch_tensor_to_array_real32_5d module procedure torch_tensor_to_array_real64_1d module procedure torch_tensor_to_array_real64_2d module procedure torch_tensor_to_array_real64_3d module procedure torch_tensor_to_array_real64_4d module procedure torch_tensor_to_array_real64_5d end interface !> Interface for deleting generic torch objects interface torch_delete module procedure torch_model_delete module procedure torch_tensor_delete module procedure torch_tensor_array_delete end interface interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , & device_type , device_index , & requires_grad ) result ( tensor_p ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr implicit none ! Arguments type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor_p end function torch_from_blob_c end interface interface function torch_to_blob_c ( tensor , dtype ) result ( data ) & bind ( c , name = 'torch_to_blob' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ), value , intent ( in ) :: dtype type ( c_ptr ) :: data end function torch_to_blob_c end interface contains !> Returns a tensor filled with the scalar value 0. subroutine torch_tensor_zeros ( tensor , ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr implicit none integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_zeros_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device_type , & device_index_value , requires_grad_value ) end subroutine torch_tensor_zeros !> Returns a tensor filled with the scalar value 1. subroutine torch_tensor_ones ( tensor , ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , & device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr implicit none integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_ones_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device_type , & device_index_value , requires_grad_value ) end subroutine torch_tensor_ones ! Torch Tensor API !| Exposes the given data as a tensor without taking ownership of the original data. !  This routine will take an (i, j, k) array and return an (k, j, i) tensor. subroutine torch_tensor_from_blob ( tensor , data , ndims , tensor_shape , layout , dtype , & device_type , device_index , & requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad_value !! Whether gradients need to be computed for the created tensor if (. not . present ( requires_grad )) then requires_grad_value = logical (. false ., c_bool ) else requires_grad_value = requires_grad end if strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , & device_type , device_index_value , & requires_grad_value ) end subroutine torch_tensor_from_blob !> Prints the contents of a tensor. subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print !> Determines the device index of a tensor. function torch_tensor_get_device_index ( tensor ) result ( device_index ) use , intrinsic :: iso_c_binding , only : c_int type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor integer ( c_int ) :: device_index !! Device index of tensor interface function torch_tensor_get_device_index_c ( tensor ) result ( device_index ) & bind ( c , name = 'torch_tensor_get_device_index' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: device_index end function torch_tensor_get_device_index_c end interface device_index = torch_tensor_get_device_index_c ( tensor % p ) end function torch_tensor_get_device_index !> Determines the rank of a tensor. function get_rank ( self ) result ( rank ) class ( torch_tensor ), intent ( in ) :: self integer ( kind = int32 ) :: rank !! rank of tensor interface function torch_tensor_get_rank_c ( tensor ) result ( rank ) & bind ( c , name = 'torch_tensor_get_rank' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: rank end function torch_tensor_get_rank_c end interface rank = torch_tensor_get_rank_c ( self % p ) end function get_rank !> Determines the shape of a tensor. function get_shape ( self ) result ( sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_long , c_long_long , c_ptr class ( torch_tensor ), intent ( in ) :: self #ifdef UNIX integer ( kind = c_long ), pointer :: sizes (:) !! Pointer to tensor data #else integer ( kind = c_long_long ), pointer :: sizes (:) !! Pointer to tensor data #endif integer ( kind = int32 ) :: ndims ( 1 ) type ( c_ptr ) :: cptr interface function torch_tensor_get_sizes_c ( tensor ) result ( sizes ) & bind ( c , name = 'torch_tensor_get_sizes' ) use , intrinsic :: iso_c_binding , only : c_int , c_long , c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor type ( c_ptr ) :: sizes end function torch_tensor_get_sizes_c end interface ndims ( 1 ) = self % get_rank () cptr = torch_tensor_get_sizes_c ( self % p ) call c_f_pointer ( cptr , sizes , ndims ) end function get_shape !> Deallocates an array of tensors. subroutine torch_tensor_array_delete ( tensor_array ) type ( torch_tensor ), dimension (:), intent ( inout ) :: tensor_array integer ( ftorch_int ) :: i ! use bounds rather than (1, N) because it's safer do i = lbound ( tensor_array , dim = 1 ), ubound ( tensor_array , dim = 1 ) call torch_tensor_delete ( tensor_array ( i )) end do end subroutine torch_tensor_array_delete !> Deallocates a tensor. subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( inout ) :: tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete ! Torch Model API !> Loads a TorchScript nn.module (pre-trained PyTorch model saved with TorchScript) subroutine torch_model_load ( model , filename , device_type , device_index , & requires_grad , is_training ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_null_char type ( torch_model ), intent ( out ) :: model !! Returned deserialized model character ( * ), intent ( in ) :: filename !! Filename of saved TorchScript model integer ( c_int ), optional , intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor logical , optional , intent ( in ) :: is_training !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: device_type_value integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor logical :: is_training_value !! Whether the model is being trained, rather than evaluated interface function torch_jit_load_c ( filename , device_type , device_index , & requires_grad , is_training ) result ( model ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_bool , c_char , c_int , c_ptr implicit none character ( c_char ), intent ( in ) :: filename ( * ) integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad logical ( c_bool ), value , intent ( in ) :: is_training type ( c_ptr ) :: model end function torch_jit_load_c end interface ! Process optional arguments if ( present ( device_type )) then device_type_value = device_type else device_type_value = torch_kCPU endif if ( present ( device_index )) then device_index_value = device_index else if ( device_type_value == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if if (. not . present ( is_training )) then is_training_value = . false . else is_training_value = is_training end if ! Need to append c_null_char at end of filename model % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char , & device_type_value , device_index_value , & logical ( requires_grad_value , c_bool ), & logical ( is_training_value , c_bool )) end subroutine torch_model_load !> Performs a forward pass of the model with the input tensors subroutine torch_model_forward ( model , input_tensors , output_tensors , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int , c_loc type ( torch_model ), intent ( in ) :: model !! Model type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ), dimension (:) :: output_tensors !! Returned output tensors logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor integer ( ftorch_int ) :: i integer ( c_int ) :: n_inputs integer ( c_int ) :: n_outputs type ( c_ptr ), dimension ( size ( input_tensors )), target :: input_ptrs type ( c_ptr ), dimension ( size ( output_tensors )), target :: output_ptrs interface subroutine torch_jit_model_forward_c ( model , input_tensors , n_inputs , & output_tensors , n_outputs , requires_grad ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int implicit none type ( c_ptr ), value , intent ( in ) :: model type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensors integer ( c_int ), value , intent ( in ) :: n_outputs logical ( c_bool ), value , intent ( in ) :: requires_grad end subroutine torch_jit_model_forward_c end interface n_inputs = size ( input_tensors ) n_outputs = size ( output_tensors ) if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do ! Assign array of pointers to the output tensors do i = 1 , n_outputs output_ptrs ( i ) = output_tensors ( i )% p end do call torch_jit_model_forward_c ( model % p , c_loc ( input_ptrs ), n_inputs , & c_loc ( output_ptrs ), n_outputs , & logical ( requires_grad_value , c_bool )) end subroutine torch_model_forward !> Deallocates a TorchScript model subroutine torch_model_delete ( model ) type ( torch_model ), intent ( in ) :: model !! Torch Model to deallocate interface subroutine torch_jit_model_delete_c ( model ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr implicit none type ( c_ptr ), value , intent ( in ) :: model end subroutine torch_jit_model_delete_c end interface call torch_jit_model_delete_c ( model % p ) end subroutine torch_model_delete !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int8` subroutine torch_tensor_from_array_int8_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int8` subroutine torch_tensor_from_array_int8_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int8` subroutine torch_tensor_from_array_int8_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int8` subroutine torch_tensor_from_array_int8_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `int8` subroutine torch_tensor_from_array_int8_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int8_5d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int16` subroutine torch_tensor_from_array_int16_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int16` subroutine torch_tensor_from_array_int16_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int16` subroutine torch_tensor_from_array_int16_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int16` subroutine torch_tensor_from_array_int16_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `int16` subroutine torch_tensor_from_array_int16_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int16_5d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int32` subroutine torch_tensor_from_array_int32_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int32` subroutine torch_tensor_from_array_int32_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int32` subroutine torch_tensor_from_array_int32_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int32` subroutine torch_tensor_from_array_int32_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `int32` subroutine torch_tensor_from_array_int32_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int32_5d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int64` subroutine torch_tensor_from_array_int64_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int64` subroutine torch_tensor_from_array_int64_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int64` subroutine torch_tensor_from_array_int64_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int64` subroutine torch_tensor_from_array_int64_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `int64` subroutine torch_tensor_from_array_int64_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_int64_5d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `real32` subroutine torch_tensor_from_array_real32_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `real32` subroutine torch_tensor_from_array_real32_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `real32` subroutine torch_tensor_from_array_real32_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `real32` subroutine torch_tensor_from_array_real32_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `real32` subroutine torch_tensor_from_array_real32_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real32_5d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `real64` subroutine torch_tensor_from_array_real64_1d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `real64` subroutine torch_tensor_from_array_real64_2d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `real64` subroutine torch_tensor_from_array_real64_3d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `real64` subroutine torch_tensor_from_array_real64_4d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_4d !> Return a Torch tensor pointing to data_in array of rank 5 containing data of type `real64` subroutine torch_tensor_from_array_real64_5d ( tensor , data_in , layout , & c_device_type , device_index , requires_grad ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! output tensor type ( torch_tensor ), intent ( out ) :: tensor !! Returned tensor ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:,:) !! Input data that tensor will point at integer ( ftorch_int ), intent ( in ) :: layout ( 5 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad !! Whether gradients need to be computed for the created tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 5 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 5 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 5 !! Number of dimension of input data integer ( ftorch_int ) :: i integer ( c_int ) :: device_index_value logical :: requires_grad_value !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad )) then requires_grad_value = . false . else requires_grad_value = requires_grad end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad_value , c_bool )) end subroutine torch_tensor_from_array_real64_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `int8` subroutine torch_tensor_to_array_int8_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `int8` subroutine torch_tensor_to_array_int8_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `int8` subroutine torch_tensor_to_array_int8_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `int8` subroutine torch_tensor_to_array_int8_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `int8` subroutine torch_tensor_to_array_int8_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int8 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int8_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `int16` subroutine torch_tensor_to_array_int16_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `int16` subroutine torch_tensor_to_array_int16_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `int16` subroutine torch_tensor_to_array_int16_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `int16` subroutine torch_tensor_to_array_int16_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `int16` subroutine torch_tensor_to_array_int16_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int16 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int16_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `int32` subroutine torch_tensor_to_array_int32_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `int32` subroutine torch_tensor_to_array_int32_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `int32` subroutine torch_tensor_to_array_int32_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `int32` subroutine torch_tensor_to_array_int32_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `int32` subroutine torch_tensor_to_array_int32_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int32 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int32_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `int64` subroutine torch_tensor_to_array_int64_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `int64` subroutine torch_tensor_to_array_int64_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `int64` subroutine torch_tensor_to_array_int64_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `int64` subroutine torch_tensor_to_array_int64_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `int64` subroutine torch_tensor_to_array_int64_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor integer ( kind = int64 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_int64_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `real32` subroutine torch_tensor_to_array_real32_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `real32` subroutine torch_tensor_to_array_real32_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `real32` subroutine torch_tensor_to_array_real32_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `real32` subroutine torch_tensor_to_array_real32_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `real32` subroutine torch_tensor_to_array_real32_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real32 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real32_5d !> Return the array data associated with a Torch tensor of rank 1 and data type `real64` subroutine torch_tensor_to_array_real64_1d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 1 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 1(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 1(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_1d !> Return the array data associated with a Torch tensor of rank 2 and data type `real64` subroutine torch_tensor_to_array_real64_2d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 2 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 2(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 2(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_2d !> Return the array data associated with a Torch tensor of rank 3 and data type `real64` subroutine torch_tensor_to_array_real64_3d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 3 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 3(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 3(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_3d !> Return the array data associated with a Torch tensor of rank 4 and data type `real64` subroutine torch_tensor_to_array_real64_4d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 4 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 4(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 4(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_4d !> Return the array data associated with a Torch tensor of rank 5 and data type `real64` subroutine torch_tensor_to_array_real64_5d ( tensor , data_out , sizes ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 , int64 type ( torch_tensor ), intent ( in ) :: tensor !! Returned tensor real ( kind = real64 ), pointer , intent ( out ) :: data_out (:,:,:,:,:) !! Pointer to tensor data integer , optional , intent ( in ) :: sizes ( 5 ) !! Number of entries for each rank integer ( kind = int64 ), allocatable :: my_shape (:) !! Number of entries for each rank ! Local data integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type type ( c_ptr ) :: cptr my_shape = tensor % get_shape () if ( present ( sizes )) then if (. not . all ( my_shape == sizes )) then write ( * , * ) 'Error :: sizes argument does not match shape of tensor' write ( * , '(A, 5(I0, \" \"), A)' ) 'sizes        :: [ ' , sizes (:), ']' write ( * , '(A, 5(I0, \" \"), A)' ) 'tensor shape :: [ ' , my_shape (:), ']' stop 1 end if end if ! Have the data_out array point to the Tensor data cptr = torch_to_blob_c ( tensor % p , c_dtype ) call c_f_pointer ( cptr , data_out , my_shape ) end subroutine torch_tensor_to_array_real64_5d end module ftorch","tags":"","loc":"sourcefile/ftorch.f90.html"},{"title":"ctorch.cpp – FTorch","text":"Source Code #include <torch/script.h> #include <torch/torch.h> #include \"ctorch.h\" constexpr auto get_dtype ( torch_data_t dtype ) { switch ( dtype ) { case torch_kUInt8 : std :: cerr << \"[WARNING]: uint8 not supported in Fortran\" << std :: endl ; // See https://gcc.gnu.org/onlinedocs/gfortran/ISO_005fFORTRAN_005fENV.html exit ( EXIT_FAILURE ); case torch_kInt8 : return torch :: kInt8 ; case torch_kInt16 : return torch :: kInt16 ; case torch_kInt32 : return torch :: kInt32 ; case torch_kInt64 : return torch :: kInt64 ; case torch_kFloat16 : std :: cerr << \"[WARNING]: float16 not supported in Fortran\" << std :: endl ; // See https://gcc.gnu.org/onlinedocs/gfortran/ISO_005fFORTRAN_005fENV.html exit ( EXIT_FAILURE ); case torch_kFloat32 : return torch :: kFloat32 ; case torch_kFloat64 : return torch :: kFloat64 ; default : std :: cerr << \"[WARNING]: unknown data type, setting to torch_kFloat32\" << std :: endl ; return torch :: kFloat32 ; } } const auto get_device ( torch_device_t device_type , int device_index ) { switch ( device_type ) { case torch_kCPU : if ( device_index != -1 ) { std :: cerr << \"[WARNING]: device index unused for CPU-only runs\" << std :: endl ; } return torch :: Device ( torch :: kCPU ); case torch_kCUDA : if ( device_index == -1 ) { std :: cerr << \"[WARNING]: device index unset, defaulting to 0\" << std :: endl ; device_index = 0 ; } if ( device_index >= 0 && device_index < torch :: cuda :: device_count ()) { return torch :: Device ( torch :: kCUDA , device_index ); } else { std :: cerr << \"[ERROR]: invalid device index \" << device_index << \" for device count \" << torch :: cuda :: device_count () << std :: endl ; exit ( EXIT_FAILURE ); } default : std :: cerr << \"[WARNING]: unknown device type, setting to torch_kCPU\" << std :: endl ; return torch :: Device ( torch :: kCPU ); } } void set_is_training ( torch_jit_script_module_t module , const bool is_training = false ) { auto model = static_cast < torch :: jit :: script :: Module *> ( module ); if ( is_training ) { model -> train (); } else { model -> eval (); } } torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: zeros ( vshape , torch :: dtype ( get_dtype ( dtype ))) . to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: ones ( vshape , torch :: dtype ( get_dtype ( dtype ))) . to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: empty ( vshape , torch :: dtype ( get_dtype ( dtype ))) . to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } // Exposes the given data as a Tensor without taking ownership of the original // data torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); c10 :: IntArrayRef vstrides ( strides , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: from_blob ( data , vshape , vstrides , torch :: dtype ( get_dtype ( dtype ))) . to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } void * torch_to_blob ( const torch_tensor_t tensor , const torch_data_t dtype ) { auto t = reinterpret_cast < torch :: Tensor * const > ( tensor ); void * raw_ptr ; switch ( dtype ) { case torch_kUInt8 : std :: cerr << \"[WARNING]: uint8 not supported\" << std :: endl ; exit ( EXIT_FAILURE ); case torch_kInt8 : raw_ptr = ( void * ) t -> data_ptr < int8_t > (); break ; case torch_kInt16 : raw_ptr = ( void * ) t -> data_ptr < int16_t > (); break ; case torch_kInt32 : raw_ptr = ( void * ) t -> data_ptr < int32_t > (); break ; case torch_kInt64 : raw_ptr = ( void * ) t -> data_ptr < int64_t > (); break ; case torch_kFloat16 : std :: cerr << \"[WARNING]: float16 not supported\" << std :: endl ; // NOTE: std::float16_t is available but only with C++23 exit ( EXIT_FAILURE ); case torch_kFloat32 : raw_ptr = ( void * ) t -> data_ptr < float > (); // NOTE: std::float32_t is available but only with C++23 break ; case torch_kFloat64 : raw_ptr = ( void * ) t -> data_ptr < double > (); // NOTE: std::float64_t is available but only with C++23 break ; default : std :: cerr << \"[WARNING]: unknown data type\" << std :: endl ; exit ( EXIT_FAILURE ); } return raw_ptr ; } void torch_tensor_print ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); std :: cout << * t << std :: endl ; } int torch_tensor_get_device_index ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); return t -> device (). index (); } int torch_tensor_get_rank ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); return t -> sizes (). size (); } #ifdef UNIX const long int * torch_tensor_get_sizes ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); return t -> sizes (). data (); } #else const long long int * torch_tensor_get_sizes ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); return t -> sizes (). data (); } #endif void torch_tensor_delete ( torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); delete t ; } torch_jit_script_module_t torch_jit_load ( const char * filename , const torch_device_t device_type = torch_kCPU , const int device_index = -1 , const bool requires_grad = false , const bool is_training = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: jit :: script :: Module * module = nullptr ; try { module = new torch :: jit :: script :: Module ; * module = torch :: jit :: load ( filename , get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } set_is_training ( module , is_training ); return module ; } void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t * outputs , const int nout , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); // Here we cast the pointers we recieved in to Tensor objects auto model = static_cast < torch :: jit :: script :: Module *> ( module ); auto in = reinterpret_cast < torch :: Tensor * const *> ( inputs ); auto out = reinterpret_cast < torch :: Tensor **> ( outputs ); // Local IValue for checking we are passed types torch :: jit :: IValue LocalTensor ; // Generate a vector of IValues (placeholders for various Torch types) std :: vector < torch :: jit :: IValue > inputs_vec ; // Populate with Tensors pointed at by pointers // For each IValue check it is of Tensor type for ( int i = 0 ; i < nin ; ++ i ) { LocalTensor = * ( in [ i ]); if ( LocalTensor . isTensor ()) { inputs_vec . push_back ( LocalTensor ); } else { std :: cerr << \"[ERROR]: One of the inputs to torch_jit_module_forward is \" \"not a Tensor.\" << std :: endl ; exit ( EXIT_FAILURE ); } } try { auto model_out = model -> forward ( inputs_vec ); if ( model_out . isTensor ()) { // Single output models will return a tensor directly. std :: move ( * out [ 0 ]) = model_out . toTensor (); } else if ( model_out . isTuple ()) { // Multiple output models will return a tuple => cast to tensors. for ( int i = 0 ; i < nout ; ++ i ) { std :: move ( * out [ i ]) = model_out . toTuple () -> elements ()[ i ]. toTensor (); } } else { // If for some reason the forward method does not return a Tensor it // should raise an error when trying to cast to a Tensor type std :: cerr << \"[ERROR]: Model Output is neither Tensor nor Tuple.\" << std :: endl ; } } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; exit ( EXIT_FAILURE ); } } void torch_jit_module_delete ( torch_jit_script_module_t module ) { auto m = reinterpret_cast < torch :: jit :: script :: Module *> ( module ); delete m ; }","tags":"","loc":"sourcefile/ctorch.cpp.html"},{"title":"pt2ts.py – FTorch","text":"Source Code \"\"\"Load a PyTorch model and convert it to TorchScript.\"\"\" import os import sys from typing import Optional # FPTLIB-TODO # Add a module import with your model here: # This example assumes the model architecture is in an adjacent module `my_ml_model.py` import my_ml_model import torch def script_to_torchscript ( model : torch . nn . Module , filename : Optional [ str ] = \"scripted_model.pt\" ) -> None : \"\"\" Save PyTorch model to TorchScript using scripting. Parameters ---------- model : torch.NN.Module a PyTorch model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved scripted_model = torch . jit . script ( model ) # print(scripted_model.code) scripted_model . save ( filename ) def trace_to_torchscript ( model : torch . nn . Module , dummy_input : torch . Tensor , filename : Optional [ str ] = \"traced_model.pt\" , ) -> None : \"\"\" Save PyTorch model to TorchScript using tracing. Parameters ---------- model : torch.NN.Module a PyTorch model dummy_input : torch.Tensor appropriate size Tensor to act as input to model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved traced_model = torch . jit . trace ( model , dummy_input ) # traced_model.save(filename) frozen_model = torch . jit . freeze ( traced_model ) ## print(frozen_model.graph) ## print(frozen_model.code) frozen_model . save ( filename ) def load_torchscript ( filename : Optional [ str ] = \"saved_model.pt\" ) -> torch . nn . Module : \"\"\" Load a TorchScript from file. Parameters ---------- filename : str name of file containing TorchScript model \"\"\" model = torch . jit . load ( filename ) return model if __name__ == \"__main__\" : # ===================================================== # Load model and prepare for saving # ===================================================== # FPTLIB-TODO # Load a pre-trained PyTorch model # Insert code here to load your model as `trained_model`. # This example assumes my_ml_model has a method `initialize` to load # architecture, weights, and place in inference mode trained_model = my_ml_model . initialize () # Switch off specific layers/parts of the model that behave # differently during training and inference. # This may have been done by the user already, so just make sure here. trained_model . eval () # ===================================================== # Prepare dummy input and check model runs # ===================================================== # FPTLIB-TODO # Generate a dummy input Tensor `dummy_input` to the model of appropriate size. # This example assumes two inputs of size (512x40) and (512x1) trained_model_dummy_input_1 = torch . ones (( 512 , 40 ), dtype = torch . float64 ) trained_model_dummy_input_2 = torch . ones (( 512 , 1 ), dtype = torch . float64 ) # FPTLIB-TODO # Uncomment the following lines to save for inference on GPU (rather than CPU): # device = torch.device('cuda') # trained_model = trained_model.to(device) # trained_model.eval() # trained_model_dummy_input_1 = trained_model_dummy_input_1.to(device) # trained_model_dummy_input_2 = trained_model_dummy_input_2.to(device) # FPTLIB-TODO # Run model for dummy inputs # If something isn't working This will generate an error trained_model_dummy_outputs = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) # ===================================================== # Save model # ===================================================== # FPTLIB-TODO # Set the name of the file you want to save the torchscript model to: saved_ts_filename = \"saved_model.pt\" # A filepath may also be provided. To do this, pass the filepath as an argument to # this script when it is run from the command line, i.e. `./pt2ts.py path/to/model`. # FPTLIB-TODO # Save the PyTorch model using either scripting (recommended if possible) or tracing # ----------- # Scripting # ----------- script_to_torchscript ( trained_model , filename = saved_ts_filename ) # ----------- # Tracing # ----------- # trace_to_torchscript( #     trained_model, trained_model_dummy_input, filename=saved_ts_filename # ) # ===================================================== # Check model saved OK # ===================================================== # Load torchscript and run model as a test # FPTLIB-TODO # Scale inputs as above and, if required, move inputs and mode to GPU trained_model_dummy_input_1 = 2.0 * trained_model_dummy_input_1 trained_model_dummy_input_2 = 2.0 * trained_model_dummy_input_2 trained_model_testing_outputs = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) ts_model = load_torchscript ( filename = saved_ts_filename ) ts_model_outputs = ts_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) if not isinstance ( ts_model_outputs , tuple ): ts_model_outputs = ( ts_model_outputs ,) if not isinstance ( trained_model_testing_outputs , tuple ): trained_model_testing_outputs = ( trained_model_testing_outputs ,) for ts_output , output in zip ( ts_model_outputs , trained_model_testing_outputs ): if torch . all ( ts_output . eq ( output )): print ( \"Saved TorchScript model working as expected in a basic test.\" ) print ( \"Users should perform further validation as appropriate.\" ) else : model_error = ( \"Saved Torchscript model is not performing as expected. \\n \" \"Consider using scripting if you used tracing, or investigate further.\" ) raise RuntimeError ( model_error ) # Check that the model file is created filepath = os . path . dirname ( __file__ ) if len ( sys . argv ) == 1 else sys . argv [ 1 ] if not os . path . exists ( os . path . join ( filepath , saved_ts_filename )): torchscript_file_error = ( f \"Saved TorchScript file { os . path . join ( filepath , saved_ts_filename ) } \" \"cannot be found.\" ) raise FileNotFoundError ( torchscript_file_error )","tags":"","loc":"sourcefile/pt2ts.py.html"},{"title":"ctorch.h – FTorch","text":"Source Code #ifndef C_TORCH_H #define C_TORCH_H #ifdef __cplusplus #define EXPORT_C extern \"C\" #else #define EXPORT_C #endif #include <stdint.h> // Opaque pointer type alias for torch::jit::script::Module class typedef void * torch_jit_script_module_t ; // Opaque pointer type alias for at::Tensor typedef void * torch_tensor_t ; // Data types typedef enum { torch_kUInt8 , torch_kInt8 , torch_kInt16 , torch_kInt32 , torch_kInt64 , torch_kFloat16 , torch_kFloat32 , torch_kFloat64 } torch_data_t ; // Device types typedef enum { torch_kCPU , torch_kCUDA } torch_device_t ; // ===================================================================================== // Tensor API // ===================================================================================== /** * Function to generate a Torch Tensor of zeros * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to generate a Torch Tensor of ones * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to generate an empty Torch Tensor * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to create a Torch Tensor from memory location given extra * information * @param pointer to the Tensor in memory * @param number of dimensions of the Tensor * @param shape of the Tensor * @param strides to take through data * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required * @return Torch Tensor interpretation of the data pointed at */ EXPORT_C torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to extract a C-array from a Torch Tensor's data. * * @param the Torch Tensor * @param data type of the elements of the Tensor * @return pointer to the Tensor in memory */ EXPORT_C void * torch_to_blob ( const torch_tensor_t tensor , const torch_data_t dtype ); /** * Function to print out a Torch Tensor * @param Torch Tensor to print */ EXPORT_C void torch_tensor_print ( const torch_tensor_t tensor ); /** * Function to determine the device index of a Torch Tensor * @param Torch Tensor to determine the device index of * @return device index of the Torch Tensor */ EXPORT_C int torch_tensor_get_device_index ( const torch_tensor_t tensor ); /** * Function to determine the rank of a Torch Tensor * @param Torch Tensor to determine the rank of * @return rank of the Torch Tensor */ EXPORT_C int torch_tensor_get_rank ( const torch_tensor_t tensor ); /** * Function to determine the sizes (shape) of a Torch Tensor * @param Torch Tensor to determine the rank of * @return pointer to the sizes array of the Torch Tensor */ #ifdef UNIX EXPORT_C const long int * torch_tensor_get_sizes ( const torch_tensor_t tensor ); #else EXPORT_C const long long int * torch_tensor_get_sizes ( const torch_tensor_t tensor ); #endif /** * Function to delete a Torch Tensor to clean up * @param Torch Tensor to delete */ EXPORT_C void torch_tensor_delete ( torch_tensor_t tensor ); // ===================================================================================== // Module API // ===================================================================================== /** * Function to load in a Torch model from a TorchScript file and store in a * Torch Module * @param filename where TorchScript description of model is stored * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required * @param whether model is being trained * @return Torch Module loaded in from file */ EXPORT_C torch_jit_script_module_t torch_jit_load ( const char * filename , const torch_device_t device_type , const int device_index , const bool requires_grad , const bool is_training ); /** * Function to run the `forward` method of a Torch Module * @param Torch Module containing the model * @param vector of Torch Tensors as inputs to the model * @param number of input Tensors in the input vector * @param vector of Torch Tensors as outputs from running the model * @param number of output Tensors in the output vector * @param whether gradient is required */ EXPORT_C void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t * outputs , const int nout , const bool requires_grad ); /** * Function to delete a Torch Module to clean up * @param Torch Module to delete */ EXPORT_C void torch_jit_module_delete ( torch_jit_script_module_t module ); #endif /* C_TORCH_H*/","tags":"","loc":"sourcefile/ctorch.h.html"},{"title":"User Guide – FTorch","text":"Please see the menu on the left for detailed documentation and user guides for using FTorch . Useful resources Useful resources The libtorch C++ API documentation","tags":"","loc":"page/index.html"},{"title":"FTorch License – FTorch","text":"MIT License Copyright (c) 2022 Institute of Computing for Climate Science Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.","tags":"","loc":"page/LICENSE.html"},{"title":"Installation and Build Process – FTorch","text":"Dependencies Basic instructions CMake build options FTorch Library Other projects using CMake Building other projects with make Installation of FTorch is done by CMake. This is controlled by the CMakeLists.txt file in src/ . Dependencies To install the library requires the following to be installed on the system: CMake >= 3.15 libtorch or PyTorch Fortran (2008 standard compliant), C++ (must fully support C++17), and C compilers Basic instructions To build the library, first clone it from GitHub to your local machine and then run: cd FTorch/src/\nmkdir build\ncd build Then invoke CMake with the Release build option, plus any other options as required\nfrom the table below in CMake build options (note: you will likely need to add some of these options to enforce a consistent\nbuild on your machine): cmake .. -DCMAKE_BUILD_TYPE=Release Finally build and install the library using: cmake --build . --target install or, if you want to separate these steps: cmake --build .\ncmake --install . Note: if you are building on Windows please refer to the Windows install guidance as the process will\nlikely differ from the UNIX-based stsyems covered here. CMake build options FTorch Library It is likely that you will need to provide at least the CMAKE_PREFIX_PATH flag. The following CMake flags are available and can be passed as arguments through -D<Option>=<Value> : Option Value Description CMAKE_Fortran_COMPILER ifort / gfortran Specify a Fortran compiler to build the library with. This should match the Fortran compiler you're using to build the code you are calling this library from. 1 CMAKE_C_COMPILER icc / gcc Specify a C compiler to build the library with. 1 CMAKE_CXX_COMPILER icpc / g++ Specify a C++ compiler to build the library with. 1 CMAKE_PREFIX_PATH </path/to/libTorch/> Location of Torch installation 2 CMAKE_INSTALL_PREFIX </path/to/install/lib/at/> Location at which the library files should be installed. By default this is /usr/local CMAKE_BUILD_TYPE Release / Debug Specifies build type. The default is Debug , use Release for production code CMAKE_BUILD_TESTS TRUE / FALSE Specifies whether to compile FTorch's test suite as part of the build. ENABLE_CUDA TRUE / FALSE Specifies whether to check for and enable CUDA 3 1 On Windows this may need to be the full path to the compiler if CMake\ncannot locate it by default. 2 The path to the Torch installation needs to allow CMake to locate the relevant Torch CMake files. If Torch has been installed as libtorch then this should be the absolute path to the unzipped libtorch distribution.\n      If Torch has been installed as PyTorch in a Python venv (virtual environment) ,\n      e.g. with pip install torch , then this should be </path/to/venv/>lib/python<3.xx>/site-packages/torch/ . 3 This is often overridden by PyTorch. When installing with pip, the index-url flag can be used to ensure a CPU or GPU only version is installed, e.g. pip install torch --index-url https://download.pytorch.org/whl/cpu or pip install torch --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8). URLs for alternative versions can be found here . For example, to build on a unix system using the gnu compilers and install to $HOME/FTorchbin/ we would need to run: cmake .. \\ - DCMAKE_BUILD_TYPE = Release \\ - DCMAKE_Fortran_COMPILER = gfortran \\ - DCMAKE_C_COMPILER = gcc \\ - DCMAKE_CXX_COMPILER = g ++ \\ - DCMAKE_PREFIX_PATH = / path / to / venv / lib / python3 . xx / site - packages / torch / \\ - DCMAKE_INSTALL_PREFIX = ~/ FTorchbin Once this completes you should be able to generate the code and install using: cmake --build . --target install Note: If you are using CMake < 3.15 then you will need to build and install separately\nusing the make system specific commands. For example, if using make on UNIX this would be: make\nmake install Installation will place the following directories at the install location: CMAKE_INSTALL_PREFIX/include/ - contains C header and Fortran mod files CMAKE_INSTALL_PREFIX/lib64/ - contains cmake directory and .so files Note: In a Windows environment this will require administrator privileges for the default install location. Other projects using CMake We generally advise building projects that make use of FTorch with CMake where possible. If doing this you need to include the following in the CMakeLists.txt file to\nfind the FTorch installation and link it to the executable. find_package ( FTorch ) target_link_libraries ( <executable> PRIVATE FTorch::ftorch ) message ( STATUS \"Building with Fortran PyTorch coupling\" ) You will then need to use the -DFTorch_DIR=</path/to/install/location> flag\nwhen running CMake. Building other projects with make To build a project with make you need to include the FTorch library when compiling\nand link the executable against it. To compile with make add the following compiler flag when compiling files that\nuse ftorch: FCFLAGS += - I < path / to / install / location >/ include / ftorch When compiling the final executable add the following link flag: LDFLAGS += -L<path/to/install/location>/lib64 -lftorch You may also need to add the location of the .so files to your LD_LIBRARY_PATH unless installing in a default location: export LD_LIBRARY_PATH = $ LD_LIBRARY_PATH : < path / to / installation >/ lib64","tags":"","loc":"page/cmake.html"},{"title":"Developer Guide – FTorch","text":"If you would like to contribute to the FTorch project, or modify the code at a deeper\nlevel, please see below for guidance. Getting involved Code of Conduct Extending the API Fortran source and Fypp git hook Code style General guidelines Documentation Getting involved Contributions and collaborations are welcome. For bugs, feature requests, and clear suggestions for improvement please open an issue . If you have built something upon FTorch that would be useful to others, or can\naddress an open issue , please fork the repository and open a\npull request. Code of Conduct Everyone participating in the FTorch project, and in particular in the\nissue tracker, pull requests, and social media activity, is expected to treat other\npeople with respect and, more generally, to follow the guidelines articulated in the Python Community Code of Conduct . Extending the API If you have a Torch functionality that you wish to bring in from the C++ API to\nthe FTorch Fortran API the steps are generally as follows: Modify ctorch.cpp to create a C++ version of the function that accesses torch::<item> . Add the function to the header file ctorch.h Modify ftorch.fypp to create a Fortran version of the function\n  that binds to the version in ctorch.cpp . Details of C++ functionalities available to be wrapped can be found\nin the libtorch C++ API . As this is an open-source project we appreciate any contributions\nback from users that have extended the functionality.\nIf you have done something but don't know where to start with\nopen-source contributions please get in touch! * * Our preferred method of contact is via Github issues and discussions,\nbut if you are unfamiliar with this you can email ICCS asking for the FTorch developers. Fortran source and Fypp The Fortran source code for FTorch is contained in src/ftorch.f90 .\nHowever, this file should not be edited directly, but instead generated from src/ftorch.fypp .\nThis is a file that is set up to be run through the Fypp preprocessor.\nWe use this because we want to create a pleasant interface of single function calls.\nThe nature of Fortran means that this requires a lot of repeated combinations of\narray shapes and data types under interface structures.\nBy using Fypp we can generate these programatically. Fypp can be installed via pip: pip install fypp To generate the Fortran code run: fypp src/ftorch.fypp src/ftorch.f90 Note: Generally it would be advisable to provide only the .fypp source code to\nreduce duplication and confusion. However, because it is a relatively small file\nand many of our users wish to \"clone-and-go\" rather than develop, we provide both. Development should only take place in ftorch.fypp , however. git hook In order to streamline the process of uploading we provide a pre-commit hook in .githooks/pre-commit .\nThis will check that both the .fypp and .f90 files have been updated together in a\nsynchronous fashion before a commmit can take place.\nIf this does not happen then the second line of defence (GitHub continuous integration)\nwill fail following the commit. Use of the hook is not automatic and needs to be enabled by the developer\n(after they have inspected it and are happy with its contents).\nHooks can be enabled by placing them in the .git directory with the following commands: cp .githooks/pre-commit .git/hooks/\nchmod +x .git/pre-commit Code style FTorch source code is subject to a number of static analysis checks to ensure that it\nconforms to quality and legibility. These tools are a mixture of formatters and linters. The tools we use are as follows on a language-by-language basis: Fortran: fortitude C++: clang-format and clang-tidy C: clang-format and clang-tidy Python: ruff Shell: ShellCheck CMake: cmake-format GitHub Actions workflows: zizmor Instructions on installing these tools can be found in their respective documentations.\nNote that all but ShellCheck may be installed with pip. A shortcut for doing\nthis is to run the following from the base FTorch directory: pip install -r requirements.txt Contributors should run them over their code and ensure that it conforms before submitting\na pull request. If there is a good reason to ignore a particular rule this should be\njustified in the pull request and ideally documented in the code. There is a GitHub action as part of the continuous integration that will perform these\nchecks on all opened pull requests before they are merged. General guidelines Match optional argument defaults between Fortran, C, and C++ ( principle of least astonishment ). Handle torch::Error and std::exception in the C++ functions by catching and\n  printing to screen before exiting cleanly. Documentation The API documentation for FTorch is generated using FORD .\nFor detailed information refer to the FORD User Guide ,\nbut as a quick-start: !! is used to signify documentation. Documentation comes after whatever it is documenting (inline or subsequent line). Documentation can precede an item if designated using !> . FORD is pip installable: pip install ford To generate the documentation run: ford FTorch.md from the root of the repository. FTorch.md is the FORD index file, API documentation is automatically generated, and\nany further items are contained in pages/ as markdown files. Documentation of the C functions in ctorch.h is provided\nby Doxygen .","tags":"","loc":"page/developer.html"},{"title":"Examples – FTorch","text":"Generic example Overview of the interfacing process 1. Saving the model as TorchScript 2. Using the model from Fortran 3. Build the code CMake Make Running on GPUs Worked examples 1) SimpleNet 2) Resnet 3) MultiGPU 4) MultiIO 7) Autograd Generic example Overview of the interfacing process In order to use FTorch users will typically need to follow these steps: Save a PyTorch model as TorchScript . Write Fortran using the FTorch bindings to use the model from within Fortran. Build and compile the code, linking against the FTorch library These are outlined in detail below. 1. Saving the model as TorchScript The trained PyTorch model needs to be exported to TorchScript .\nThis can be done from within your code using the jit.script or jit.trace functionalities from within Python. If you are not familiar with these we provide a tool pt2ts.py as part of this distribution which contains an easily adaptable script to save your\nPyTorch model as TorchScript. 2. Using the model from Fortran To use the trained Torch model from within Fortran we need to import the ftorch module and use the binding routines to load the model, convert the data,\nand run inference.\nA very simple example is given below. This minimal snippet loads a saved Torch model, creates an input consisting of a 10x10 matrix of ones, and runs the model to infer output. This is for illustrative purposes only, and we recommend following the examples before writing your own code to fully explore the features. ! Import library for interfacing with PyTorch use ftorch implicit none ! Generate an object to hold the Torch model type ( torch_model ) :: model ! Set up array of n_inputs input tensors and array of n_outputs output tensors ! Note: In this example there is only one input tensor (n_inputs = 1) and one !       output tensor (n_outputs = 1) integer , parameter :: n_inputs = 1 integer , parameter :: n_outputs = 1 type ( torch_tensor ), dimension ( n_inputs ) :: model_input_arr type ( torch_tensor ), dimension ( n_outputs ) :: model_output_arr ! Set up the model inputs and output as Fortran arrays real , dimension ( 10 , 10 ), target :: input real , dimension ( 5 ), target :: output ! Set up number of dimensions of input tensor and axis order integer , parameter :: in_dims = 2 integer :: in_layout ( in_dims ) = [ 1 , 2 ] integer , parameter :: out_dims = 1 integer :: out_layout ( out_dims ) = [ 1 ] ! Initialise the Torch model to be used torch_model_load ( model , \"/path/to/saved/model.pt\" ) ! Initialise the inputs as Fortran array of ones input = 1.0 ! Wrap Fortran data as no-copy Torch Tensors ! There may well be some reshaping required depending on the ! structure of the model which is not covered here (see examples) call torch_tensor_from_array ( model_input_arr ( 1 ), input , in_layout , torch_kCPU ) call torch_tensor_from_array ( model_output_arr ( 1 ), output , out_layout , torch_kCPU ) ! Run model forward method and Infer ! Again, there may be some reshaping required depending on model design call torch_model_forward ( model , model_input_arr , model_output_arr ) ! Write out the result of running the model write ( * , * ) output ! Clean up call torch_delete ( model ) call torch_delete ( model_input_arr ) call torch_delete ( model_output_arr ) 3. Build the code The code now needs to be compiled and linked against our installed library.\nHere we describe how to do this for two build systems, CMake and make. CMake If our project were using CMake we would need the following in the CMakeLists.txt file to find the FTorch installation and link it to the executable. This can be done by adding the following to the CMakeLists.txt file: find_package ( FTorch ) target_link_libraries ( <executable> PRIVATE FTorch::ftorch ) message ( STATUS \"Building with Fortran PyTorch coupling\" ) and using the -DCMAKE_PREFIX_PATH=</path/to/install/location> flag when running CMake. Note: If you used the CMAKE_INSTALL_PREFIX argument when building and installing the library then you should use the same path for </path/to/install/location> . Make To build with make we need to include the library when compiling and link the executable\nagainst it. To compile with make we need add the following compiler flag when compiling files that\nuse FTorch: FCFLAGS += - I < path / to / install / location >/ include / ftorch When compiling the final executable add the following link flag: LDFLAGS += -L<path/to/install/location>/lib -lftorch You may also need to add the location of the .so files to your LD_LIBRARY_PATH unless installing in a default location: export LD_LIBRARY_PATH = $ LD_LIBRARY_PATH : < path / to / install / location >/ lib Note: Depending on your system and architecture lib may be lib64 or something similar. Running on GPUs In order to run a model on GPU, two main changes to the above process are required: When saving your TorchScript model, ensure that it is on the GPU. When calling torch_tensor_from_array in Fortran, the device for the input\n   tensor(s) should be set to torch_kCUDA , rather than torch_kCPU . For more information refer to the GPU Documentation Worked examples The repository comes with a number of documented worked examples . These are designed to introduce users to FTorch and how to use the various features. A subset of the examples are included as integration tests as part of FTorch's test suite . 1) SimpleNet This worked example provides a simple but complete demonstration of how to use the library.\nIt uses simple PyTorch 'net' that takes an input vector of length 5 and applies a single\nLinear layer to multiply it by 2.\nThe aim is to demonstrate the most basic features of coupling before worrying about\nmore complex issues that are covered in later examples. 2) Resnet This worked example provides a more realistic demonstration of how to use the library,\nusing ResNet-18 to classify an image.\nAs the input to this model is four-dimensional (batch size, colour, x, y),\ncare must be taken dealing with the data array in Python and Fortran.\nSee when to transpose arrays for more details. 3) MultiGPU This worked example builds on the SimpleNet demo and shows how to account for the case of sending different\ndata to multiple GPU devices. 4) MultiIO This worked example considers a variant of the SimpleNet demo, which demonstrates how to account for\nmultiple input tensors and multiple output tensors. 7) Autograd This worked example is currently under development. Eventually, it will demonstrate how to perform\nautomatic differentiation in FTorch by leveraging PyTorch's Autograd module.\nCurrently, it just demonstrates how to use torch_tensor_to_array .","tags":"","loc":"page/examples.html"},{"title":"GPU Support – FTorch","text":"GPU Support Multi-GPU runs GPU Support In order to run a model on GPU, two main changes are required: 1) When saving your TorchScript model, ensure that it is on the GPU.\nFor example, when using pt2ts.py ,\nthis can be done by uncommenting the following lines: device_type = torch . device ( \"cuda\" ) trained_model = trained_model . to ( device_type ) trained_model . eval () trained_model_dummy_input_1 = trained_model_dummy_input_1 . to ( device_type ) trained_model_dummy_input_2 = trained_model_dummy_input_2 . to ( device_type ) Note: This code also moves the dummy input tensors to the GPU.\nWhilst not necessary for saving the model, but the tensors must also be on the GPU\nto test that the models runs. 2) When calling torch_tensor_from_array in Fortran, the device type for the input\n   tensor(s) should be set to torch_kCUDA , rather than torch_kCPU .\n   This ensures that the inputs are on the same device type as the model. Note: You do not need to change the device type for the output tensors as we\nwant them to be on the CPU for subsequent use in Fortran. Multi-GPU runs In the case of having multiple GPU devices, as well as setting torch_kCUDA as the\ndevice type for any input tensors and models, you should also specify their device index\nas the GPU device to be targeted. This argument is optional and will default to device\nindex 0 if unset. For example, the following code snippet sets up a Torch tensor with GPU device index 2: device_index = 2 call torch_tensor_from_array ( in_tensors ( 1 ), in_data , tensor_layout , & torch_kCUDA , device_index = device_index ) Whereas the following code snippet sets up a Torch tensor with (default) device index 0: call torch_tensor_from_array ( in_tensors ( 1 ), in_data , tensor_layout , & torch_kCUDA ) See the MultiGPU example for a worked example of running with multiple GPUs.","tags":"","loc":"page/gpu.html"},{"title":"FTorch test suite – FTorch","text":"Testing Building the integration tests Running the integration tests Testing FTorch's test suite currently comprises of integration tests based on a subset\nof the examples . These tests are built and run and their\noutputs are analysed to check they contain expected regular expressions. Building the integration tests To enable FTorch's integration tests, ensure that the CMAKE_BUILD_TESTS option\nis set to TRUE for the build i.e., -DCMAKE_BUILD_TESTS=True . Running the integration tests Once the build is complete, activate the Python virtual environment you created\nfor FTorch 1 and simply run the helper script in the root FTorch directory. Depending on the OS you are running you will need\nto use either: ./run_integration_tests.sh for unix (mac and linux) run_integration_tests.bat for windows This will automatically install any additional Python dependencies for the\nexamples. Alternatively, individual tests may be run by going to the corresponding\nsubdirectory of ${BUILD_DIR}/test/examples (where ${BUILD_DIR} is the build\ndirectory for FTorch) and calling ctest . This will produce a report on which\ntests passed and which failed for your build. Note that some of the examples\nhave additional dependencies, which may need installing into your virtual\nenvironment. 1 If you built FTorch against libtorch (rather than creating a\nvirtual environment) then either create a virtual environment for\nthe purposes of testing, or note that this script may have your Python\nenvironment install some modules.","tags":"","loc":"page/testing.html"},{"title":"When to transpose data – FTorch","text":"Transposition of data between Fortran and C can lead to a lot of unneccessary confusion.\nThe FTorch library looks after this for you with the torch_tensor_from_array() function which\nallows you to index a tensor in Torch in exactly the same way as you would in Fortran. If you wish to do something different to this then there are more complex functions\navailable and we describe here how and when to use them. Introduction - row- vs. column-major Why does this matter? What can we do? 1) Transpose before passing 2) Design nets to use transpose 3) Use the layout argument in torch_tensor_from_array Advanced use with torch_tensor_from_blob Introduction - row- vs. column-major Astute users will note that Fortran is a column-major language whilst C, C++, and Python are row-major . This means that the matrix/tensor in Fortran will appear in contiguous memory on the computer as with the order of elements decided by moving down the columns before progressing in the\nrow dimension. In contrast, the same matrix/tensor defined in a row-major language will appear in\ncontiguous memory as reading along each row before progressing down the column dimension. Why does this matter? This matters for FTorch because a key feature is no-copy memory transfer between Fortran\nand Torch.\nTo do this the Fortran data that will be used in Torch is stored in memory and a pointer to the first\nelement, provided to Torch. Now, if Torch were to take this block of memory and interpret it as as a 2x2 matrix it\nwould be read in as which is the transpose of the\nmatrix we had in Fortran; likely not what we were expecting! This means we need to be careful when passing data to make sure that what we read in\nto our Torch net is correct as we expect. What can we do? There are a few approaches we can take to address this. The first two of these are listed for conceptual purposes, whilst in practice we\nadvise handling this using the torch_tensor_from_array function described in 3) below . 1) Transpose before passing As seen from the above example, writing out from Fortran and reading directly in to\nTorch results in us recieving the transpose. Therefore we could transpose out Fortran data immediately before passing it to Torch.\nAs a result we will read in to Torch indexed the same as in Fortran pre-transposition. For arrays of dimension 2 this can be done using the intrinsic transpose() function. For larger arrays we are required to use the 'reshape()' intrinsic to swap\nthe order of the indices. For example, if we had a 3x4x5 matrix we would need to call A_to_torch = reshape(A, shape=[5, 4, 3], order=[3, 2, 1]) which could then be read by Torch as a 3x4x5 tensor. We would, of course, need to remember to transpose/reshape any output of the model\nas required. However, the transposition process involves creating a copy of the Fortran data.\nFor large matrices/tensors this can become expensive.\nIt would be better if we can pass data without having to transpose beforehand. 2) Design nets to use transpose Alternatively we could design our net to use as its input tensor meaning we can simply write from Fortran and read to Torch. However, this requires foresight and may not be intuitive - we would like to be indexing\ndata in the same way in both Fortran and Torch.\nNot doing so could leave us open to introducing bugs. 3) Use the layout argument in torch_tensor_from_array By far the easiest way to deal with the issue is not to worry about it at all! As described at the top of this page, by using the torch_tensor_from_array function\nwe can make use of the layout argument.\nThis allows us to take data from Fortran and send it to Torch to be indexed in exactly\nthe same way by using strided access based on the shape of the array. It takes the form of an array specifying which order to read the indices in.\ni.e. [1, 2] will read i then j .\nBy passing layout = [1, 2] the data will be read into the correct indices by\nTorch. This is achieved by wrapping the torch_tensor_from_blob function to automatically\ngenerate strides assuming that a straightforward conversion between\nrow- and column-major is what should happen. i.e. if the Fortran array A is passed as torch_tensor_from_array(A, [1, 2], torch_device) the resulting Tensor will be read by Torch as Note: If, for some reason, we did want a different, transposed layout in Torch we\ncould use torch_tensor_from_array(A, [2, 1], torch_device) to get: Advanced use with torch_tensor_from_blob For more advanced options for manipulating and controlling data access when passing\nbetween Fortran and Torch see the more powerful but more complex torch_tensor_from_blob function","tags":"","loc":"page/transposing.html"},{"title":"Troubleshooting – FTorch","text":"If you are experiencing problems building or using FTorch please see below for guidance on common problems. Windows Visual Studio MinGW Apple Silicon FAQ Why are inputs to torch models an array? Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch? How do I compile an int64 version of ftorch for large tensors? Windows If possible we recommend using the Windows Subsystem for Linux (WSL) to build\nthe library. In this case the build process is the same as for a Linux environment. If you need to build in native Windows please read the following information: Visual Studio It is possible to build using Visual Studio and the Intel Fortran Compiler. In this case you must install the following: Visual Studio ensuring C++ tools are selected and installed. Intel OneAPI Basetoolkit Intel OneAPI HPC toolkit ensuring that the Intel Fortran compiler and VS integration is selected. You will then need to load the intel Fortran compilers using setvars.bat which is found in the Intel compiler install\ndirectory (see the intel\ndocs )\nfor more details. From cmd this can be done with: call \"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" Finally you will need to add -G \"NMake Makefiles\" to the cmake command in the regular install instructions . So the basic command to build from cmd becomes: cmake - G \"NMake Makefiles\" - DCMAKE_PREFIX_PATH = \"C:\\Users\\<path-to-libtorch-download>\\libtorch\" - DCMAKE_BUILD_TYPE = Release .. cmake -- build . cmake -- install . The following is an example cmd script that installs FTorch and runs the integration tests. It assumes you have already\ninstall cmake , git , the intel compilers and visual studio. rem disable output for now ECHO ON rem load intel compilers call \"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" rem download ftorch git clone https : // github . com / Cambridge - ICCS / FTorch . git cd FTorch rem make venv python - m venv . ftorch rem activate the environment call . ftorch \\ Scripts \\ activate rem install torch pip install torch torchvision torchaudio rem enable output ECHO ON rem run cmake to generate build scripts rem ( update CMAKE_PREFIX_PATH depending on location of ftorch venv ) cd src cmake - Bbuild - G \"NMake Makefiles\" - DCMAKE_Fortran_FLAGS = \"/fpscomp:logicals\" &#94; - DCMAKE_PREFIX_PATH = \"C:\\Users\\Quickemu\\Downloads\\FTorch\\.ftorch\\Lib\\site-packages\" &#94; - DCMAKE_BUILD_TYPE = Release &#94; - DCMAKE_BUILD_TESTS = True &#94; - DCMAKE_Fortran_COMPILER = ifx - DCMAKE_C_COMPILER = icx - DCMAKE_CXX_COMPILER = icx rem build and install ftorch cmake -- build build cmake -- install build rem quit if this raises an error if % errorlevel % neq 0 exit / b % errorlevel % ECHO OFF rem add ftorch and pytorch libs to path rem ( update these depending on where you installed ftorch and where you created the venv ) set PATH = C : \\ Users \\ Quickemu \\ Downloads \\ FTorch \\ . ftorch \\ Lib \\ site - packages ; % PATH % set PATH = C : \\ Program Files ( x86 ) \\ FTorch \\ bin ; % PATH % set PATH = C : \\ Users \\ Quickemu \\ Downloads \\ FTorch \\ . ftorch \\ Lib \\ site - packages \\ torch \\ lib ; % PATH % cd .. rem run integration tests ECHO ON run_integration_tests . bat if % errorlevel % neq 0 exit / b % errorlevel % We would also recommend Windows users to review the Windows CI workflow ( .github/workflows/test_suite_windows.yml ) for more\ninformation, as this provides another example of how to build and run FTorch and its integration tests. If using powershell the setvars and build commands become: cmd / k '\"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" && powershell' cmake - G \"NMake Makefiles\" - DCMAKE_PREFIX_PATH = \"C:\\Users\\<path-to-libtorch-download>\\libtorch\" - DCMAKE_BUILD_TYPE = Release .. cmake -- build . cmake -- install . MinGW It may be tempting to build on Windows using MinGW.\nHowever, libtorch does not currently support MinGW .\nInstead please build using Visual Studio and the intel Fortran compiler (ifort) as\ndetailed in the project README. Apple Silicon At the time of writing, libtorch is currently only officially available for x86\narchitectures (according to pytorch.org ).\nHowever, the version of PyTorch provided by pip install provides an ARM binary\nfor libtorch which works on Apple Silicon.\nTherefore you should pip install torch in this situation and follow the guidance\non locating Torch within a virtual environment (venv) for CMake. FAQ Why are inputs to torch models an array? The reason input and output tensors to torch_model_forward are\ncontained in arrays is because it is possible to pass multiple input tensors to\nthe forward() method of a torch net, and it is possible for the net to return\nmultiple output arrays. The nature of Fortran means that it is not possible to set an arbitrary number\nof inputs to the torch_model_forward subroutine, so instead we use a single\narray of input tensors which can have an arbitrary length. Similarly, a single\narray of output tensors is used. Note that this does not refer to batching data.\nThis should be done in the same way as in Torch; by extending the dimensionality of\nthe input tensors. Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch? By default we disable gradient calculations for tensors and models and place models in\nevaluation mode for efficiency.\nThese can be adjusted using the requires_grad and is_training optional arguments\nin the Fortran interface. See the API procedures documentation for details. How do I compile an int64 version of ftorch for large tensors? Currently FTorch represents the number of elements in an array dimension using\n32-bit integers. For most users this will be more than enough, but if your code\nuses large tensors (where large means more than 2,147,483,647 elements\nin any one dimension (the maximum value of a 32-bit integer)), you may you may\nneed to compile ftorch with 64-bit integers. If you do not, you may receive a\ncompile time error like the following: 39 |   call torch_tensor_from_array(tensor, in_data, tensor_layout, torch_kCPU)\n      |                                                                          1\nError: There is no specific subroutine for the generic ‘torch_tensor_from_array’ at (1) To fix this, we can build ftorch with 64-bit integers. We need to modify this\nline in src/ftorch.fypp integer , parameter :: ftorch_int = int32 ! set integer size for FTorch library We can use 64-bit integers by changing the above line to this integer , parameter :: ftorch_int = int64 ! set integer size for FTorch library Finally, you will need to run fypp ( fypp is not a core dependency, so you\nmay need to install this separately) e.g., fypp src/ftorch.fypp src/ftorch.F90","tags":"","loc":"page/troubleshooting.html"},{"title":"Recent API Changes – FTorch","text":"Why? Changes and how to update your code torch_tensors are created using a subroutine call, not a function module becomes model and loading becomes a subroutine call, not a function n_inputs is no longer required Outputs now need to be an array of torch_tensors Why? Recently we made a number of breaking changes to the FTorch API. We realise that this forms an inconvenience to those of you who are actively\nusing FTorch and is not something we did lightly.\nThese changes were neccessary to improve functionality and we have made them in one go\nas we move towards a stable API and first release in the very near future.\nOnce the first release is set then the API becomes standardised then changes like this\nwill be avoided. We hope that this is the last time we have such a shift. The changes allow us to implement two new features: Multiple output tensors\n   Previously you could pass an array of several input tensors to a Torch model, but\n   only recieve a single output tensor back. Now you can use models that return several\n   output tensors by passing an array of output tensors instead. Preparation for autograd functionality\n   We hope to make it easier to access the autograd features of PyTorch from within Fortran.\n   To do this we needed to change how data was assigned from a Fortran array to a Torch tensor.\n   This is now done via a subroutine call rather than a function. Changes and how to update your code torch_tensor s are created using a subroutine call, not a function Previously you would have created a Torch tensor and assigned some fortran data to it as follows: real , dimension ( 5 ), target :: fortran_data type ( torch_tensor ) :: my_tensor integer :: tensor_layout ( 1 ) = [ 1 ] my_tensor = torch_tensor_from_array ( fortran_data , tensor_layout , torch_kCPU ) Now a call is made to a subroutine with the tensor as the first argument: real , dimension ( 5 ), target :: fortran_data type ( torch_tensor ) :: my_tensor integer :: tensor_layout ( 1 ) = [ 1 ] call torch_tensor_from_array ( my_tensor , fortran_data , tensor_layout , torch_kCPU ) module becomes model and loading becomes a subroutine call, not a function Previously a neural net was referred to as a ' module ' and loaded using appropriately\nnamed functions and types. type ( torch_module ) :: model model = torch_module_load ( args ( 1 )) call torch_module_forward ( model , in_tensors , out_tensors ) Following user feedback we now refer to a neural net and its associated types and calls\nas a ' model '.\nThe process of loading a net is also now a subroutine call for consistency with the\ntensor creation operations: type ( torch_model ) :: model call torch_model_load ( model , 'path_to_saved_net.pt' ) call torch_model_forward ( model , in_tensors , out_tensors ) n_inputs is no longer required Previously when you called the forward method on a net you had to specify the number of tensors\nin the array of inputs: call torch_model_forward ( model , in_tensors , n_inputs , out_tensors ) Now all that is supplied to the forward call is the model, and the arrays of input and\noutput tensors. No need for n_inputs (or n_outputs )! call torch_model_forward ( model , in_tensors , out_tensors ) Outputs now need to be an array of torch_tensor s Previously you passed an array of torch_tensor types as inputs, and a single torch_tensor to the forward method: type ( torch_tensor ), dimension ( n_inputs ) :: input_tensor_array type ( torch_tensor ) :: output_tensor ... call torch_model_forward ( model , input_tensor_array , n_inputs , output_tensor ) Now both the inputs and the outputs need to be an array of torch_tensor types: type ( torch_tensor ), dimension ( n_inputs ) :: input_tensor_array type ( torch_tensor ), dimension ( n_outputs ) :: output_tensor_array ... call torch_model_forward ( model , input_tensor_array , output_tensor_array )","tags":"","loc":"page/updates.html"}]}