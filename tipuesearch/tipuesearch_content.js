var tipuesearch = {"pages":[{"title":" FTorch ","text":"FTorch Brief description Presentations License Projects using FTorch Brief description It is desirable to be able to run machine learning (ML) models directly in Fortran.\nML models are often trained in some other language (say, Python) using a popular frameworks (say, PyTorch) and saved.\nWe want to run inference on this model without having to call a Python executable.\nTo achieve this we use the existing Torch C++ interface, libtorch. FTorch provides a library enabling a user to directly couple their PyTorch models to Fortran code.\nThere are also installation instructions for the library and examples of performing coupling. We support running on both CPU and GPU, and have tested the library on UNIX and Windows based operating systems Presentations The following presentations contain information about FTorch: Reducing the Overhead of Coupled Machine Learning Models between Python and Fortran RSECon23 Slides License The FTorch source code, related files and documentation are\ndistributed under an MIT License which can be viewed here . Projects using FTorch The following projects make use of FTorch. If you use our library in your work please let us know. MiMA Machine Learning - DataWave Using FTorch to couple a neural net parameterisation of gravity waves to an atmospheric model. Developer Info ICCS Cambridge","tags":"home","loc":"index.html"},{"title":"torch_module – FTorch ","text":"type, public :: torch_module Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net module in memory Source Code type torch_module type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net module in memory end type torch_module","tags":"","loc":"type/torch_module.html"},{"title":"torch_tensor – FTorch ","text":"type, public :: torch_tensor Type for holding a torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Source Code type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory end type torch_tensor","tags":"","loc":"type/torch_tensor.html"},{"title":"t_t_from_array – FTorch","text":"public  function t_t_from_array(data_arr, tensor_shape, dtype, device) result(tensor) Uses iso_c_binding This routine will take an (i, j, k) array and return an (k, j, i) tensor\nit is invoked from a set of interfaces torch_tensor_from_array_dtype Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data_arr Pointer to data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Source Code function t_t_from_array ( data_arr , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_double , c_loc ! Arguments type ( c_ptr ), intent ( in ) :: data_arr !! Pointer to data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ), allocatable :: strides (:) !! Strides for accessing data integer ( c_int ), allocatable :: layout (:) !! Layout for strides for accessing data integer ( c_int ) :: ndims !! Number of dimensions of the tensor interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_from_blob_c end interface ndims = size ( tensor_shape ) allocate ( strides ( ndims )) allocate ( layout ( ndims )) ! Fortran Layout do i = 1 , ndims layout ( i ) = i end do strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( data_arr , ndims , tensor_shape , strides , dtype , device ) deallocate ( strides ) deallocate ( layout ) end function t_t_from_array","tags":"","loc":"proc/t_t_from_array.html"},{"title":"torch_module_load – FTorch","text":"public  function torch_module_load(filename) result(module) Uses iso_c_binding Loads a Torch Script module (pre-trained PyTorch model saved with Torch Script) Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: filename Filename of Torch Script module Return Value type( torch_module ) Returned deserialized module Source Code function torch_module_load ( filename ) result ( module ) use , intrinsic :: iso_c_binding , only : c_null_char character ( * ), intent ( in ) :: filename !! Filename of Torch Script module type ( torch_module ) :: module !! Returned deserialized module interface function torch_jit_load_c ( filename ) result ( module ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_char , c_ptr character ( c_char ), intent ( in ) :: filename ( * ) type ( c_ptr ) :: module end function torch_jit_load_c end interface ! Need to append c_null_char at end of filename module % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char ) end function torch_module_load","tags":"","loc":"proc/torch_module_load.html"},{"title":"torch_tensor_from_array_c_double – FTorch","text":"public  function torch_tensor_from_array_c_double(data_arr, tensor_shape, device) result(tensor) Uses iso_c_binding Arguments Type Intent Optional Attributes Name real(kind=c_double), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_c_double ( data_arr , tensor_shape , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_double , c_loc real ( c_double ), intent ( in ), target :: data_arr ( * ) !! Fortran array of data ! real(c_double), intent(in), target :: data_arr(*)   !! Fortran array of data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), parameter :: dtype = torch_kFloat64 integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor tensor = t_t_from_array ( c_loc ( data_arr ), tensor_shape , dtype , device ) end function torch_tensor_from_array_c_double","tags":"","loc":"proc/torch_tensor_from_array_c_double.html"},{"title":"torch_tensor_from_array_c_float – FTorch","text":"public  function torch_tensor_from_array_c_float(data_arr, tensor_shape, device) result(tensor) Uses iso_c_binding Arguments Type Intent Optional Attributes Name real(kind=c_float), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_c_float ( data_arr , tensor_shape , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_float , c_loc real ( c_float ), intent ( in ), target :: data_arr ( * ) !! Fortran array of data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), parameter :: dtype = torch_kFloat32 integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor tensor = t_t_from_array ( c_loc ( data_arr ), tensor_shape , dtype , device ) end function torch_tensor_from_array_c_float","tags":"","loc":"proc/torch_tensor_from_array_c_float.html"},{"title":"torch_tensor_from_blob – FTorch","text":"public  function torch_tensor_from_blob(data, ndims, tensor_shape, dtype, device, layout) result(tensor) Uses iso_c_binding Exposes the given data as a tensor without taking ownership of the original data.\nThis routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_blob ( data , ndims , tensor_shape , dtype , device , layout ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr ! Arguments type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_from_blob_c end interface strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) end function torch_tensor_from_blob","tags":"","loc":"proc/torch_tensor_from_blob.html"},{"title":"torch_tensor_ones – FTorch","text":"public  function torch_tensor_ones(ndims, tensor_shape, dtype, device) result(tensor) Uses iso_c_binding Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_ones ( ndims , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_ones_c end interface tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device ) end function torch_tensor_ones","tags":"","loc":"proc/torch_tensor_ones.html"},{"title":"torch_tensor_zeros – FTorch","text":"public  function torch_tensor_zeros(ndims, tensor_shape, dtype, device) result(tensor) Uses iso_c_binding Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_zeros ( ndims , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_zeros_c end interface tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device ) end function torch_tensor_zeros","tags":"","loc":"proc/torch_tensor_zeros.html"},{"title":"torch_module_delete – FTorch","text":"public  subroutine torch_module_delete(module) Deallocates a Torch Script module Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module Source Code subroutine torch_module_delete ( module ) type ( torch_module ), intent ( in ) :: module !! Module interface subroutine torch_jit_module_delete_c ( module ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: module end subroutine torch_jit_module_delete_c end interface call torch_jit_module_delete_c ( module % p ) end subroutine torch_module_delete","tags":"","loc":"proc/torch_module_delete.html"},{"title":"torch_module_forward – FTorch","text":"public  subroutine torch_module_forward(module, input_tensors, n_inputs, output_tensor) Uses iso_c_binding Performs a forward pass of the module with the input tensors Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors integer(kind=c_int) :: n_inputs Number of tensors in input_tensors type( torch_tensor ), intent(in) :: output_tensor Returned output tensors Source Code subroutine torch_module_forward ( module , input_tensors , n_inputs , output_tensor ) use , intrinsic :: iso_c_binding , only : c_ptr , c_int , c_loc type ( torch_module ), intent ( in ) :: module !! Module type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ) :: output_tensor !! Returned output tensors integer ( c_int ) :: n_inputs !! Number of tensors in `input_tensors` integer :: i type ( c_ptr ), dimension ( n_inputs ), target :: input_ptrs interface subroutine torch_jit_module_forward_c ( module , input_tensors , n_inputs , & output_tensor ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_ptr , c_int type ( c_ptr ), value , intent ( in ) :: module type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensor end subroutine torch_jit_module_forward_c end interface ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do call torch_jit_module_forward_c ( module % p , c_loc ( input_ptrs ), n_inputs , output_tensor % p ) end subroutine torch_module_forward","tags":"","loc":"proc/torch_module_forward.html"},{"title":"torch_tensor_delete – FTorch","text":"public  subroutine torch_tensor_delete(tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Source Code subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete","tags":"","loc":"proc/torch_tensor_delete.html"},{"title":"torch_tensor_print – FTorch","text":"public  subroutine torch_tensor_print(tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Source Code subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print","tags":"","loc":"proc/torch_tensor_print.html"},{"title":"torch_tensor_from_array – FTorch","text":"public interface torch_tensor_from_array Module Procedures public  function torch_tensor_from_array_c_float (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_float), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_c_double (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_double), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor","tags":"","loc":"interface/torch_tensor_from_array.html"},{"title":"ftorch – FTorch","text":"The ftorch module containing wrappers to access libtorch Uses iso_c_binding Enumerations enum, bind(c) Enumerators enumerator :: torch_kUInt8 = 0 enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 enum, bind(c) Enumerators enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 Interfaces public        interface torch_tensor_from_array public  function torch_tensor_from_array_c_float (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_float), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_c_double (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_double), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Derived Types type, public :: torch_module Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net module in memory type, public :: torch_tensor Type for holding a torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Functions public  function t_t_from_array (data_arr, tensor_shape, dtype, device) result(tensor) This routine will take an (i, j, k) array and return an (k, j, i) tensor\nit is invoked from a set of interfaces torch_tensor_from_array_dtype Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data_arr Pointer to data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_module_load (filename) result(module) Loads a Torch Script module (pre-trained PyTorch model saved with Torch Script) Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: filename Filename of Torch Script module Return Value type( torch_module ) Returned deserialized module public  function torch_tensor_from_array_c_double (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_double), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_c_float (data_arr, tensor_shape, device) result(tensor) Arguments Type Intent Optional Attributes Name real(kind=c_float), intent(in), target :: data_arr (*) Fortran array of data integer(kind=c_int64_t), intent(in) :: tensor_shape (:) Shape of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_blob (data, ndims, tensor_shape, dtype, device, layout) result(tensor) Exposes the given data as a tensor without taking ownership of the original data.\nThis routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_ones (ndims, tensor_shape, dtype, device) result(tensor) Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_zeros (ndims, tensor_shape, dtype, device) result(tensor) Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device Device on which the tensor will live on (torch_kCPU or torch_kGPU) Return Value type( torch_tensor ) Returned tensor Subroutines public  subroutine torch_module_delete (module) Deallocates a Torch Script module Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module public  subroutine torch_module_forward (module, input_tensors, n_inputs, output_tensor) Performs a forward pass of the module with the input tensors Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors integer(kind=c_int) :: n_inputs Number of tensors in input_tensors type( torch_tensor ), intent(in) :: output_tensor Returned output tensors public  subroutine torch_tensor_delete (tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor public  subroutine torch_tensor_print (tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor","tags":"","loc":"module/ftorch.html"},{"title":"ftorch.f90 – FTorch","text":"Source Code module ftorch !! The ftorch module containing wrappers to access libtorch use , intrinsic :: iso_c_binding , only : c_int , c_int8_t , c_int16_t , c_int32_t , c_int64_t , c_int64_t , & c_float , c_double , c_char , c_ptr , c_null_ptr implicit none !> Type for holding a torch neural net (nn.Module). type torch_module type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net module in memory end type torch_module !> Type for holding a torch tensor. type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory end type torch_tensor ! From c_torch.h (torch_data_t) enum , bind ( c ) enumerator :: torch_kUInt8 = 0 enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 end enum ! From c_torch.h (torch_device_t) enum , bind ( c ) enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 end enum ! Interface for calculating tensor from array for different possible input types interface torch_tensor_from_array module procedure torch_tensor_from_array_c_float module procedure torch_tensor_from_array_c_double ! module procedure torch_tensor_from_array_c_int8_t ! module procedure torch_tensor_from_array_c_int16_t ! module procedure torch_tensor_from_array_c_int32_t ! module procedure torch_tensor_from_array_c_int64_t end interface contains ! Torch Tensor API !> Exposes the given data as a tensor without taking ownership of the original data. !> This routine will take an (i, j, k) array and return an (k, j, i) tensor. function torch_tensor_from_blob ( data , ndims , tensor_shape , dtype , device , layout ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr ! Arguments type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_from_blob_c end interface strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) end function torch_tensor_from_blob !> This routine will take an (i, j, k) array and return an (k, j, i) tensor !> it is invoked from a set of interfaces `torch_tensor_from_array_dtype` function t_t_from_array ( data_arr , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_double , c_loc ! Arguments type ( c_ptr ), intent ( in ) :: data_arr !! Pointer to data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ), allocatable :: strides (:) !! Strides for accessing data integer ( c_int ), allocatable :: layout (:) !! Layout for strides for accessing data integer ( c_int ) :: ndims !! Number of dimensions of the tensor interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_from_blob_c end interface ndims = size ( tensor_shape ) allocate ( strides ( ndims )) allocate ( layout ( ndims )) ! Fortran Layout do i = 1 , ndims layout ( i ) = i end do strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( data_arr , ndims , tensor_shape , strides , dtype , device ) deallocate ( strides ) deallocate ( layout ) end function t_t_from_array !> Returns a tensor filled with the scalar value 1. function torch_tensor_ones ( ndims , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_ones_c end interface tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device ) end function torch_tensor_ones !> Returns a tensor filled with the scalar value 0. function torch_tensor_zeros ( ndims , tensor_shape , dtype , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , device ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device type ( c_ptr ) :: tensor end function torch_zeros_c end interface tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device ) end function torch_tensor_zeros !> Prints the contents of a tensor. subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print !> Deallocates a tensor. subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete ! Torch Module API !> Loads a Torch Script module (pre-trained PyTorch model saved with Torch Script) function torch_module_load ( filename ) result ( module ) use , intrinsic :: iso_c_binding , only : c_null_char character ( * ), intent ( in ) :: filename !! Filename of Torch Script module type ( torch_module ) :: module !! Returned deserialized module interface function torch_jit_load_c ( filename ) result ( module ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_char , c_ptr character ( c_char ), intent ( in ) :: filename ( * ) type ( c_ptr ) :: module end function torch_jit_load_c end interface ! Need to append c_null_char at end of filename module % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char ) end function torch_module_load !> Performs a forward pass of the module with the input tensors subroutine torch_module_forward ( module , input_tensors , n_inputs , output_tensor ) use , intrinsic :: iso_c_binding , only : c_ptr , c_int , c_loc type ( torch_module ), intent ( in ) :: module !! Module type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ) :: output_tensor !! Returned output tensors integer ( c_int ) :: n_inputs !! Number of tensors in `input_tensors` integer :: i type ( c_ptr ), dimension ( n_inputs ), target :: input_ptrs interface subroutine torch_jit_module_forward_c ( module , input_tensors , n_inputs , & output_tensor ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_ptr , c_int type ( c_ptr ), value , intent ( in ) :: module type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensor end subroutine torch_jit_module_forward_c end interface ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do call torch_jit_module_forward_c ( module % p , c_loc ( input_ptrs ), n_inputs , output_tensor % p ) end subroutine torch_module_forward !> Deallocates a Torch Script module subroutine torch_module_delete ( module ) type ( torch_module ), intent ( in ) :: module !! Module interface subroutine torch_jit_module_delete_c ( module ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: module end subroutine torch_jit_module_delete_c end interface call torch_jit_module_delete_c ( module % p ) end subroutine torch_module_delete ! Series of interface functions function torch_tensor_from_array_c_double ( data_arr , tensor_shape , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_double , c_loc real ( c_double ), intent ( in ), target :: data_arr ( * ) !! Fortran array of data ! real(c_double), intent(in), target :: data_arr(*)   !! Fortran array of data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), parameter :: dtype = torch_kFloat64 integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor tensor = t_t_from_array ( c_loc ( data_arr ), tensor_shape , dtype , device ) end function torch_tensor_from_array_c_double function torch_tensor_from_array_c_float ( data_arr , tensor_shape , device ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_int , c_int64_t , c_float , c_loc real ( c_float ), intent ( in ), target :: data_arr ( * ) !! Fortran array of data integer ( c_int64_t ), intent ( in ) :: tensor_shape (:) !! Shape of the tensor integer ( c_int ), parameter :: dtype = torch_kFloat32 integer ( c_int ), intent ( in ) :: device !! Device on which the tensor will live on (torch_kCPU or torch_kGPU) type ( torch_tensor ) :: tensor !! Returned tensor tensor = t_t_from_array ( c_loc ( data_arr ), tensor_shape , dtype , device ) end function torch_tensor_from_array_c_float end module ftorch","tags":"","loc":"sourcefile/ftorch.f90.html"},{"title":"ctorch.h – FTorch","text":"Source Code #ifndef C_TORCH_H #define C_TORCH_H #ifdef __cplusplus #define EXPORT_C extern \"C\" #else #define EXPORT_C #endif // Opaque pointer type alias for torch::jit::script::Module class typedef void * torch_jit_script_module_t ; // Opaque pointer type alias for at::Tensor typedef void * torch_tensor_t ; // Data types typedef enum { torch_kUInt8 , torch_kInt8 , torch_kInt16 , torch_kInt32 , torch_kInt64 , torch_kFloat16 , torch_kFloat32 , torch_kFloat64 } torch_data_t ; // Device types typedef enum { torch_kCPU , torch_kCUDA } torch_device_t ; // ===================================================================================== // Tensor API // ===================================================================================== /** * Function to generate a Torch Tensor of zeros * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device used (cpu, CUDA, etc.) */ EXPORT_C torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ); /** * Function to generate a Torch Tensor of ones * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device used (cpu, CUDA, etc.) */ EXPORT_C torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ); /** * Function to generate an empty Torch Tensor * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device used (cpu, CUDA, etc.) */ EXPORT_C torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ); /** * Function to create a Torch Tensor from memory location given extra information * @param pointer to the Tensor in memory * @param number of dimensions of the Tensor * @param shape of the Tensor * @param strides to take through data * @param data type of the elements of the Tensor * @param device used (cpu, CUDA, etc.) * @return Torch Tensor interpretation of the data pointed at */ EXPORT_C torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device ); /** * Function to print out a Torch Tensor * @param Torch Tensor to print */ EXPORT_C void torch_tensor_print ( const torch_tensor_t tensor ); /** * Function to create a Torch Tensor from memory location given extra information * This is a rework for torch_from_blob that uses strides, and will eventually * replace torch_from_blob. * @param pointer to the Tensor in memory * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device used (cpu, CUDA, etc.) * @return Torch Tensor interpretation of the data pointed at */ EXPORT_C torch_tensor_t torch_from_blob_f ( void * data , int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ); /** * Function to delete a Torch Tensor to clean up * @param Torch Tensor to delete */ EXPORT_C void torch_tensor_delete ( torch_tensor_t tensor ); // ===================================================================================== // Module API // ===================================================================================== /** * Function to load in a Torch model from a TorchScript file and store in a Torch Module * @param filename where TorchScript description of model is stored * @return Torch Module loaded in from file */ EXPORT_C torch_jit_script_module_t torch_jit_load ( const char * filename ); /** * Function to run the `forward` method of a Torch Module * @param Torch Module containing the model * @param vector of Torch Tensors as inputs to the model * @param number of input Tensors in the input vector * @param the output Tensor from running the model */ EXPORT_C void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t output ); /** * Function to delete a Torch Module to clean up * @param Torch Module to delete */ EXPORT_C void torch_jit_module_delete ( torch_jit_script_module_t module ); #endif /* C_TORCH_H*/","tags":"","loc":"sourcefile/ctorch.h.html"},{"title":"pt2ts.py – FTorch","text":"Source Code \"\"\"Load a pytorch model and convert it to TorchScript.\"\"\" from typing import Optional import torch # FPTLIB-TODO # Add a module import with your model here: # This example assumes the model architecture is in an adjacent module `my_ml_model.py` import my_ml_model def script_to_torchscript ( model : torch . nn . Module , filename : Optional [ str ] = \"scripted_model.pt\" ) -> None : \"\"\" Save pyTorch model to TorchScript using scripting. Parameters ---------- model : torch.NN.Module a pyTorch model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved scripted_model = torch . jit . script ( model ) # print(scripted_model.code) scripted_model . save ( filename ) def trace_to_torchscript ( model : torch . nn . Module , dummy_input : torch . Tensor , filename : Optional [ str ] = \"traced_model.pt\" , ) -> None : \"\"\" Save pyTorch model to TorchScript using tracing. Parameters ---------- model : torch.NN.Module a pyTorch model dummy_input : torch.Tensor appropriate size Tensor to act as input to model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved traced_model = torch . jit . trace ( model , dummy_input ) # traced_model.save(filename) frozen_model = torch . jit . freeze ( traced_model ) ## print(frozen_model.graph) ## print(frozen_model.code) frozen_model . save ( filename ) def load_torchscript ( filename : Optional [ str ] = \"saved_model.pt\" ) -> torch . nn . Module : \"\"\" Load a TorchScript from file. Parameters ---------- filename : str name of file containing TorchScript model \"\"\" model = torch . jit . load ( filename ) return model if __name__ == \"__main__\" : # ===================================================== # Load model and prepare for saving # ===================================================== # FPTLIB-TODO # Load a pre-trained PyTorch model # Insert code here to load your model as `trained_model`. # This example assumes my_ml_model has a method `initialize` to load # architecture, weights, and place in inference mode trained_model = my_ml_model . initialize () # Switch off specific layers/parts of the model that behave # differently during training and inference. # This may have been done by the user already, so just make sure here. trained_model . eval () # ===================================================== # Prepare dummy input and check model runs # ===================================================== # FPTLIB-TODO # Generate a dummy input Tensor `dummy_input` to the model of appropriate size. # This example assumes two inputs of size (512x40) and (512x1) trained_model_dummy_input_1 = torch . ones (( 512 , 40 ), dtype = torch . float64 ) trained_model_dummy_input_2 = torch . ones (( 512 , 1 ), dtype = torch . float64 ) # FPTLIB-TODO # Uncomment the following lines to save for inference on GPU (rather than CPU): # device = torch.device('cuda') # trained_model = trained_model.to(device) # trained_model.eval() # trained_model_dummy_input_1 = trained_model_dummy_input_1.to(device) # trained_model_dummy_input_2 = trained_model_dummy_input_2.to(device) # FPTLIB-TODO # Run model for dummy inputs # If something isn't working This will generate an error trained_model_dummy_output = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) # ===================================================== # Save model # ===================================================== # FPTLIB-TODO # Set the name of the file you want to save the torchscript model to: saved_ts_filename = \"saved_model.pt\" # FPTLIB-TODO # Save the pytorch model using either scripting (recommended where possible) or tracing # ----------- # Scripting # ----------- script_to_torchscript ( trained_model , filename = saved_ts_filename ) # ----------- # Tracing # ----------- # trace_to_torchscript(trained_model, trained_model_dummy_input, filename=saved_ts_filename) # ===================================================== # Check model saved OK # ===================================================== # Load torchscript and run model as a test # FPTLIB-TODO # Scale inputs as above and, if required, move inputs and mode to GPU trained_model_dummy_input_1 = 2.0 * trained_model_dummy_input_1 trained_model_dummy_input_2 = 2.0 * trained_model_dummy_input_2 trained_model_testing_output = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) ts_model = load_torchscript ( filename = saved_ts_filename ) ts_model_output = ts_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) if torch . all ( ts_model_output . eq ( trained_model_testing_output )): print ( \"Saved TorchScript model working as expected in a basic test.\" ) print ( \"Users should perform further validation as appropriate.\" ) else : raise RuntimeError ( \"Saved Torchscript model is not performing as expected. \\n \" \"Consider using scripting if you used tracing, or investigate further.\" )","tags":"","loc":"sourcefile/pt2ts.py.html"},{"title":"ctorch.cpp – FTorch","text":"Source Code #include <torch/script.h> #include <torch/torch.h> #include \"ctorch.h\" constexpr auto get_dtype ( torch_data_t dtype ) { switch ( dtype ) { case torch_kUInt8 : return torch :: kUInt8 ; case torch_kInt8 : return torch :: kInt8 ; case torch_kInt16 : return torch :: kInt16 ; case torch_kInt32 : return torch :: kInt32 ; case torch_kInt64 : return torch :: kInt64 ; case torch_kFloat16 : return torch :: kFloat16 ; case torch_kFloat32 : return torch :: kFloat32 ; case torch_kFloat64 : return torch :: kFloat64 ; default : std :: cerr << \"[ERROR]: unknown data type, setting to torch_kFloat32\" << std :: endl ; return torch :: kFloat32 ; } } constexpr auto get_device ( torch_device_t device ) { switch ( device ) { case torch_kCPU : return torch :: kCPU ; case torch_kCUDA : return torch :: kCUDA ; default : std :: cerr << \"[ERROR]: unknown device type, setting to torch_kCPU\" << std :: endl ; return torch :: kCPU ; } } torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ) { torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: zeros ( vshape , torch :: dtype ( get_dtype ( dtype )). device ( get_device ( device ))); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ) { torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: ones ( vshape , torch :: dtype ( get_dtype ( dtype )). device ( get_device ( device ))); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device ) { torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: empty ( vshape , torch :: dtype ( get_dtype ( dtype )). device ( get_device ( device ))); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } /* // Exposes the given data as a Tensor without taking ownership of the original // data torch_tensor_t torch_from_blob(void* data, int ndim, const int64_t* shape, torch_data_t dtype, torch_device_t device) { torch::Tensor* tensor = nullptr; try { // This doesn't throw if shape and dimensions are incompatible c10::IntArrayRef vshape(shape, ndim); tensor = new torch::Tensor; *tensor = torch::from_blob( data, vshape, torch::dtype(get_dtype(dtype)).device(get_device(device))); } catch (const torch::Error& e) { std::cerr << \"[ERROR]: \" << e.msg() << std::endl; delete tensor; exit(EXIT_FAILURE); } catch (const std::exception& e) { std::cerr << \"[ERROR]: \" << e.what() << std::endl; delete tensor; exit(EXIT_FAILURE); } return tensor; } */ // New version of torch_from_blob that uses strides torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device ) { torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); c10 :: IntArrayRef vstrides ( strides , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: from_blob ( data , vshape , vstrides , torch :: dtype ( get_dtype ( dtype )). device ( get_device ( device ))); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } void torch_tensor_print ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); std :: cout << * t << std :: endl ; } void torch_tensor_delete ( torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); delete t ; } torch_jit_script_module_t torch_jit_load ( const char * filename ) { torch :: jit :: script :: Module * module = nullptr ; try { module = new torch :: jit :: script :: Module ; * module = torch :: jit :: load ( filename ); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } return module ; } void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t output ) { // Here we cast the pointers we recieved in to Tensor objects auto model = static_cast < torch :: jit :: script :: Module *> ( module ); auto in = reinterpret_cast < torch :: Tensor * const *> ( inputs ); auto out = static_cast < torch :: Tensor *> ( output ); // Local IValue for checking we are passed types torch :: jit :: IValue LocalTensor ; // Generate a vector of IValues (placeholders for various Torch types) std :: vector < torch :: jit :: IValue > inputs_vec ; // Populate with Tensors pointed at by pointers // For each IValue check it is of Tensor type for ( int i = 0 ; i < nin ; ++ i ) { LocalTensor = * ( in [ i ]); if ( LocalTensor . isTensor ()) { inputs_vec . push_back ( LocalTensor ); } else { std :: cerr << \"[ERROR]: One of the inputs to torch_jit_module_forward is not a Tensor.\" << std :: endl ; exit ( EXIT_FAILURE ); } } try { // If for some reason the forward method does not return a Tensor it should // raise an error when trying to cast to a Tensor type std :: move ( * out ) = model -> forward ( inputs_vec ). toTensor (); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; exit ( EXIT_FAILURE ); } // FIXME: this should be the responsibility of the user if ( out -> is_cuda ()) torch :: cuda :: synchronize (); } void torch_jit_module_delete ( torch_jit_script_module_t module ) { auto m = reinterpret_cast < torch :: jit :: script :: Module *> ( module ); delete m ; }","tags":"","loc":"sourcefile/ctorch.cpp.html"},{"title":"Other documentation – FTorch","text":"Useful resources Useful resources The libtorch API","tags":"","loc":"page/index.html"},{"title":"FTorch License – FTorch","text":"MIT License Copyright (c) 2022 Institute of Computing for Climate Science Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.","tags":"","loc":"page/LICENSE.html"},{"title":"Installation and Build Process – FTorch","text":"Basic instructions CMake build options FTorch Library Other projects using CMake Building other projects with make Installation of FTorch is done by CMake. This is controlled by the CMakeLists.txt file in src/ . Basic instructions To build the library, first clone it from github to your local machine and then run: cd FTorch/src/\nmkdir build cd build Then invoke CMake with the Release build option, plus any other options as required\nfrom the table below in CMake build options (note: you will likely need to add some of these options to ): cmake .. -DCMAKE_BUILD_TYPE = Release Finally build and install the library: cmake --build . --target install --config Release CMake build options FTorch Library It is likely that you will need to provide at least the CMAKE_PREFIX_PATH flag. The following CMake flags are available and can be passed as arguments through -D<Option>=<Value> : Option Value Description CMAKE_Fortran_COMPILER ifort / gfortran Specify a Fortran compiler to build the library with. This should match the Fortran compiler you're using to build the code you are calling this library from. CMAKE_C_COMPILER icc / gcc Specify a C compiler to build the library with CMAKE_CXX_COMPILER icpc / g++ Specify a C++ compiler to build the library with CMAKE_PREFIX_PATH </path/to/libTorch/> Location of Torch installation 1 CMAKE_INSTALL_PREFIX </path/to/install/lib/at/> Location at which the library files should be installed. By default this is /usr/local CMAKE_BUILD_TYPE Release / Debug Specifies build type. The default is Debug , use Release for production code ENABLE_CUDA TRUE / FALSE Specifies whether to check for and enable CUDA 2 1 The path to the Torch installation needs to allow cmake to locate the relevant Torch cmake files. If Torch has been installed as libtorch then this should be the absolute path to the unzipped libtorch distribution.\n      If Torch has been installed as PyTorch in a python venv (virtual environment) ,\n      e.g. with pip install torch , then this should be </path/to/venv/>lib/python<3.xx>/site-packages/torch/ . 2 This is often overridden by PyTorch. When installing with pip, the index-url flag can be used to ensure a CPU or GPU only version is installed, e.g. pip install torch --index-url https://download.pytorch.org/whl/cpu or pip install torch --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8). URLs for alternative versions can be found here . For example, to build on a unix system using the gnu compilers and install to $HOME/FTorchbin/ we would need to run: cmake .. -DCMAKE_BUILD_TYPE = Release -DCMAKE_Fortran_COMPILER = gfortran -DCMAKE_C_COMPILER = icc -DCMAKE_CXX_COMPILER = icpc -DCMAKE_PREFIX_PATH = /path/to/venv/lib/python3.11/site-packages/torch/ -DCMAKE_INSTALL_PREFIX = ~/FTorchbin Once this completes you should be able to generate the code and install using: cmake --build . --target install --config Release or, if you want to separate these into two steps: cmake --build .\ncmake --install . --config Release Note: If you are using cmake<3.15 then you will need to build and install separately\nusing the make system specific commands.\nFor example, if using make on UNIX this would be: make\nmake install Installation will place the following directories at the install location: CMAKE_INSTALL_PREFIX/include/ - contains C header and Fortran mod files CMAKE_INSTALL_PREFIX/lib64/ - contains cmake directory and .so files Note: In a Windows environment this will require administrator privileges for the default install location. Other projects using CMake We generally advise building projects that make use of FTorch with CMake where possible. If doing this you need to include the following in the CMakeLists.txt file to\nfind the FTorch installation and link it to the executable. find_package ( FTorch ) target_link_libraries ( <executable> PRIVATE FTorch::ftorch ) message ( STATUS \"Building with Fortran PyTorch coupling\" ) You will then need to use the -DFTorch_DIR=</path/to/install/location> flag\nwhen running cmake. Building other projects with make To build a project with make you need to include the FTorch library when compiling\nand link the executable against it. To compile with make add the following compiler flag when compiling files that\nuse ftorch: FCFLAGS += - I < path / to / install / location >/ include / ftorch When compiling the final executable add the following link flag: LDFLAGS += -L<path/to/install/location>/lib64 -lftorch You may also need to add the location of the .so files to your LD_LIBRARY_PATH unless installing in a default location: export LD_LIBRARY_PATH = $ LD_LIBRARY_PATH : < path / to / installation >/ lib64","tags":"","loc":"page/cmake.html"},{"title":"Examples – FTorch","text":"Generic example Worked examples 1) Simple 2) Resnet 3) Generic example Worked examples 1) Simple 2) Resnet 3)","tags":"","loc":"page/examples.html"},{"title":"GPU Support – FTorch","text":"GPU Support GPU Support In order to run a model on GPU, two main changes are required: 1) When saving your TorchScript model, ensure that it is on the GPU.\nFor example, when using pt2ts.py , this can be done by\nuncommenting the following lines: device = torch . device ( 'cuda' ) trained_model = trained_model . to ( device ) trained_model . eval () trained_model_dummy_input_1 = trained_model_dummy_input_1 . to ( device ) trained_model_dummy_input_2 = trained_model_dummy_input_2 . to ( device ) Note: this also moves the dummy input tensors to the GPU. This is not necessary for\nsaving the model, but the tensors must also be on the GPU to test that the models runs. 2) When calling torch_tensor_from_blob in Fortran, the device for the input tensor(s),\n   but not the output tensor(s), should be set to torch_kCUDA , rather than torch_kCPU . This ensures that the inputs are on the same device as the model.","tags":"","loc":"page/gpu.html"},{"title":"When to transpose data – FTorch","text":"Introduction - row- vs. column-major Why does this matter? What can we do? 1) Transpose before passing 2) Design nets to use transpose 3) Use the layout argument in torch_tensor_from_blob Advanced use Introduction - row- vs. column-major Astute users will note that Fortran is a column-major language whilst C, C++, and Python are row-major . This means that the matrix/tensor in Fortran will appear in contiguous memory on the computer as with the order of elements decided by moving down the columns before progressing in the\nrow dimension. In contrast, the same matrix/tensor defined in a row-major language will appear in\ncontiguous memory as reading along each row before progressing down the column dimension. Why does this matter? This matters for FTorch because a key feature is no-copy memory transfer between Fortran\nand Torch.\nTo do this the Fortran data that will be used in Torch is stored in memory and a pointer to the first\nelement, provided to Torch. Now, if Torch were to take this block of memory and interpret it as as a 2x2 matrix it\nwould be read in as which is the transpose of the\nmatrix we had in Fortran; likely not what we were expecting! This means we need to be careful when passing data to make sure that what we read in\nto our Torch net is correct as we expect. What can we do? There are a few approaches we can take to address this. The first two of these are listed for conceptual purposes, whilst we advise handling\nthis in practice by using the layout argument presented in 3) below . 1) Transpose before passing As seen from the above example, writing out from Fortran and reading directly in to\nTorch results in us recieving the transpose. Therefore we could transpose out Fortran data immediately before passing it to Torch.\nAs a result we will read in to Torch indexed the same as in Fortran pre-transposition. For arrays of dimension 2 this can be done using the intrinsic transpose() function. For larger arrays we are required to use the 'reshape()' intrinsic to swap\nthe order of the indices.\nTODO: Example for 3 or 3D matrix We would, of course, need to remember to transpose/reshape any output of the model\nas required. However, the transposition process involves creating a copy of the Fortran data.\nFor large matrices/tensors this can become expensive.\nIt would be better if we can pass data without having to transpose beforehand. 2) Design nets to use transpose Alternatively we could design our net to use as its input tensor meaning we can simply write from Fortran and read to Torch. However, this requires foresight and may not be intuitive - we would like to be indexing\ndata in the same way in both Fortran and Torch.\nNot doing so could leave us open to introfucing bugs. 3) Use the layout argument in torch_tensor_from_blob In the documentation for torch_tensor_from_blob there is a layout argument. This tells us how data output by Fortran should be read by Torch. TODO: Finish this\npassing layout = [1, 2] means that the data will be read in the correct indices by\nTorch. Tells us which order to read the indices in.\ni.e. [1, 2] will read i then j . Advanced use Those experienced with C will perhaps have noticed that there are further freedoms\navailable beyond those presented above. [WIP] Always stride, or is there a transpose tradeoff?","tags":"","loc":"page/transposing.html"},{"title":"Troubleshooting – FTorch","text":"If you are experiencing problems building or using FTorch please see below for guidance on common problems. Windows Visual Studio MinGW Windows If possible we recommend using the Windows Subsystem for Linux (WSL) to build the library.\nIn this case the build process is the same as for a Linux environment. If you need Visual Studio Use Visual Studio and the Intel Fortran Compiler In this case you must install Visual Studio Intel OneAPI Base and HPC toolkit (ensure that the Intel Fortran compiler and VS integration is selected). You should then be able to build from CMD following the MinGW It may be tempting to build on Windows using MinGW.\nHowever, libtorch does not currently support MinGW .\nInstead please build using Visual Studio and the intel fortran compiler (ifort) as\ndetailed in the project README.","tags":"","loc":"page/troubleshooting.html"}]}