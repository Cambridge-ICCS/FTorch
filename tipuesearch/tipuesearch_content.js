var tipuesearch = {"pages":[{"title":" FTorch ","text":"FTorch Brief description Presentations License Projects using FTorch Brief description It is desirable to be able to run machine learning (ML) models directly in Fortran.\nML models are often trained in some other language (say, Python) using a popular frameworks (say, PyTorch) and saved.\nWe want to run inference on this model without having to call a Python executable.\nTo achieve this we use the existing Torch C++ interface, libtorch. FTorch provides a library enabling a user to directly couple their PyTorch models to Fortran code.\nThere are also installation instructions for the library and examples of performing coupling. We support running on both CPU and GPU, and have tested the library on UNIX and Windows based operating systems Presentations The following presentations contain information about FTorch: Reducing the overheads for coupling PyTorch machine learning models to Fortran ML & DL Seminars, LSCE, IPSL, Paris - November 2023 Slides - Recording Reducing the Overhead of Coupled Machine Learning Models between Python and Fortran RSECon23, Swansea - September 2023 Slides - Recording License The FTorch source code, related files and documentation are\ndistributed under an MIT License which can be viewed here . Projects using FTorch The following projects make use of FTorch. If you use our library in your work please let us know. M2LInES CAM-ML \\\n  Using FTorch to couple a neural net parameterisation of convection to the CAM\n  atmospheric model in CESM. DataWave CAM-GW \\\n  Using FTorch to couple neural net parameterisations of gravity waves to the CAM\n  atmospheric model in CESM. MiMA Machine Learning \\\n  Using FTorch to couple a neural net parameterisation of gravity waves to the MiMA\n  atmospheric model. Developer Info ICCS Cambridge","tags":"home","loc":"index.html"},{"title":"torch_module – FTorch ","text":"type, public :: torch_module Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net module in memory Source Code type torch_module type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net module in memory end type torch_module","tags":"","loc":"type/torch_module.html"},{"title":"torch_tensor – FTorch ","text":"type, public :: torch_tensor Type for holding a Torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Source Code type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory end type torch_tensor","tags":"","loc":"type/torch_tensor.html"},{"title":"torch_module_load – FTorch","text":"public  function torch_module_load(filename, device_type, device_index, requires_grad_opt, is_training_opt) result(module) Uses iso_c_binding Loads a TorchScript module (pre-trained PyTorch model saved with TorchScript) Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: filename Filename of TorchScript module integer(kind=c_int), intent(in), optional :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor logical, intent(in), optional :: is_training_opt Whether gradients need to be computed for the created tensor Return Value type( torch_module ) Returned deserialized module Source Code function torch_module_load ( filename , device_type , device_index , requires_grad_opt , is_training_opt ) result ( module ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_null_char character ( * ), intent ( in ) :: filename !! Filename of TorchScript module integer ( c_int ), optional , intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor logical , optional , intent ( in ) :: is_training_opt !! Whether gradients need to be computed for the created tensor type ( torch_module ) :: module !! Returned deserialized module integer ( c_int ) :: device_type_value integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor logical :: is_training !! Whether the model is being trained, rather than evaluated interface function torch_jit_load_c ( filename , device_type , device_index , requires_grad , is_training ) result ( module ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_bool , c_char , c_int , c_ptr character ( c_char ), intent ( in ) :: filename ( * ) integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad logical ( c_bool ), value , intent ( in ) :: is_training type ( c_ptr ) :: module end function torch_jit_load_c end interface ! Process optional arguments if ( present ( device_type )) then device_type_value = device_type else device_type_value = torch_kCPU endif if ( present ( device_index )) then device_index_value = device_index else if ( device_type_value == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if if (. not . present ( is_training_opt )) then is_training = . false . else is_training = is_training_opt end if ! Need to append c_null_char at end of filename module % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char , & device_type_value , device_index_value , & logical ( requires_grad , c_bool ), & logical ( is_training , c_bool )) end function torch_module_load","tags":"","loc":"proc/torch_module_load.html"},{"title":"torch_tensor_from_array_int16_1d – FTorch","text":"public  function torch_tensor_from_array_int16_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int16_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_1d","tags":"","loc":"proc/torch_tensor_from_array_int16_1d.html"},{"title":"torch_tensor_from_array_int16_2d – FTorch","text":"public  function torch_tensor_from_array_int16_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int16_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_2d","tags":"","loc":"proc/torch_tensor_from_array_int16_2d.html"},{"title":"torch_tensor_from_array_int16_3d – FTorch","text":"public  function torch_tensor_from_array_int16_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int16_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_3d","tags":"","loc":"proc/torch_tensor_from_array_int16_3d.html"},{"title":"torch_tensor_from_array_int16_4d – FTorch","text":"public  function torch_tensor_from_array_int16_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int16_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_4d","tags":"","loc":"proc/torch_tensor_from_array_int16_4d.html"},{"title":"torch_tensor_from_array_int32_1d – FTorch","text":"public  function torch_tensor_from_array_int32_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int32_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_1d","tags":"","loc":"proc/torch_tensor_from_array_int32_1d.html"},{"title":"torch_tensor_from_array_int32_2d – FTorch","text":"public  function torch_tensor_from_array_int32_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int32_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_2d","tags":"","loc":"proc/torch_tensor_from_array_int32_2d.html"},{"title":"torch_tensor_from_array_int32_3d – FTorch","text":"public  function torch_tensor_from_array_int32_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int32_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_3d","tags":"","loc":"proc/torch_tensor_from_array_int32_3d.html"},{"title":"torch_tensor_from_array_int32_4d – FTorch","text":"public  function torch_tensor_from_array_int32_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int32_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_4d","tags":"","loc":"proc/torch_tensor_from_array_int32_4d.html"},{"title":"torch_tensor_from_array_int64_1d – FTorch","text":"public  function torch_tensor_from_array_int64_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int64_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_1d","tags":"","loc":"proc/torch_tensor_from_array_int64_1d.html"},{"title":"torch_tensor_from_array_int64_2d – FTorch","text":"public  function torch_tensor_from_array_int64_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int64_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_2d","tags":"","loc":"proc/torch_tensor_from_array_int64_2d.html"},{"title":"torch_tensor_from_array_int64_3d – FTorch","text":"public  function torch_tensor_from_array_int64_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int64_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_3d","tags":"","loc":"proc/torch_tensor_from_array_int64_3d.html"},{"title":"torch_tensor_from_array_int64_4d – FTorch","text":"public  function torch_tensor_from_array_int64_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int64_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_4d","tags":"","loc":"proc/torch_tensor_from_array_int64_4d.html"},{"title":"torch_tensor_from_array_int8_1d – FTorch","text":"public  function torch_tensor_from_array_int8_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int8_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_1d","tags":"","loc":"proc/torch_tensor_from_array_int8_1d.html"},{"title":"torch_tensor_from_array_int8_2d – FTorch","text":"public  function torch_tensor_from_array_int8_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int8_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_2d","tags":"","loc":"proc/torch_tensor_from_array_int8_2d.html"},{"title":"torch_tensor_from_array_int8_3d – FTorch","text":"public  function torch_tensor_from_array_int8_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int8_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_3d","tags":"","loc":"proc/torch_tensor_from_array_int8_3d.html"},{"title":"torch_tensor_from_array_int8_4d – FTorch","text":"public  function torch_tensor_from_array_int8_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_int8_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_4d","tags":"","loc":"proc/torch_tensor_from_array_int8_4d.html"},{"title":"torch_tensor_from_array_real32_1d – FTorch","text":"public  function torch_tensor_from_array_real32_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real32_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_1d","tags":"","loc":"proc/torch_tensor_from_array_real32_1d.html"},{"title":"torch_tensor_from_array_real32_2d – FTorch","text":"public  function torch_tensor_from_array_real32_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real32_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_2d","tags":"","loc":"proc/torch_tensor_from_array_real32_2d.html"},{"title":"torch_tensor_from_array_real32_3d – FTorch","text":"public  function torch_tensor_from_array_real32_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real32_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_3d","tags":"","loc":"proc/torch_tensor_from_array_real32_3d.html"},{"title":"torch_tensor_from_array_real32_4d – FTorch","text":"public  function torch_tensor_from_array_real32_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real32_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_4d","tags":"","loc":"proc/torch_tensor_from_array_real32_4d.html"},{"title":"torch_tensor_from_array_real64_1d – FTorch","text":"public  function torch_tensor_from_array_real64_1d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real64_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_1d","tags":"","loc":"proc/torch_tensor_from_array_real64_1d.html"},{"title":"torch_tensor_from_array_real64_2d – FTorch","text":"public  function torch_tensor_from_array_real64_2d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real64_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_2d","tags":"","loc":"proc/torch_tensor_from_array_real64_2d.html"},{"title":"torch_tensor_from_array_real64_3d – FTorch","text":"public  function torch_tensor_from_array_real64_3d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real64_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_3d","tags":"","loc":"proc/torch_tensor_from_array_real64_3d.html"},{"title":"torch_tensor_from_array_real64_4d – FTorch","text":"public  function torch_tensor_from_array_real64_4d(data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Uses iso_fortran_env iso_c_binding Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_array_real64_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_4d","tags":"","loc":"proc/torch_tensor_from_array_real64_4d.html"},{"title":"torch_tensor_from_blob – FTorch","text":"public  function torch_tensor_from_blob(data, ndims, tensor_shape, layout, dtype, device_type, device_index, requires_grad_opt) result(tensor) Uses iso_c_binding Exposes the given data as a tensor without taking ownership of the original data.\n This routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_from_blob ( data , ndims , tensor_shape , layout , dtype , & device_type , device_index , & requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_from_blob","tags":"","loc":"proc/torch_tensor_from_blob.html"},{"title":"torch_tensor_get_device_index – FTorch","text":"public  function torch_tensor_get_device_index(tensor) result(device_index) Uses iso_c_binding Determines the device index of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Return Value integer(kind=c_int) Device index of tensor Source Code function torch_tensor_get_device_index ( tensor ) result ( device_index ) use , intrinsic :: iso_c_binding , only : c_int type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor integer ( c_int ) :: device_index !! Device index of tensor interface function torch_tensor_get_device_index_c ( tensor ) result ( device_index ) & bind ( c , name = 'torch_tensor_get_device_index' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: device_index end function torch_tensor_get_device_index_c end interface device_index = torch_tensor_get_device_index_c ( tensor % p ) end function torch_tensor_get_device_index","tags":"","loc":"proc/torch_tensor_get_device_index.html"},{"title":"torch_tensor_ones – FTorch","text":"public  function torch_tensor_ones(ndims, tensor_shape, dtype, device_type, device_index, requires_grad_opt) result(tensor) Uses iso_c_binding Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_ones ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_ones_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_ones","tags":"","loc":"proc/torch_tensor_ones.html"},{"title":"torch_tensor_zeros – FTorch","text":"public  function torch_tensor_zeros(ndims, tensor_shape, dtype, device_type, device_index, requires_grad_opt) result(tensor) Uses iso_c_binding Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Source Code function torch_tensor_zeros ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_zeros_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_zeros","tags":"","loc":"proc/torch_tensor_zeros.html"},{"title":"torch_module_delete – FTorch","text":"public  subroutine torch_module_delete(module) Deallocates a TorchScript module Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module to deallocate Source Code subroutine torch_module_delete ( module ) type ( torch_module ), intent ( in ) :: module !! Module to deallocate interface subroutine torch_jit_module_delete_c ( module ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: module end subroutine torch_jit_module_delete_c end interface call torch_jit_module_delete_c ( module % p ) end subroutine torch_module_delete","tags":"","loc":"proc/torch_module_delete.html"},{"title":"torch_module_forward – FTorch","text":"public  subroutine torch_module_forward(module, input_tensors, n_inputs, output_tensor, requires_grad_opt) Uses iso_c_binding Performs a forward pass of the module with the input tensors Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors integer(kind=c_int) :: n_inputs type( torch_tensor ), intent(in) :: output_tensor Returned output tensors logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Source Code subroutine torch_module_forward ( module , input_tensors , n_inputs , output_tensor , requires_grad_opt ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int , c_loc type ( torch_module ), intent ( in ) :: module !! Module type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ) :: output_tensor !! Returned output tensors logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: n_inputs logical :: requires_grad !! Whether gradients need to be computed for the created tensor integer :: i type ( c_ptr ), dimension ( n_inputs ), target :: input_ptrs interface subroutine torch_jit_module_forward_c ( module , input_tensors , n_inputs , & output_tensor , requires_grad ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int type ( c_ptr ), value , intent ( in ) :: module type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensor logical ( c_bool ), value , intent ( in ) :: requires_grad end subroutine torch_jit_module_forward_c end interface if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do call torch_jit_module_forward_c ( module % p , c_loc ( input_ptrs ), n_inputs , & output_tensor % p , & logical ( requires_grad , c_bool )) end subroutine torch_module_forward","tags":"","loc":"proc/torch_module_forward.html"},{"title":"torch_tensor_delete – FTorch","text":"public  subroutine torch_tensor_delete(tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Source Code subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete","tags":"","loc":"proc/torch_tensor_delete.html"},{"title":"torch_tensor_print – FTorch","text":"public  subroutine torch_tensor_print(tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Source Code subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print","tags":"","loc":"proc/torch_tensor_print.html"},{"title":"torch_from_blob_c – FTorch","text":"interface public  function torch_from_blob_c(data, ndims, tensor_shape, strides, dtype, device_type, device_index, requires_grad) result(tensor_p) bind(c, name = 'torch_from_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: data integer(kind=c_int), intent(in), value :: ndims integer(kind=c_int64_t), intent(in) :: tensor_shape (*) integer(kind=c_int64_t), intent(in) :: strides (*) integer(kind=c_int), intent(in), value :: dtype integer(kind=c_int), intent(in), value :: device_type integer(kind=c_int), intent(in), value :: device_index logical(kind=c_bool), intent(in), value :: requires_grad Return Value type(c_ptr)","tags":"","loc":"interface/torch_from_blob_c.html"},{"title":"torch_tensor_from_array – FTorch","text":"public interface torch_tensor_from_array Interface for directing torch_tensor_from_array to possible input types and ranks Module Procedures public  function torch_tensor_from_array_int8_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor","tags":"","loc":"interface/torch_tensor_from_array.html"},{"title":"ftorch – FTorch","text":"Main module for FTorch containing types and procedures.\n Generated from ftorch.fypp using the fypp Fortran preprocessor . License FTorch is released under an MIT license.\n   See the LICENSE file for details. Uses iso_fortran_env iso_c_binding Enumerations enum, bind(c) Enumerators enumerator :: torch_kUInt8 = 0 enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 Description Enumerator for Torch data types From c_torch.h (torch_data_t) Note that 0 torch_kUInt8 and 5 torch_kFloat16 are not sypported in Fortran enum, bind(c) Enumerators enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 Description Enumerator for Torch devices From c_torch.h (torch_device_t) Interfaces interface public  function torch_from_blob_c(data, ndims, tensor_shape, strides, dtype, device_type, device_index, requires_grad) result(tensor_p) bind(c, name = 'torch_from_blob') Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in), value :: data integer(kind=c_int), intent(in), value :: ndims integer(kind=c_int64_t), intent(in) :: tensor_shape (*) integer(kind=c_int64_t), intent(in) :: strides (*) integer(kind=c_int), intent(in), value :: dtype integer(kind=c_int), intent(in), value :: device_type integer(kind=c_int), intent(in), value :: device_index logical(kind=c_bool), intent(in), value :: requires_grad Return Value type(c_ptr) public        interface torch_tensor_from_array Interface for directing torch_tensor_from_array to possible input types and ranks public  function torch_tensor_from_array_int8_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Derived Types type, public :: torch_module Type for holding a torch neural net (nn.Module). Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the neural net module in memory type, public :: torch_tensor Type for holding a Torch tensor. Components Type Visibility Attributes Name Initial type(c_ptr), public :: p = c_null_ptr pointer to the tensor in memory Functions public  function torch_module_load (filename, device_type, device_index, requires_grad_opt, is_training_opt) result(module) Loads a TorchScript module (pre-trained PyTorch model saved with TorchScript) Arguments Type Intent Optional Attributes Name character(len=*), intent(in) :: filename Filename of TorchScript module integer(kind=c_int), intent(in), optional :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor logical, intent(in), optional :: is_training_opt Whether gradients need to be computed for the created tensor Return Value type( torch_module ) Returned deserialized module public  function torch_tensor_from_array_int16_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int16_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int16 Arguments Type Intent Optional Attributes Name integer(kind=int16), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int32 Arguments Type Intent Optional Attributes Name integer(kind=int32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int64 Arguments Type Intent Optional Attributes Name integer(kind=int64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_int8_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type int8 Arguments Type Intent Optional Attributes Name integer(kind=int8), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real32_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real32 Arguments Type Intent Optional Attributes Name real(kind=real32), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_1d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 1 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:) Input data that tensor will point at integer, intent(in) :: layout (1) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_2d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 2 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:) Input data that tensor will point at integer, intent(in) :: layout (2) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_3d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 3 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:) Input data that tensor will point at integer, intent(in) :: layout (3) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_array_real64_4d (data_in, layout, c_device_type, device_index, requires_grad_opt) result(tensor) Return a Torch tensor pointing to data_in array of rank 4 containing data of type real64 Arguments Type Intent Optional Attributes Name real(kind=real64), intent(in), target :: data_in (:,:,:,:) Input data that tensor will point at integer, intent(in) :: layout (4) Control order of indices integer(kind=c_int), intent(in) :: c_device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_from_blob (data, ndims, tensor_shape, layout, dtype, device_type, device_index, requires_grad_opt) result(tensor) Exposes the given data as a tensor without taking ownership of the original data.\n This routine will take an (i, j, k) array and return an (k, j, i) tensor. Arguments Type Intent Optional Attributes Name type(c_ptr), intent(in) :: data Pointer to data integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: layout (*) Layout for strides for accessing data integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_get_device_index (tensor) result(device_index) Determines the device index of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor Return Value integer(kind=c_int) Device index of tensor public  function torch_tensor_ones (ndims, tensor_shape, dtype, device_type, device_index, requires_grad_opt) result(tensor) Returns a tensor filled with the scalar value 1. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor public  function torch_tensor_zeros (ndims, tensor_shape, dtype, device_type, device_index, requires_grad_opt) result(tensor) Returns a tensor filled with the scalar value 0. Arguments Type Intent Optional Attributes Name integer(kind=c_int), intent(in) :: ndims Number of dimensions of the tensor integer(kind=c_int64_t), intent(in) :: tensor_shape (*) Shape of the tensor integer(kind=c_int), intent(in) :: dtype Data type of the tensor integer(kind=c_int), intent(in) :: device_type Device type the tensor will live on ( torch_kCPU or torch_kCUDA ) integer(kind=c_int), intent(in), optional :: device_index device index to use for torch_kCUDA case logical(kind=c_bool), intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor Return Value type( torch_tensor ) Returned tensor Subroutines public  subroutine torch_module_delete (module) Deallocates a TorchScript module Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module to deallocate public  subroutine torch_module_forward (module, input_tensors, n_inputs, output_tensor, requires_grad_opt) Performs a forward pass of the module with the input tensors Arguments Type Intent Optional Attributes Name type( torch_module ), intent(in) :: module Module type( torch_tensor ), intent(in), dimension(:) :: input_tensors Array of Input tensors integer(kind=c_int) :: n_inputs type( torch_tensor ), intent(in) :: output_tensor Returned output tensors logical, intent(in), optional :: requires_grad_opt Whether gradients need to be computed for the created tensor public  subroutine torch_tensor_delete (tensor) Deallocates a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor public  subroutine torch_tensor_print (tensor) Prints the contents of a tensor. Arguments Type Intent Optional Attributes Name type( torch_tensor ), intent(in) :: tensor Input tensor","tags":"","loc":"module/ftorch.html"},{"title":"ftorch.f90 – FTorch","text":"Source Code !| Main module for FTorch containing types and procedures. !  Generated from `ftorch.fypp` using the [fypp Fortran preprocessor](https://fypp.readthedocs.io/en/stable/index.html). ! !  * License !    FTorch is released under an MIT license. !    See the [LICENSE](https://github.com/Cambridge-ICCS/FTorch/blob/main/LICENSE) !    file for details. module ftorch use , intrinsic :: iso_c_binding , only : c_int , c_int8_t , c_int16_t , c_int32_t , c_int64_t , c_int64_t , & c_float , c_double , c_char , c_ptr , c_null_ptr use , intrinsic :: iso_fortran_env , only : int8 , int16 , int32 , int64 , real32 , real64 implicit none !> Type for holding a torch neural net (nn.Module). type torch_module type ( c_ptr ) :: p = c_null_ptr !! pointer to the neural net module in memory end type torch_module !> Type for holding a Torch tensor. type torch_tensor type ( c_ptr ) :: p = c_null_ptr !! pointer to the tensor in memory end type torch_tensor !| Enumerator for Torch data types !  From c_torch.h (torch_data_t) !  Note that 0 `torch_kUInt8` and 5 `torch_kFloat16` are not sypported in Fortran enum , bind ( c ) enumerator :: torch_kUInt8 = 0 ! not supported in Fortran enumerator :: torch_kInt8 = 1 enumerator :: torch_kInt16 = 2 enumerator :: torch_kInt32 = 3 enumerator :: torch_kInt64 = 4 enumerator :: torch_kFloat16 = 5 ! not supported in Fortran enumerator :: torch_kFloat32 = 6 enumerator :: torch_kFloat64 = 7 end enum !| Enumerator for Torch devices !  From c_torch.h (torch_device_t) enum , bind ( c ) enumerator :: torch_kCPU = 0 enumerator :: torch_kCUDA = 1 end enum !> Interface for directing `torch_tensor_from_array` to possible input types and ranks interface torch_tensor_from_array module procedure torch_tensor_from_array_int8_1d module procedure torch_tensor_from_array_int8_2d module procedure torch_tensor_from_array_int8_3d module procedure torch_tensor_from_array_int8_4d module procedure torch_tensor_from_array_int16_1d module procedure torch_tensor_from_array_int16_2d module procedure torch_tensor_from_array_int16_3d module procedure torch_tensor_from_array_int16_4d module procedure torch_tensor_from_array_int32_1d module procedure torch_tensor_from_array_int32_2d module procedure torch_tensor_from_array_int32_3d module procedure torch_tensor_from_array_int32_4d module procedure torch_tensor_from_array_int64_1d module procedure torch_tensor_from_array_int64_2d module procedure torch_tensor_from_array_int64_3d module procedure torch_tensor_from_array_int64_4d module procedure torch_tensor_from_array_real32_1d module procedure torch_tensor_from_array_real32_2d module procedure torch_tensor_from_array_real32_3d module procedure torch_tensor_from_array_real32_4d module procedure torch_tensor_from_array_real64_1d module procedure torch_tensor_from_array_real64_2d module procedure torch_tensor_from_array_real64_3d module procedure torch_tensor_from_array_real64_4d end interface interface function torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , & device_type , device_index , & requires_grad ) result ( tensor_p ) & bind ( c , name = 'torch_from_blob' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr ! Arguments type ( c_ptr ), value , intent ( in ) :: data integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int64_t ), intent ( in ) :: strides ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor_p end function torch_from_blob_c end interface contains !> Returns a tensor filled with the scalar value 0. function torch_tensor_zeros ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor interface function torch_zeros_c ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_zeros' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_zeros_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if tensor % p = torch_zeros_c ( ndims , tensor_shape , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_zeros !> Returns a tensor filled with the scalar value 1. function torch_tensor_ones ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor interface function torch_ones_c ( ndims , tensor_shape , dtype , device_type , device_index , requires_grad ) result ( tensor ) & bind ( c , name = 'torch_ones' ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr integer ( c_int ), value , intent ( in ) :: ndims integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) integer ( c_int ), value , intent ( in ) :: dtype integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad type ( c_ptr ) :: tensor end function torch_ones_c end interface ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if tensor % p = torch_ones_c ( ndims , tensor_shape , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_ones ! Torch Tensor API !| Exposes the given data as a tensor without taking ownership of the original data. !  This routine will take an (i, j, k) array and return an (k, j, i) tensor. function torch_tensor_from_blob ( data , ndims , tensor_shape , layout , dtype , & device_type , device_index , & requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_int64_t , c_ptr type ( c_ptr ), intent ( in ) :: data !! Pointer to data integer ( c_int ), intent ( in ) :: ndims !! Number of dimensions of the tensor integer ( c_int64_t ), intent ( in ) :: tensor_shape ( * ) !! Shape of the tensor integer ( c_int ), intent ( in ) :: layout ( * ) !! Layout for strides for accessing data integer ( c_int ), intent ( in ) :: dtype !! Data type of the tensor integer ( c_int ), intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical ( c_bool ), optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor type ( torch_tensor ) :: tensor !! Returned tensor integer ( c_int ) :: i !! loop index integer ( c_int64_t ) :: strides ( ndims ) !! Strides for accessing data integer ( c_int ) :: device_index_value !! device index used logical ( c_bool ) :: requires_grad !! Whether gradients need to be computed for the created tensor if (. not . present ( requires_grad_opt )) then requires_grad = logical (. false ., c_bool ) else requires_grad = requires_grad_opt end if strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * tensor_shape ( layout ( i - 1 )) end do ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif tensor % p = torch_from_blob_c ( data , ndims , tensor_shape , strides , dtype , device_type , device_index_value , requires_grad ) end function torch_tensor_from_blob !> Prints the contents of a tensor. subroutine torch_tensor_print ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_print_c ( tensor ) & bind ( c , name = 'torch_tensor_print' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_print_c end interface call torch_tensor_print_c ( tensor % p ) end subroutine torch_tensor_print !> Determines the device index of a tensor. function torch_tensor_get_device_index ( tensor ) result ( device_index ) use , intrinsic :: iso_c_binding , only : c_int type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor integer ( c_int ) :: device_index !! Device index of tensor interface function torch_tensor_get_device_index_c ( tensor ) result ( device_index ) & bind ( c , name = 'torch_tensor_get_device_index' ) use , intrinsic :: iso_c_binding , only : c_int , c_ptr type ( c_ptr ), value , intent ( in ) :: tensor integer ( c_int ) :: device_index end function torch_tensor_get_device_index_c end interface device_index = torch_tensor_get_device_index_c ( tensor % p ) end function torch_tensor_get_device_index !> Deallocates a tensor. subroutine torch_tensor_delete ( tensor ) type ( torch_tensor ), intent ( in ) :: tensor !! Input tensor interface subroutine torch_tensor_delete_c ( tensor ) & bind ( c , name = 'torch_tensor_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: tensor end subroutine torch_tensor_delete_c end interface call torch_tensor_delete_c ( tensor % p ) end subroutine torch_tensor_delete ! Torch Module API !> Loads a TorchScript module (pre-trained PyTorch model saved with TorchScript) function torch_module_load ( filename , device_type , device_index , requires_grad_opt , is_training_opt ) result ( module ) use , intrinsic :: iso_c_binding , only : c_bool , c_int , c_null_char character ( * ), intent ( in ) :: filename !! Filename of TorchScript module integer ( c_int ), optional , intent ( in ) :: device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor logical , optional , intent ( in ) :: is_training_opt !! Whether gradients need to be computed for the created tensor type ( torch_module ) :: module !! Returned deserialized module integer ( c_int ) :: device_type_value integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor logical :: is_training !! Whether the model is being trained, rather than evaluated interface function torch_jit_load_c ( filename , device_type , device_index , requires_grad , is_training ) result ( module ) & bind ( c , name = 'torch_jit_load' ) use , intrinsic :: iso_c_binding , only : c_bool , c_char , c_int , c_ptr character ( c_char ), intent ( in ) :: filename ( * ) integer ( c_int ), value , intent ( in ) :: device_type integer ( c_int ), value , intent ( in ) :: device_index logical ( c_bool ), value , intent ( in ) :: requires_grad logical ( c_bool ), value , intent ( in ) :: is_training type ( c_ptr ) :: module end function torch_jit_load_c end interface ! Process optional arguments if ( present ( device_type )) then device_type_value = device_type else device_type_value = torch_kCPU endif if ( present ( device_index )) then device_index_value = device_index else if ( device_type_value == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if if (. not . present ( is_training_opt )) then is_training = . false . else is_training = is_training_opt end if ! Need to append c_null_char at end of filename module % p = torch_jit_load_c ( trim ( adjustl ( filename )) // c_null_char , & device_type_value , device_index_value , & logical ( requires_grad , c_bool ), & logical ( is_training , c_bool )) end function torch_module_load !> Performs a forward pass of the module with the input tensors subroutine torch_module_forward ( module , input_tensors , n_inputs , output_tensor , requires_grad_opt ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int , c_loc type ( torch_module ), intent ( in ) :: module !! Module type ( torch_tensor ), intent ( in ), dimension (:) :: input_tensors !! Array of Input tensors type ( torch_tensor ), intent ( in ) :: output_tensor !! Returned output tensors logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor integer ( c_int ) :: n_inputs logical :: requires_grad !! Whether gradients need to be computed for the created tensor integer :: i type ( c_ptr ), dimension ( n_inputs ), target :: input_ptrs interface subroutine torch_jit_module_forward_c ( module , input_tensors , n_inputs , & output_tensor , requires_grad ) & bind ( c , name = 'torch_jit_module_forward' ) use , intrinsic :: iso_c_binding , only : c_bool , c_ptr , c_int type ( c_ptr ), value , intent ( in ) :: module type ( c_ptr ), value , intent ( in ) :: input_tensors integer ( c_int ), value , intent ( in ) :: n_inputs type ( c_ptr ), value , intent ( in ) :: output_tensor logical ( c_bool ), value , intent ( in ) :: requires_grad end subroutine torch_jit_module_forward_c end interface if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if ! Assign array of pointers to the input tensors do i = 1 , n_inputs input_ptrs ( i ) = input_tensors ( i )% p end do call torch_jit_module_forward_c ( module % p , c_loc ( input_ptrs ), n_inputs , & output_tensor % p , & logical ( requires_grad , c_bool )) end subroutine torch_module_forward !> Deallocates a TorchScript module subroutine torch_module_delete ( module ) type ( torch_module ), intent ( in ) :: module !! Module to deallocate interface subroutine torch_jit_module_delete_c ( module ) & bind ( c , name = 'torch_jit_module_delete' ) use , intrinsic :: iso_c_binding , only : c_ptr type ( c_ptr ), value , intent ( in ) :: module end subroutine torch_jit_module_delete_c end interface call torch_jit_module_delete_c ( module % p ) end subroutine torch_module_delete !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int8` function torch_tensor_from_array_int8_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int8` function torch_tensor_from_array_int8_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int8` function torch_tensor_from_array_int8_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int8` function torch_tensor_from_array_int8_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int8 ! inputs integer ( kind = int8 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt8 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int8_4d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int16` function torch_tensor_from_array_int16_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int16` function torch_tensor_from_array_int16_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int16` function torch_tensor_from_array_int16_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int16` function torch_tensor_from_array_int16_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int16 ! inputs integer ( kind = int16 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt16 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int16_4d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int32` function torch_tensor_from_array_int32_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int32` function torch_tensor_from_array_int32_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int32` function torch_tensor_from_array_int32_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int32` function torch_tensor_from_array_int32_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int32 ! inputs integer ( kind = int32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int32_4d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `int64` function torch_tensor_from_array_int64_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `int64` function torch_tensor_from_array_int64_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `int64` function torch_tensor_from_array_int64_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `int64` function torch_tensor_from_array_int64_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : int64 ! inputs integer ( kind = int64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kInt64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_int64_4d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `real32` function torch_tensor_from_array_real32_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `real32` function torch_tensor_from_array_real32_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `real32` function torch_tensor_from_array_real32_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `real32` function torch_tensor_from_array_real32_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real32 ! inputs real ( kind = real32 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat32 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real32_4d !> Return a Torch tensor pointing to data_in array of rank 1 containing data of type `real64` function torch_tensor_from_array_real64_1d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 1 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 1 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 1 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 1 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_1d !> Return a Torch tensor pointing to data_in array of rank 2 containing data of type `real64` function torch_tensor_from_array_real64_2d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 2 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 2 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 2 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 2 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_2d !> Return a Torch tensor pointing to data_in array of rank 3 containing data of type `real64` function torch_tensor_from_array_real64_3d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 3 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 3 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 3 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 3 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_3d !> Return a Torch tensor pointing to data_in array of rank 4 containing data of type `real64` function torch_tensor_from_array_real64_4d ( data_in , layout , c_device_type , device_index , requires_grad_opt ) result ( tensor ) use , intrinsic :: iso_c_binding , only : c_bool , c_float , c_int , c_int64_t , c_loc use , intrinsic :: iso_fortran_env , only : real64 ! inputs real ( kind = real64 ), intent ( in ), target :: data_in (:,:,:,:) !! Input data that tensor will point at integer , intent ( in ) :: layout ( 4 ) !! Control order of indices integer ( c_int ), intent ( in ) :: c_device_type !! Device type the tensor will live on (`torch_kCPU` or `torch_kCUDA`) integer ( c_int ), optional , intent ( in ) :: device_index !! device index to use for `torch_kCUDA` case logical , optional , intent ( in ) :: requires_grad_opt !! Whether gradients need to be computed for the created tensor ! output tensory type ( torch_tensor ) :: tensor !! Returned tensor ! local data integer ( c_int64_t ) :: c_tensor_shape ( 4 ) !! Shape of the tensor integer ( c_int ), parameter :: c_dtype = torch_kFloat64 !! Data type integer ( c_int64_t ) :: strides ( 4 ) !! Strides for accessing data integer ( c_int ), parameter :: ndims = 4 !! Number of dimension of input data integer :: i integer ( c_int ) :: device_index_value logical :: requires_grad !! Whether gradients need to be computed for the created tensor ! Process optional arguments if ( present ( device_index )) then device_index_value = device_index else if ( c_device_type == torch_kCPU ) then device_index_value = - 1 else device_index_value = 0 endif if (. not . present ( requires_grad_opt )) then requires_grad = . false . else requires_grad = requires_grad_opt end if c_tensor_shape = shape ( data_in ) strides ( layout ( 1 )) = 1 do i = 2 , ndims strides ( layout ( i )) = strides ( layout ( i - 1 )) * c_tensor_shape ( layout ( i - 1 )) end do tensor % p = torch_from_blob_c ( c_loc ( data_in ), ndims , c_tensor_shape , & strides , c_dtype , c_device_type , & device_index_value , & logical ( requires_grad , c_bool )) end function torch_tensor_from_array_real64_4d end module ftorch","tags":"","loc":"sourcefile/ftorch.f90.html"},{"title":"pt2ts.py – FTorch","text":"Source Code \"\"\"Load a PyTorch model and convert it to TorchScript.\"\"\" from typing import Optional import torch # FPTLIB-TODO # Add a module import with your model here: # This example assumes the model architecture is in an adjacent module `my_ml_model.py` import my_ml_model def script_to_torchscript ( model : torch . nn . Module , filename : Optional [ str ] = \"scripted_model.pt\" ) -> None : \"\"\" Save PyTorch model to TorchScript using scripting. Parameters ---------- model : torch.NN.Module a PyTorch model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved scripted_model = torch . jit . script ( model ) # print(scripted_model.code) scripted_model . save ( filename ) def trace_to_torchscript ( model : torch . nn . Module , dummy_input : torch . Tensor , filename : Optional [ str ] = \"traced_model.pt\" , ) -> None : \"\"\" Save PyTorch model to TorchScript using tracing. Parameters ---------- model : torch.NN.Module a PyTorch model dummy_input : torch.Tensor appropriate size Tensor to act as input to model filename : str name of file to save to \"\"\" # FIXME: torch.jit.optimize_for_inference() when PyTorch issue #81085 is resolved traced_model = torch . jit . trace ( model , dummy_input ) # traced_model.save(filename) frozen_model = torch . jit . freeze ( traced_model ) ## print(frozen_model.graph) ## print(frozen_model.code) frozen_model . save ( filename ) def load_torchscript ( filename : Optional [ str ] = \"saved_model.pt\" ) -> torch . nn . Module : \"\"\" Load a TorchScript from file. Parameters ---------- filename : str name of file containing TorchScript model \"\"\" model = torch . jit . load ( filename ) return model if __name__ == \"__main__\" : # ===================================================== # Load model and prepare for saving # ===================================================== # FPTLIB-TODO # Load a pre-trained PyTorch model # Insert code here to load your model as `trained_model`. # This example assumes my_ml_model has a method `initialize` to load # architecture, weights, and place in inference mode trained_model = my_ml_model . initialize () # Switch off specific layers/parts of the model that behave # differently during training and inference. # This may have been done by the user already, so just make sure here. trained_model . eval () # ===================================================== # Prepare dummy input and check model runs # ===================================================== # FPTLIB-TODO # Generate a dummy input Tensor `dummy_input` to the model of appropriate size. # This example assumes two inputs of size (512x40) and (512x1) trained_model_dummy_input_1 = torch . ones (( 512 , 40 ), dtype = torch . float64 ) trained_model_dummy_input_2 = torch . ones (( 512 , 1 ), dtype = torch . float64 ) # FPTLIB-TODO # Uncomment the following lines to save for inference on GPU (rather than CPU): # device = torch.device('cuda') # trained_model = trained_model.to(device) # trained_model.eval() # trained_model_dummy_input_1 = trained_model_dummy_input_1.to(device) # trained_model_dummy_input_2 = trained_model_dummy_input_2.to(device) # FPTLIB-TODO # Run model for dummy inputs # If something isn't working This will generate an error trained_model_dummy_output = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) # ===================================================== # Save model # ===================================================== # FPTLIB-TODO # Set the name of the file you want to save the torchscript model to: saved_ts_filename = \"saved_model.pt\" # FPTLIB-TODO # Save the PyTorch model using either scripting (recommended where possible) or tracing # ----------- # Scripting # ----------- script_to_torchscript ( trained_model , filename = saved_ts_filename ) # ----------- # Tracing # ----------- # trace_to_torchscript(trained_model, trained_model_dummy_input, filename=saved_ts_filename) # ===================================================== # Check model saved OK # ===================================================== # Load torchscript and run model as a test # FPTLIB-TODO # Scale inputs as above and, if required, move inputs and mode to GPU trained_model_dummy_input_1 = 2.0 * trained_model_dummy_input_1 trained_model_dummy_input_2 = 2.0 * trained_model_dummy_input_2 trained_model_testing_output = trained_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) ts_model = load_torchscript ( filename = saved_ts_filename ) ts_model_output = ts_model ( trained_model_dummy_input_1 , trained_model_dummy_input_2 , ) if torch . all ( ts_model_output . eq ( trained_model_testing_output )): print ( \"Saved TorchScript model working as expected in a basic test.\" ) print ( \"Users should perform further validation as appropriate.\" ) else : raise RuntimeError ( \"Saved Torchscript model is not performing as expected. \\n \" \"Consider using scripting if you used tracing, or investigate further.\" )","tags":"","loc":"sourcefile/pt2ts.py.html"},{"title":"ctorch.h – FTorch","text":"Source Code #ifndef C_TORCH_H #define C_TORCH_H #ifdef __cplusplus #define EXPORT_C extern \"C\" #else #define EXPORT_C #endif // Opaque pointer type alias for torch::jit::script::Module class typedef void * torch_jit_script_module_t ; // Opaque pointer type alias for at::Tensor typedef void * torch_tensor_t ; // Data types typedef enum { torch_kUInt8 , torch_kInt8 , torch_kInt16 , torch_kInt32 , torch_kInt64 , torch_kFloat16 , torch_kFloat32 , torch_kFloat64 } torch_data_t ; // Device types typedef enum { torch_kCPU , torch_kCUDA } torch_device_t ; // ===================================================================================== // Tensor API // ===================================================================================== /** * Function to generate a Torch Tensor of zeros * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to generate a Torch Tensor of ones * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to generate an empty Torch Tensor * @param number of dimensions of the Tensor * @param shape of the Tensor * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required */ EXPORT_C torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to create a Torch Tensor from memory location given extra information * @param pointer to the Tensor in memory * @param number of dimensions of the Tensor * @param shape of the Tensor * @param strides to take through data * @param data type of the elements of the Tensor * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required * @return Torch Tensor interpretation of the data pointed at */ EXPORT_C torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device_type , int device_index , const bool requires_grad ); /** * Function to print out a Torch Tensor * @param Torch Tensor to print */ EXPORT_C void torch_tensor_print ( const torch_tensor_t tensor ); /** * Function to determine the device index of a Torch Tensor * @param Torch Tensor to determine the device index of * @return device index of the Torch Tensor */ EXPORT_C int torch_tensor_get_device_index ( const torch_tensor_t tensor ); /** * Function to delete a Torch Tensor to clean up * @param Torch Tensor to delete */ EXPORT_C void torch_tensor_delete ( torch_tensor_t tensor ); // ===================================================================================== // Module API // ===================================================================================== /** * Function to load in a Torch model from a TorchScript file and store in a Torch Module * @param filename where TorchScript description of model is stored * @param device type used (cpu, CUDA, etc.) * @param device index for the CUDA case * @param whether gradient is required * @param whether model is being trained * @return Torch Module loaded in from file */ EXPORT_C torch_jit_script_module_t torch_jit_load ( const char * filename , const torch_device_t device_type , const int device_index , const bool requires_grad , const bool is_training ); /** * Function to run the `forward` method of a Torch Module * @param Torch Module containing the model * @param vector of Torch Tensors as inputs to the model * @param number of input Tensors in the input vector * @param the output Tensor from running the model * @param whether gradient is required */ EXPORT_C void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t output , const bool requires_grad ); /** * Function to delete a Torch Module to clean up * @param Torch Module to delete */ EXPORT_C void torch_jit_module_delete ( torch_jit_script_module_t module ); #endif /* C_TORCH_H*/","tags":"","loc":"sourcefile/ctorch.h.html"},{"title":"ctorch.cpp – FTorch","text":"Source Code #include <torch/script.h> #include <torch/torch.h> #include \"ctorch.h\" constexpr auto get_dtype ( torch_data_t dtype ) { switch ( dtype ) { case torch_kUInt8 : return torch :: kUInt8 ; case torch_kInt8 : return torch :: kInt8 ; case torch_kInt16 : return torch :: kInt16 ; case torch_kInt32 : return torch :: kInt32 ; case torch_kInt64 : return torch :: kInt64 ; case torch_kFloat16 : return torch :: kFloat16 ; case torch_kFloat32 : return torch :: kFloat32 ; case torch_kFloat64 : return torch :: kFloat64 ; default : std :: cerr << \"[WARNING]: unknown data type, setting to torch_kFloat32\" << std :: endl ; return torch :: kFloat32 ; } } const auto get_device ( torch_device_t device_type , int device_index ) { switch ( device_type ) { case torch_kCPU : if ( device_index != -1 ) { std :: cerr << \"[WARNING]: device index unused for CPU-only runs\" << std :: endl ; } return torch :: Device ( torch :: kCPU ); case torch_kCUDA : if ( device_index == -1 ) { std :: cerr << \"[WARNING]: device index unset, defaulting to 0\" << std :: endl ; device_index = 0 ; } if ( device_index >= 0 && device_index < torch :: cuda :: device_count ()) { return torch :: Device ( torch :: kCUDA , device_index ); } else { std :: cerr << \"[ERROR]: invalid device index \" << device_index << \" for device count \" << torch :: cuda :: device_count () << std :: endl ; exit ( EXIT_FAILURE ); } default : std :: cerr << \"[WARNING]: unknown device type, setting to torch_kCPU\" << std :: endl ; return torch :: Device ( torch :: kCPU ); } } void set_is_training ( torch_jit_script_module_t module , const bool is_training = false ) { auto model = static_cast < torch :: jit :: script :: Module *> ( module ); if ( is_training ) { model -> train (); } else { model -> eval (); } } torch_tensor_t torch_zeros ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: zeros ( vshape , torch :: dtype ( get_dtype ( dtype ))). to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_ones ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: ones ( vshape , torch :: dtype ( get_dtype ( dtype ))). to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } torch_tensor_t torch_empty ( int ndim , const int64_t * shape , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: empty ( vshape , torch :: dtype ( get_dtype ( dtype ))). to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } // Exposes the given data as a Tensor without taking ownership of the original // data torch_tensor_t torch_from_blob ( void * data , int ndim , const int64_t * shape , const int64_t * strides , torch_data_t dtype , torch_device_t device_type , int device_index = -1 , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: Tensor * tensor = nullptr ; try { // This doesn't throw if shape and dimensions are incompatible c10 :: IntArrayRef vshape ( shape , ndim ); c10 :: IntArrayRef vstrides ( strides , ndim ); tensor = new torch :: Tensor ; * tensor = torch :: from_blob ( data , vshape , vstrides , torch :: dtype ( get_dtype ( dtype ))). to ( get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete tensor ; exit ( EXIT_FAILURE ); } return tensor ; } void torch_tensor_print ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); std :: cout << * t << std :: endl ; } int torch_tensor_get_device_index ( const torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); return t -> device (). index (); } void torch_tensor_delete ( torch_tensor_t tensor ) { auto t = reinterpret_cast < torch :: Tensor *> ( tensor ); delete t ; } torch_jit_script_module_t torch_jit_load ( const char * filename , const torch_device_t device_type = torch_kCPU , const int device_index = -1 , const bool requires_grad = false , const bool is_training = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); torch :: jit :: script :: Module * module = nullptr ; try { module = new torch :: jit :: script :: Module ; * module = torch :: jit :: load ( filename , get_device ( device_type , device_index )); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; delete module ; exit ( EXIT_FAILURE ); } set_is_training ( module , is_training ); return module ; } void torch_jit_module_forward ( const torch_jit_script_module_t module , const torch_tensor_t * inputs , const int nin , torch_tensor_t output , const bool requires_grad = false ) { torch :: AutoGradMode enable_grad ( requires_grad ); // Here we cast the pointers we recieved in to Tensor objects auto model = static_cast < torch :: jit :: script :: Module *> ( module ); auto in = reinterpret_cast < torch :: Tensor * const *> ( inputs ); auto out = static_cast < torch :: Tensor *> ( output ); // Local IValue for checking we are passed types torch :: jit :: IValue LocalTensor ; // Generate a vector of IValues (placeholders for various Torch types) std :: vector < torch :: jit :: IValue > inputs_vec ; // Populate with Tensors pointed at by pointers // For each IValue check it is of Tensor type for ( int i = 0 ; i < nin ; ++ i ) { LocalTensor = * ( in [ i ]); if ( LocalTensor . isTensor ()) { inputs_vec . push_back ( LocalTensor ); } else { std :: cerr << \"[ERROR]: One of the inputs to torch_jit_module_forward is not a Tensor.\" << std :: endl ; exit ( EXIT_FAILURE ); } } try { // If for some reason the forward method does not return a Tensor it should // raise an error when trying to cast to a Tensor type std :: move ( * out ) = model -> forward ( inputs_vec ). toTensor (); } catch ( const torch :: Error & e ) { std :: cerr << \"[ERROR]: \" << e . msg () << std :: endl ; exit ( EXIT_FAILURE ); } catch ( const std :: exception & e ) { std :: cerr << \"[ERROR]: \" << e . what () << std :: endl ; exit ( EXIT_FAILURE ); } } void torch_jit_module_delete ( torch_jit_script_module_t module ) { auto m = reinterpret_cast < torch :: jit :: script :: Module *> ( module ); delete m ; }","tags":"","loc":"sourcefile/ctorch.cpp.html"},{"title":"User Guide – FTorch","text":"Please see the menu on the left for detailed documentation and user guides for using FTorch . Useful resources Useful resources The libtorch C++ API documentation","tags":"","loc":"page/index.html"},{"title":"FTorch License – FTorch","text":"MIT License Copyright (c) 2022 Institute of Computing for Climate Science Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.","tags":"","loc":"page/LICENSE.html"},{"title":"Installation and Build Process – FTorch","text":"Basic instructions CMake build options FTorch Library Other projects using CMake Building other projects with make Installation of FTorch is done by CMake. This is controlled by the CMakeLists.txt file in src/ . Basic instructions To build the library, first clone it from GitHub to your local machine and then run: cd FTorch/src/\nmkdir build\ncd build Then invoke CMake with the Release build option, plus any other options as required\nfrom the table below in CMake build options (note: you will likely need to add some of these options to enforce a consistent\nbuild on your machine): cmake .. -DCMAKE_BUILD_TYPE=Release Finally build and install the library using: cmake --build . --target install or, if you want to separate these steps: cmake --build .\ncmake --install . Note: if you are building on Windows please refer to the Windows install guidance as the process will\nlikely differ from the UNIX-based stsyems covered here. CMake build options FTorch Library It is likely that you will need to provide at least the CMAKE_PREFIX_PATH flag. The following CMake flags are available and can be passed as arguments through -D<Option>=<Value> : Option Value Description CMAKE_Fortran_COMPILER ifort / gfortran Specify a Fortran compiler to build the library with. This should match the Fortran compiler you're using to build the code you are calling this library from. 1 CMAKE_C_COMPILER icc / gcc Specify a C compiler to build the library with. 1 CMAKE_CXX_COMPILER icpc / g++ Specify a C++ compiler to build the library with. 1 CMAKE_PREFIX_PATH </path/to/libTorch/> Location of Torch installation 2 CMAKE_INSTALL_PREFIX </path/to/install/lib/at/> Location at which the library files should be installed. By default this is /usr/local CMAKE_BUILD_TYPE Release / Debug Specifies build type. The default is Debug , use Release for production code ENABLE_CUDA TRUE / FALSE Specifies whether to check for and enable CUDA 3 1 On Windows this may need to be the full path to the compiler if CMake\ncannot locate it by default. 2 The path to the Torch installation needs to allow CMake to locate the relevant Torch CMake files. If Torch has been installed as libtorch then this should be the absolute path to the unzipped libtorch distribution.\n      If Torch has been installed as PyTorch in a Python venv (virtual environment) ,\n      e.g. with pip install torch , then this should be </path/to/venv/>lib/python<3.xx>/site-packages/torch/ . 3 This is often overridden by PyTorch. When installing with pip, the index-url flag can be used to ensure a CPU or GPU only version is installed, e.g. pip install torch --index-url https://download.pytorch.org/whl/cpu or pip install torch --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8). URLs for alternative versions can be found here . For example, to build on a unix system using the gnu compilers and install to $HOME/FTorchbin/ we would need to run: cmake .. \\ - DCMAKE_BUILD_TYPE = Release \\ - DCMAKE_Fortran_COMPILER = gfortran \\ - DCMAKE_C_COMPILER = gcc \\ - DCMAKE_CXX_COMPILER = g ++ \\ - DCMAKE_PREFIX_PATH = / path / to / venv / lib / python3 . xx / site - packages / torch / \\ - DCMAKE_INSTALL_PREFIX = ~/ FTorchbin Once this completes you should be able to generate the code and install using: cmake --build . --target install Note: If you are using CMake < 3.15 then you will need to build and install separately\nusing the make system specific commands. For example, if using make on UNIX this would be: make\nmake install Installation will place the following directories at the install location: CMAKE_INSTALL_PREFIX/include/ - contains C header and Fortran mod files CMAKE_INSTALL_PREFIX/lib64/ - contains cmake directory and .so files Note: In a Windows environment this will require administrator privileges for the default install location. Other projects using CMake We generally advise building projects that make use of FTorch with CMake where possible. If doing this you need to include the following in the CMakeLists.txt file to\nfind the FTorch installation and link it to the executable. find_package ( FTorch ) target_link_libraries ( <executable> PRIVATE FTorch::ftorch ) message ( STATUS \"Building with Fortran PyTorch coupling\" ) You will then need to use the -DFTorch_DIR=</path/to/install/location> flag\nwhen running CMake. Building other projects with make To build a project with make you need to include the FTorch library when compiling\nand link the executable against it. To compile with make add the following compiler flag when compiling files that\nuse ftorch: FCFLAGS += - I < path / to / install / location >/ include / ftorch When compiling the final executable add the following link flag: LDFLAGS += -L<path/to/install/location>/lib64 -lftorch You may also need to add the location of the .so files to your LD_LIBRARY_PATH unless installing in a default location: export LD_LIBRARY_PATH = $ LD_LIBRARY_PATH : < path / to / installation >/ lib64","tags":"","loc":"page/cmake.html"},{"title":"Developer Guide – FTorch","text":"If you would like to contribute to the FTorch project, or modify the code at a deeper\nlevel, please see below for guidance. Getting involved Code of Conduct Extending the API Fortran source and Fypp git hook General guidelines Documentation Getting involved Contributions and collaborations are welcome. For bugs, feature requests, and clear suggestions for improvement please open an issue . If you have built something upon FTorch that would be useful to others, or can\naddress an open issue , please fork the repository and open a\npull request. Code of Conduct Everyone participating in the FTorch project, and in particular in the\nissue tracker, pull requests, and social media activity, is expected to treat other\npeople with respect and, more generally, to follow the guidelines articulated in the Python Community Code of Conduct . Extending the API If you have a Torch functionality that you wish to bring in from the C++ API to\nthe FTorch Fortran API the steps are generally as follows: Modify ctorch.cpp to create a C++ version of the function that accesses torch::<item> . Add the function to the header file ctorch.h Modify ftorch.fypp to create a Fortran version of the function\n  that binds to the version in ctorch.cpp . Details of C++ functionalities available to be wrapped can be found\nin the libtorch C++ API . As this is an open-source project we appreciate any contributions\nback from users that have extended the functionality.\nIf you have done something but don't know where to start with\nopen-source contributions please get in touch! * * Our preferred method of contact is via Github issues and discussions,\nbut if you are unfamiliar with this you can email ICCS asking for the FTorch developers. Fortran source and Fypp The Fortran source code for FTorch is contained in src/ftorch.f90 .\nHowever, this file should not be edited directly, but instead generated from src/ftorch.fypp .\nThis is a file that is set up to be run through the Fypp preprocessor.\nWe use this because we want to create a pleasant interface of single function calls.\nThe nature of Fortran means that this requires a lot of repeated combinations of\narray shapes and data types under interface structures.\nBy using Fypp we can generate these programatically. Fypp can be installed via pip: pip install fypp To generate the Fortran code run: fypp src/ftorch.fypp src/ftorch.f90 Note: Generally it would be advisable to provide only the .fypp source code to\nreduce duplication and confusion. However, because it is a relatively small file\nand many of our users wish to \"clone-and-go\" rather than develop, we provide both. Development should only take place in ftorch.fypp , however. git hook In order to streamline the process of uploading we provide a pre-commit hook in .githooks/pre-commit .\nThis will check that both the .fypp and .f90 files have been updated together in a\nsynchronous fashion before a commmit can take place.\nIf this does not happen then the second line of defence (GitHub continuous integration)\nwill fail following the commit. Use of the hook is not automatic and needs to be enabled by the developer\n(after they have inspected it and are happy with its contents).\nHooks can be enabled by placing them in the .git directory with the following commands: cp .githooks/pre-commit .git/hooks/\nchmod +x .git/pre-commit General guidelines Match optional argument defaults between Fortran, C, and C++ ( principle of least astonishment ). Handle torch::Error and std::exception in the C++ functions by catching and\n  printing to screen before exiting cleanly. Documentation The API documentation for FTorch is generated using FORD .\nFor detailed information refer to the FORD User Guide ,\nbut as a quick-start: !! is used to signify documentation. Documentation comes after whatever it is documenting (inline or subsequent line). Documentation can precede an item if designated using !> . FORD is pip installable: pip install ford To generate the documentation run: ford FTorch.md from the root of the repository. FTorch.md is the FORD index file, API documentation is automatically generated, and\nany further items are contained in pages/ as markdown files. Documentation of the C functions in ctorch.h is provided\nby Doxygen .","tags":"","loc":"page/developer.html"},{"title":"Examples – FTorch","text":"Generic example Overview of the interfacing process 1. Saving the model as TorchScript 2. Using the model from Fortran 3. Build the code CMake Make Running on GPUs Worked examples 1) SimpleNet 2) Resnet 3) MultiGPU Generic example Overview of the interfacing process In order to use FTorch users will typically need to follow these steps: Save a PyTorch model as TorchScript . Write Fortran using the FTorch bindings to use the model from within Fortran. Build and compile the code, linking against the FTorch library These are outlined in detail below. 1. Saving the model as TorchScript The trained PyTorch model needs to be exported to TorchScript .\nThis can be done from within your code using the jit.script or jit.trace functionalities from within Python. If you are not familiar with these we provide a tool pt2ts.py as part of this distribution which contains an easily adaptable script to save your\nPyTorch model as TorchScript. 2. Using the model from Fortran To use the trained Torch model from within Fortran we need to import the ftorch module and use the binding routines to load the model, convert the data,\nand run inference.\nA very simple example is given below. This minimal snippet loads a saved Torch model, creates an input consisting of a 10x10 matrix of ones, and runs the model to infer output. This is for illustrative purposes only, and we recommend following the examples before writing your own code to fully explore the features. ! Import library for interfacing with PyTorch use ftorch implicit none ! Generate an object to hold the Torch model type ( torch_module ) :: model ! Set up array of n_inputs input tensors and the output tensor ! Note: In this example there is only one input tensor (n_inputs = 1) integer , parameter :: n_inputs = 1 type ( torch_tensor ), dimension ( n_inputs ) :: model_input_arr type ( torch_tensor ) :: model_output ! Set up the model inputs and output as Fortran arrays real , dimension ( 10 , 10 ), target :: input real , dimension ( 5 ), target :: output ! Set up number of dimensions of input tensor and axis order integer , parameter :: in_dims = 2 integer :: in_layout ( in_dims ) = [ 1 , 2 ] integer , parameter :: out_dims = 1 integer :: out_layout ( out_dims ) = [ 1 ] ! Initialise the Torch model to be used model = torch_module_load ( \"/path/to/saved/model.pt\" ) ! Initialise the inputs as Fortran array of ones input = 1.0 ! Wrap Fortran data as no-copy Torch Tensors ! There may well be some reshaping required depending on the ! structure of the model which is not covered here (see examples) model_input_arr ( 1 ) = torch_tensor_from_array ( input , in_layout , torch_kCPU ) model_output = torch_tensor_from_array ( output , out_layout , torch_kCPU ) ! Run model and Infer ! Again, there may be some reshaping required depending on model design call torch_module_forward ( model , model_input_arr , n_inputs , model_output ) ! Write out the result of running the model write ( * , * ) output ! Clean up call torch_module_delete ( model ) call torch_tensor_delete ( model_input_arr ( 1 )) call torch_tensor_delete ( model_output ) 3. Build the code The code now needs to be compiled and linked against our installed library.\nHere we describe how to do this for two build systems, CMake and make. CMake If our project were using CMake we would need the following in the CMakeLists.txt file to find the FTorch installation and link it to the executable. This can be done by adding the following to the CMakeLists.txt file: find_package ( FTorch ) target_link_libraries ( <executable> PRIVATE FTorch::ftorch ) message ( STATUS \"Building with Fortran PyTorch coupling\" ) and using the -DCMAKE_PREFIX_PATH=</path/to/install/location> flag when running CMake. Note: If you used the CMAKE_INSTALL_PREFIX argument when building and installing the library then you should use the same path for </path/to/install/location> . Make To build with make we need to include the library when compiling and link the executable\nagainst it. To compile with make we need add the following compiler flag when compiling files that\nuse FTorch: FCFLAGS += - I < path / to / install / location >/ include / ftorch When compiling the final executable add the following link flag: LDFLAGS += -L<path/to/install/location>/lib -lftorch You may also need to add the location of the .so files to your LD_LIBRARY_PATH unless installing in a default location: export LD_LIBRARY_PATH = $ LD_LIBRARY_PATH : < path / to / install / location >/ lib Note: Depending on your system and architecture lib may be lib64 or something similar. Running on GPUs In order to run a model on GPU, two main changes to the above process are required: When saving your TorchScript model, ensure that it is on the GPU. When calling torch_tensor_from_array in Fortran, the device for the input\n   tensor(s) should be set to torch_kCUDA , rather than torch_kCPU . For more information refer to the GPU Documentation Worked examples The repository comes with a number of documented worked examples . These are designed to introduce users to FTorch and how to use the various features. 1) SimpleNet This worked example provides a simple but complete demonstration of how to use the library.\nIt uses simple PyTorch 'net' that takes an input vector of length 5 and applies a single\nLinear layer to multiply it by 2.\nThe aim is to demonstrate the most basic features of coupling before worrying about\nmore complex issues that are covered in later examples. 2) Resnet This worked example provides a more realistic demonstration of how to use the library,\nusing ResNet-18 to classify an image.\nAs the input to this model is four-dimensional (batch size, colour, x, y),\ncare must be taken dealing with the data array in Python and Fortran.\nSee when to transpose arrays for more details. 3) MultiGPU This worked example builds on the SimpleNet demo and shows how to account for the case of sending different\ndata to multiple GPU devices.","tags":"","loc":"page/examples.html"},{"title":"GPU Support – FTorch","text":"GPU Support Multi-GPU runs GPU Support In order to run a model on GPU, two main changes are required: 1) When saving your TorchScript model, ensure that it is on the GPU.\nFor example, when using pt2ts.py ,\nthis can be done by uncommenting the following lines: device_type = torch . device ( \"cuda\" ) trained_model = trained_model . to ( device_type ) trained_model . eval () trained_model_dummy_input_1 = trained_model_dummy_input_1 . to ( device_type ) trained_model_dummy_input_2 = trained_model_dummy_input_2 . to ( device_type ) Note: This code also moves the dummy input tensors to the GPU.\nWhilst not necessary for saving the model, but the tensors must also be on the GPU\nto test that the models runs. 2) When calling torch_tensor_from_array in Fortran, the device type for the input\n   tensor(s) should be set to torch_kCUDA , rather than torch_kCPU .\n   This ensures that the inputs are on the same device type as the model. Note: You do not need to change the device type for the output tensors as we\nwant them to be on the CPU for subsequent use in Fortran. Multi-GPU runs In the case of having multiple GPU devices, as well as setting torch_kCUDA as the\ndevice type for any input tensors and models, you should also specify their device index\nas the GPU device to be targeted. This argument is optional and will default to device\nindex 0 if unset. For example, the following code snippet sets up a Torch tensor with GPU device index 2: device_index = 2 in_tensors ( 1 ) = torch_tensor_from_array ( in_data , tensor_layout , torch_kCUDA , & device_index = device_index ) Whereas the following code snippet sets up a Torch tensor with (default) device index 0: in_tensors ( 1 ) = torch_tensor_from_array ( in_data , tensor_layout , torch_kCUDA ) See the MultiGPU example for a worked example of running with multiple GPUs.","tags":"","loc":"page/gpu.html"},{"title":"When to transpose data – FTorch","text":"Transposition of data between Fortran and C can lead to a lot of unneccessary confusion.\nThe FTorch library looks after this for you with the torch_tensor_from_array() function which\nallows you to index a tensor in Torch in exactly the same way as you would in Fortran. If you wish to do something different to this then there are more complex functions\navailable and we describe here how and when to use them. Introduction - row- vs. column-major Why does this matter? What can we do? 1) Transpose before passing 2) Design nets to use transpose 3) Use the layout argument in torch_tensor_from_array Advanced use with torch_tensor_from_blob Introduction - row- vs. column-major Astute users will note that Fortran is a column-major language whilst C, C++, and Python are row-major . This means that the matrix/tensor in Fortran will appear in contiguous memory on the computer as with the order of elements decided by moving down the columns before progressing in the\nrow dimension. In contrast, the same matrix/tensor defined in a row-major language will appear in\ncontiguous memory as reading along each row before progressing down the column dimension. Why does this matter? This matters for FTorch because a key feature is no-copy memory transfer between Fortran\nand Torch.\nTo do this the Fortran data that will be used in Torch is stored in memory and a pointer to the first\nelement, provided to Torch. Now, if Torch were to take this block of memory and interpret it as as a 2x2 matrix it\nwould be read in as which is the transpose of the\nmatrix we had in Fortran; likely not what we were expecting! This means we need to be careful when passing data to make sure that what we read in\nto our Torch net is correct as we expect. What can we do? There are a few approaches we can take to address this. The first two of these are listed for conceptual purposes, whilst in practice we\nadvise handling this using the torch_tensor_from_array function described in 3) below . 1) Transpose before passing As seen from the above example, writing out from Fortran and reading directly in to\nTorch results in us recieving the transpose. Therefore we could transpose out Fortran data immediately before passing it to Torch.\nAs a result we will read in to Torch indexed the same as in Fortran pre-transposition. For arrays of dimension 2 this can be done using the intrinsic transpose() function. For larger arrays we are required to use the 'reshape()' intrinsic to swap\nthe order of the indices. For example, if we had a 3x4x5 matrix we would need to call A_to_torch = reshape(A, shape=[5, 4, 3], order=[3, 2, 1]) which could then be read by Torch as a 3x4x5 tensor. We would, of course, need to remember to transpose/reshape any output of the model\nas required. However, the transposition process involves creating a copy of the Fortran data.\nFor large matrices/tensors this can become expensive.\nIt would be better if we can pass data without having to transpose beforehand. 2) Design nets to use transpose Alternatively we could design our net to use as its input tensor meaning we can simply write from Fortran and read to Torch. However, this requires foresight and may not be intuitive - we would like to be indexing\ndata in the same way in both Fortran and Torch.\nNot doing so could leave us open to introducing bugs. 3) Use the layout argument in torch_tensor_from_array By far the easiest way to deal with the issue is not to worry about it at all! As described at the top of this page, by using the torch_tensor_from_array function\nwe can make use of the layout argument.\nThis allows us to take data from Fortran and send it to Torch to be indexed in exactly\nthe same way by using strided access based on the shape of the array. It takes the form of an array specifying which order to read the indices in.\ni.e. [1, 2] will read i then j .\nBy passing layout = [1, 2] the data will be read into the correct indices by\nTorch. This is achieved by wrapping the torch_tensor_from_blob function to automatically\ngenerate strides assuming that a straightforward conversion between\nrow- and column-major is what should happen. i.e. if the Fortran array A is passed as torch_tensor_from_array(A, [1, 2], torch_device) the resulting Tensor will be read by Torch as Note: If, for some reason, we did want a different, transposed layout in Torch we\ncould use torch_tensor_from_array(A, [2, 1], torch_device) to get: Advanced use with torch_tensor_from_blob For more advanced options for manipulating and controlling data access when passing\nbetween Fortran and Torch see the more powerful but more complex torch_tensor_from_blob function","tags":"","loc":"page/transposing.html"},{"title":"Troubleshooting – FTorch","text":"If you are experiencing problems building or using FTorch please see below for guidance on common problems. Windows Visual Studio MinGW Apple Silicon FAQ Why are inputs to torch models an array? Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch? Windows If possible we recommend using the Windows Subsystem for Linux (WSL) to build the library.\nIn this case the build process is the same as for a Linux environment. If you need to build in native Windows please read the following information: Visual Studio It is possible to build using Visual Studio and the Intel Fortran Compiler In this case you must install Visual Studio Intel OneAPI Base and HPC toolkit (ensure that the Intel Fortran compiler and VS integration is selected). You will then need to load the intel Fortran compilers using setvars.bat which is found in the Intel compiler install directory (see the intel docs )\nfor more details. From CMD this can be done with: \"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" Finally you will need to add -G \"NMake Makefiles\" to the cmake command in the regular install instructions . So the basic command to build from CMD becomes: cmake - G \"NMake Makefiles\" - DCMAKE_PREFIX_PATH = \"C:\\Users\\melt\\Downloads\\libtorch-win-shared-with-deps-2.1.0+cpu\\libtorch\" - DCMAKE_BUILD_TYPE = Release .. cmake -- build . cmake -- install . If using powershell the setvars and build commands become: cmd / k '\"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" && powershell' cmake - G \"NMake Makefiles\" - DCMAKE_PREFIX_PATH = \"C:\\Users\\melt\\Downloads\\libtorch-win-shared-with-deps-2.1.0+cpu\\libtorch\" - DCMAKE_BUILD_TYPE = Release .. cmake -- build . cmake -- install . MinGW It may be tempting to build on Windows using MinGW.\nHowever, libtorch does not currently support MinGW .\nInstead please build using Visual Studio and the intel Fortran compiler (ifort) as\ndetailed in the project README. Apple Silicon At the time of writing, libtorch is currently only officially available for x86\narchitectures (according to pytorch.org ).\nHowever, the version of PyTorch provided by pip install provides an ARM binary\nfor libtorch which works on Apple Silicon.\nTherefore you should pip install torch in this situation and follow the guidance\non locating Torch within a virtual environment (venv) for CMake. FAQ Why are inputs to torch models an array? The reason input tensors to torch_module_forward are contained in an\narray is because it is possible to pass multiple input tensors to the forward() method of a torch net. The nature of Fortran means that it is not possible to set an arbitrary number\nof inputs to the torch_module_forward subroutine, so instead we use an single array\nof input tensors which can have an arbitrary length of n_inputs . Note that this does not refer to batching data.\nThis should be done in the same way as in Torch; by extending the dimensionality of\nthe input tensors. Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch? By default we disable gradient calculations for tensors and models and place models in\nevaluation mode for efficiency.\nThese can be adjusted using the requires_grad and is_training optional arguments\nin the Fortran interface. See the API procedures documentation for details.","tags":"","loc":"page/troubleshooting.html"}]}