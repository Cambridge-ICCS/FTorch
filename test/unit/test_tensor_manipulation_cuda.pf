!| Unit tests for FTorch's tensor manipulation functionality on a CUDA device.
!
!  * License
!    FTorch is released under an MIT license.
!    See the [LICENSE](https://github.com/Cambridge-ICCS/FTorch/blob/main/LICENSE)
!    file for details.
module test_tensor_manipulation_cuda
  use funit
  use ftorch, only: torch_kCPU, torch_kCUDA, torch_kFloat64, torch_kFloat32, &
                    torch_tensor, torch_tensor_delete, torch_tensor_print, &
                    torch_tensor_from_array, torch_tensor_empty, torch_tensor_to
  use ftorch_test_utils, only: assert_allclose
  use, intrinsic :: iso_c_binding, only : c_int64_t

  implicit none

  public

contains

    ! Unit test for the torch_tensor_to subroutine moving a tensor from the CPU (Float64) to a CUDA device (FLoat32)
  @test
  subroutine test_torch_tensor_to()
    use, intrinsic :: iso_fortran_env, only: sp => real32, dp => real64

    type(torch_tensor) :: cpu_tensor, gpu_tensor, test_tensor
    real(dp), dimension(2,3,4) :: dp_data
    real(sp), dimension(2,3,4) :: sp_data, test_array
    integer, parameter :: device_type_src = torch_kCPU
    integer, parameter :: device_type_tar = torch_kCUDA
    integer, parameter :: dtype_src = torch_kFloat64
    integer, parameter :: dtype_tar = torch_kFloat32
    integer :: i, j, k
    logical :: test_pass

    do k = 1, 4
       do j = 1, 3
          do i = 1, 2
             dp_data(i,j,k) = real(100*i + 10*j + k, dp)
          end do
       end do
    end do

    sp_data = real(dp_data, sp) ! source data cast to single-precision real for testing
    test_array = 0.0_sp         ! Fortran array to extract target tensor data from
    test_pass = .false.

    call torch_tensor_from_array(cpu_tensor, dp_data, device_type_src)

    call torch_tensor_empty(gpu_tensor,cpu_tensor%get_rank(),cpu_tensor%get_shape(), &
                           dtype_tar,device_type_tar)

    ! Move to target device and dtype
    call torch_tensor_to(cpu_tensor, gpu_tensor)

    @assertTrue(gpu_tensor%get_device_type() == device_type_tar)
    @assertTrue(gpu_tensor%get_shape() == cpu_tensor%get_shape())
    @assertTrue(gpu_tensor%get_rank() == cpu_tensor%get_rank())

    ! Temporary torch_tensor for testing
    call torch_tensor_from_array(test_tensor, test_array,device_type_src)

    ! Move back to CPU for comparison
    call torch_tensor_to(gpu_tensor, test_tensor)

    test_pass = assert_allclose(test_array, sp_data, "test_torch_tensor_to")

    if (.not. test_pass) then
      print *, "Error :: incorrect output from torch_tensor_to"
      print *, "Source Tensor:"
      call torch_tensor_print(cpu_tensor)
      print *, "Target Tensor:"
      call torch_tensor_print(gpu_tensor)

      call torch_tensor_delete(cpu_tensor)
      call torch_tensor_delete(gpu_tensor)
      call torch_tensor_delete(test_tensor)

      stop 999
    end if

    call torch_tensor_delete(cpu_tensor)
    call torch_tensor_delete(gpu_tensor)
    call torch_tensor_delete(test_tensor)

  end subroutine test_torch_tensor_to

end module test_tensor_manipulation_cuda
