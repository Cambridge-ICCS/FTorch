<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>torch_tensor_from_array &ndash; FTorch</title>

    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <!-- Font Awesome -->
    <link href="../css/fontawesome.min.css" rel="stylesheet">
    <link href="../css/brands.min.css" rel="stylesheet">
    <link href="../css/regular.min.css" rel="stylesheet">
    <link href="../css/solid.min.css" rel="stylesheet">
    <link href="../css/v4-font-face.min.css" rel="stylesheet">
    <link href="../css/v4-shims.min.css" rel="stylesheet">
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } }
      });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async
            integrity="sha256-DViIOMYdwlM/axqoGDPeUyf0urLoHMN4QACBKyB58Uw=" crossorigin="anonymous"></script>
    <!-- Other scripts and stylesheets -->
    <link href="../css/local.css" rel="stylesheet">
    <link href="../css/pygments.css" rel="stylesheet">
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="../page/index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>torch_tensor_from_array
      <small>Interface</small>
      
    </h1>
      <div class="container p-2 mb-4 bg-light border rounded-3">
    <div class="row align-items-center justify-content-between" id="info-bar">
      <div class="col">
        <ul class="list-inline" style="margin-bottom:0px;display:inline">
            <li class="list-inline-item" id="meta-license"><i class="fa fa-legal"></i> <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a></li>

            <li class="list-inline-item" id="statements"><i class="fa fa-list-ol"></i>
              <a data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-html="true"
                 title="<p> 3.0% of total for procedures.</p>Including implementation: 992 statements, 47.6% of total for procedures.">62 statements</a>
            </li>

            <li class="list-inline-item" id="source-file">
              <i class="fa fa-code"></i>
              <a href="../src/ftorch.F90"> Source File</a>
            </li>
        </ul>
      </div>
      <div class="col">
        <nav aria-label="breadcrumb">
          <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='../sourcefile/ftorch.f90.html'>ftorch.F90</a></li>
                <li class="breadcrumb-item"><a href='../module/ftorch.html'>ftorch</a></li>
            <li class="breadcrumb-item active" aria-current="page">torch_tensor_from_array</li>
          </ol>
        </nav>
      </div>
    </div>
  </div>
  <script>
    // Enable Bootstrap tooltips
    (function () {
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
    })();
  </script>

  </div>

  <div class="row">
    <div class="col-md-3 hidden-xs hidden-sm visible-md visible-lg">
        <div id="sidebar">
      <h3>Contents</h3>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#modprocs-0"
         aria-expanded="false" aria-controls="modprocs-0">
         <h4 class="card-header bg-primary text-white">Module Procedures</h4>
      </a>
      <div id="modprocs-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_1d">torch_tensor_from_array_int8_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_2d">torch_tensor_from_array_int8_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_3d">torch_tensor_from_array_int8_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_4d">torch_tensor_from_array_int8_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_5d">torch_tensor_from_array_int8_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_1d">torch_tensor_from_array_int16_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_2d">torch_tensor_from_array_int16_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_3d">torch_tensor_from_array_int16_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_4d">torch_tensor_from_array_int16_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_5d">torch_tensor_from_array_int16_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_1d">torch_tensor_from_array_int32_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_2d">torch_tensor_from_array_int32_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_3d">torch_tensor_from_array_int32_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_4d">torch_tensor_from_array_int32_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_5d">torch_tensor_from_array_int32_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_1d">torch_tensor_from_array_int64_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_2d">torch_tensor_from_array_int64_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_3d">torch_tensor_from_array_int64_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_4d">torch_tensor_from_array_int64_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_5d">torch_tensor_from_array_int64_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_1d">torch_tensor_from_array_real32_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_2d">torch_tensor_from_array_real32_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_3d">torch_tensor_from_array_real32_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_4d">torch_tensor_from_array_real32_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_5d">torch_tensor_from_array_real32_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_1d">torch_tensor_from_array_real64_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_2d">torch_tensor_from_array_real64_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_3d">torch_tensor_from_array_real64_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_4d">torch_tensor_from_array_real64_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_5d">torch_tensor_from_array_real64_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_1d_default_layout">torch_tensor_from_array_int8_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_2d_default_layout">torch_tensor_from_array_int8_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_3d_default_layout">torch_tensor_from_array_int8_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_4d_default_layout">torch_tensor_from_array_int8_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_5d_default_layout">torch_tensor_from_array_int8_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_1d_default_layout">torch_tensor_from_array_int16_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_2d_default_layout">torch_tensor_from_array_int16_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_3d_default_layout">torch_tensor_from_array_int16_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_4d_default_layout">torch_tensor_from_array_int16_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_5d_default_layout">torch_tensor_from_array_int16_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_1d_default_layout">torch_tensor_from_array_int32_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_2d_default_layout">torch_tensor_from_array_int32_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_3d_default_layout">torch_tensor_from_array_int32_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_4d_default_layout">torch_tensor_from_array_int32_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_5d_default_layout">torch_tensor_from_array_int32_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_1d_default_layout">torch_tensor_from_array_int64_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_2d_default_layout">torch_tensor_from_array_int64_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_3d_default_layout">torch_tensor_from_array_int64_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_4d_default_layout">torch_tensor_from_array_int64_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_5d_default_layout">torch_tensor_from_array_int64_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_1d_default_layout">torch_tensor_from_array_real32_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_2d_default_layout">torch_tensor_from_array_real32_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_3d_default_layout">torch_tensor_from_array_real32_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_4d_default_layout">torch_tensor_from_array_real32_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_5d_default_layout">torch_tensor_from_array_real32_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_1d_default_layout">torch_tensor_from_array_real64_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_2d_default_layout">torch_tensor_from_array_real64_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_3d_default_layout">torch_tensor_from_array_real64_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_4d_default_layout">torch_tensor_from_array_real64_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_5d_default_layout">torch_tensor_from_array_real64_5d_default_layout</a>
        </div>
      </div>
    </div>

  


  </div>

    </div>

    <div class="col-md-9" id='text'>
      <h2>public interface torch_tensor_from_array</h2>
      <p>Interface for directing <code>torch_tensor_from_array</code> to possible input types and ranks</p>
        <div class="card">
          <div class="card-header">
            <h3 class="card-title">Calls</h3>
          </div>
          <div class="card-body">
            <div class="depgraph"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: interface~~torch_tensor_from_array~~CallsGraph Pages: 1 -->
<svg id="interfacetorch_tensor_from_arrayCallsGraph" width="641pt" height="2050pt"
 viewBox="0.00 0.00 641.00 2049.57" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="interface~~torch_tensor_from_array~~CallsGraph" class="graph" transform="scale(0.82 0.82) rotate(0) translate(4 2506)">
<title>interface~~torch_tensor_from_array~~CallsGraph</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-2506 781,-2506 781,4 -4,4"/>
<!-- interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node1" class="node">
<title>interface~torch_tensor_from_array</title>
<polygon fill="none" stroke="black" points="142,-1263 0,-1263 0,-1239 142,-1239 142,-1263"/>
<text text-anchor="middle" x="71" y="-1248.6" font-family="Helvetica,sans-Serif" font-size="10.50">torch_tensor_from_array</text>
</g>
<!-- proc~torch_tensor_from_array_int16_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node2" class="node">
<title>proc~torch_tensor_from_array_int16_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node2"><a xlink:href="../proc/torch_tensor_from_array_int16_1d.html" xlink:title="torch_tensor_from_array_int16_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2502 222,-2502 222,-2478 415,-2478 415,-2502"/>
<text text-anchor="middle" x="318.5" y="-2487.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge1" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-1263.21C73.9,-1384.83 90.72,-2376.08 178,-2469 187.29,-2478.89 199.08,-2485.48 211.87,-2489.74"/>
<polygon fill="#000000" stroke="#000000" points="211.24,-2493.2 221.82,-2492.56 213.15,-2486.46 211.24,-2493.2"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node3" class="node">
<title>proc~torch_tensor_from_array_int16_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node3"><a xlink:href="../proc/torch_tensor_from_array_int16_1d_default_layout.html" xlink:title="torch_tensor_from_array_int16_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2460 181.5,-2460 181.5,-2436 455.5,-2436 455.5,-2460"/>
<text text-anchor="middle" x="318.5" y="-2445.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge2" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.23,-1263.01C74.46,-1381.16 94.01,-2328.85 178,-2418 183.14,-2423.45 189.04,-2427.9 195.45,-2431.53"/>
<polygon fill="#000000" stroke="#000000" points="193.97,-2434.7 204.48,-2435.97 197.06,-2428.42 193.97,-2434.7"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node4" class="node">
<title>proc~torch_tensor_from_array_int16_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node4"><a xlink:href="../proc/torch_tensor_from_array_int16_2d.html" xlink:title="torch_tensor_from_array_int16_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2418 222,-2418 222,-2394 415,-2394 415,-2418"/>
<text text-anchor="middle" x="318.5" y="-2403.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge3" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.24,-1263.09C74.69,-1379.46 96.58,-2298.87 178,-2385 187.32,-2394.86 199.13,-2401.43 211.93,-2405.68"/>
<polygon fill="#000000" stroke="#000000" points="211.31,-2409.14 221.88,-2408.5 213.21,-2402.41 211.31,-2409.14"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node5" class="node">
<title>proc~torch_tensor_from_array_int16_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node5"><a xlink:href="../proc/torch_tensor_from_array_int16_2d_default_layout.html" xlink:title="torch_tensor_from_array_int16_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2376 181.5,-2376 181.5,-2352 455.5,-2352 455.5,-2376"/>
<text text-anchor="middle" x="318.5" y="-2361.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge4" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.33,-1263.09C75.36,-1376.77 99.92,-2251.69 178,-2334 183.16,-2339.44 189.07,-2343.87 195.49,-2347.49"/>
<polygon fill="#000000" stroke="#000000" points="194.02,-2350.66 204.54,-2351.92 197.1,-2344.38 194.02,-2350.66"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node6" class="node">
<title>proc~torch_tensor_from_array_int16_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node6"><a xlink:href="../proc/torch_tensor_from_array_int16_3d.html" xlink:title="torch_tensor_from_array_int16_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2334 222,-2334 222,-2310 415,-2310 415,-2334"/>
<text text-anchor="middle" x="318.5" y="-2319.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge5" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.34,-1263.23C75.58,-1375.29 102.5,-2221.73 178,-2301 187.35,-2310.82 199.19,-2317.38 212,-2321.62"/>
<polygon fill="#000000" stroke="#000000" points="211.38,-2325.08 221.95,-2324.43 213.28,-2318.35 211.38,-2325.08"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node7" class="node">
<title>proc~torch_tensor_from_array_int16_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node7"><a xlink:href="../proc/torch_tensor_from_array_int16_3d_default_layout.html" xlink:title="torch_tensor_from_array_int16_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2292 181.5,-2292 181.5,-2268 455.5,-2268 455.5,-2292"/>
<text text-anchor="middle" x="318.5" y="-2277.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge6" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.45,-1263.03C76.33,-1371.51 105.79,-2174.49 178,-2250 183.18,-2255.42 189.11,-2259.84 195.55,-2263.44"/>
<polygon fill="#000000" stroke="#000000" points="194.08,-2266.62 204.6,-2267.86 197.15,-2260.33 194.08,-2266.62"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node8" class="node">
<title>proc~torch_tensor_from_array_int16_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node8"><a xlink:href="../proc/torch_tensor_from_array_int16_4d.html" xlink:title="torch_tensor_from_array_int16_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2250 222,-2250 222,-2226 415,-2226 415,-2250"/>
<text text-anchor="middle" x="318.5" y="-2235.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge7" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.45,-1263.24C76.54,-1370.26 108.38,-2144.53 178,-2217 187.33,-2226.71 199.09,-2233.22 211.8,-2237.45"/>
<polygon fill="#000000" stroke="#000000" points="211.1,-2240.89 221.68,-2240.26 213.02,-2234.16 211.1,-2240.89"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node9" class="node">
<title>proc~torch_tensor_from_array_int16_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node9"><a xlink:href="../proc/torch_tensor_from_array_int16_4d_default_layout.html" xlink:title="torch_tensor_from_array_int16_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2208 181.5,-2208 181.5,-2184 455.5,-2184 455.5,-2208"/>
<text text-anchor="middle" x="318.5" y="-2193.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge8" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.6,-1263.17C77.43,-1366.94 111.69,-2097.32 178,-2166 183.26,-2171.45 189.29,-2175.89 195.82,-2179.5"/>
<polygon fill="#000000" stroke="#000000" points="194.49,-2182.74 205.02,-2183.93 197.52,-2176.44 194.49,-2182.74"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node10" class="node">
<title>proc~torch_tensor_from_array_int16_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node10"><a xlink:href="../proc/torch_tensor_from_array_int16_5d.html" xlink:title="torch_tensor_from_array_int16_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2166 222,-2166 222,-2142 415,-2142 415,-2166"/>
<text text-anchor="middle" x="318.5" y="-2151.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge9" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.58,-1263.12C77.55,-1364.37 114.22,-2067.29 178,-2133 187.38,-2142.66 199.16,-2149.14 211.89,-2153.36"/>
<polygon fill="#000000" stroke="#000000" points="211.21,-2156.81 221.78,-2156.17 213.11,-2150.07 211.21,-2156.81"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node11" class="node">
<title>proc~torch_tensor_from_array_int16_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node11"><a xlink:href="../proc/torch_tensor_from_array_int16_5d_default_layout.html" xlink:title="torch_tensor_from_array_int16_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2124 181.5,-2124 181.5,-2100 455.5,-2100 455.5,-2124"/>
<text text-anchor="middle" x="318.5" y="-2109.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge10" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-1263.11C78.61,-1361.23 117.54,-2020.08 178,-2082 183.35,-2087.48 189.48,-2091.94 196.11,-2095.55"/>
<polygon fill="#000000" stroke="#000000" points="194.91,-2098.86 205.44,-2099.98 197.91,-2092.53 194.91,-2098.86"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node12" class="node">
<title>proc~torch_tensor_from_array_int32_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node12"><a xlink:href="../proc/torch_tensor_from_array_int32_1d.html" xlink:title="torch_tensor_from_array_int32_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2082 222,-2082 222,-2058 415,-2058 415,-2082"/>
<text text-anchor="middle" x="318.5" y="-2067.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge11" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-1263.16C78.71,-1358.96 120.08,-1990.07 178,-2049 187.44,-2058.6 199.26,-2065.05 212,-2069.26"/>
<polygon fill="#000000" stroke="#000000" points="211.33,-2072.7 221.9,-2072.05 213.23,-2065.96 211.33,-2072.7"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node13" class="node">
<title>proc~torch_tensor_from_array_int32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node13"><a xlink:href="../proc/torch_tensor_from_array_int32_1d_default_layout.html" xlink:title="torch_tensor_from_array_int32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2040 181.5,-2040 181.5,-2016 455.5,-2016 455.5,-2040"/>
<text text-anchor="middle" x="318.5" y="-2025.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge12" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.79,-1263.06C70.68,-1350.87 69.26,-1888.15 178,-1998 183.39,-2003.44 189.55,-2007.87 196.2,-2011.47"/>
<polygon fill="#000000" stroke="#000000" points="195.02,-2014.78 205.56,-2015.87 198,-2008.44 195.02,-2014.78"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node14" class="node">
<title>proc~torch_tensor_from_array_int32_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node14"><a xlink:href="../proc/torch_tensor_from_array_int32_2d.html" xlink:title="torch_tensor_from_array_int32_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1998 222,-1998 222,-1974 415,-1974 415,-1998"/>
<text text-anchor="middle" x="318.5" y="-1983.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge13" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.92,-1263.06C71.62,-1348.42 74.21,-1861 178,-1965 187.44,-1974.46 199.2,-1980.85 211.86,-1985.03"/>
<polygon fill="#000000" stroke="#000000" points="211.12,-1988.46 221.69,-1987.82 213.02,-1981.72 211.12,-1988.46"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node15" class="node">
<title>proc~torch_tensor_from_array_int32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node15"><a xlink:href="../proc/torch_tensor_from_array_int32_2d_default_layout.html" xlink:title="torch_tensor_from_array_int32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1956 181.5,-1956 181.5,-1932 455.5,-1932 455.5,-1956"/>
<text text-anchor="middle" x="318.5" y="-1941.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge14" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.06,-1263.03C72.73,-1345.01 80.89,-1817.57 178,-1914 183.5,-1919.46 189.76,-1923.89 196.53,-1927.48"/>
<polygon fill="#000000" stroke="#000000" points="195.49,-1930.85 206.03,-1931.87 198.42,-1924.5 195.49,-1930.85"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node16" class="node">
<title>proc~torch_tensor_from_array_int32_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node16"><a xlink:href="../proc/torch_tensor_from_array_int32_3d.html" xlink:title="torch_tensor_from_array_int32_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1914 222,-1914 222,-1890 415,-1890 415,-1914"/>
<text text-anchor="middle" x="318.5" y="-1899.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge15" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.18,-1263.15C73.63,-1342.84 85.85,-1790.43 178,-1881 187.53,-1890.37 199.35,-1896.7 212.03,-1900.86"/>
<polygon fill="#000000" stroke="#000000" points="211.3,-1904.29 221.87,-1903.63 213.2,-1897.55 211.3,-1904.29"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node17" class="node">
<title>proc~torch_tensor_from_array_int32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node17"><a xlink:href="../proc/torch_tensor_from_array_int32_3d_default_layout.html" xlink:title="torch_tensor_from_array_int32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1872 181.5,-1872 181.5,-1848 455.5,-1848 455.5,-1872"/>
<text text-anchor="middle" x="318.5" y="-1857.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge16" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.42,-1263.17C75.1,-1339.38 92.53,-1746.97 178,-1830 183.81,-1835.64 190.44,-1840.17 197.58,-1843.81"/>
<polygon fill="#000000" stroke="#000000" points="196.33,-1847.08 206.89,-1847.96 199.18,-1840.69 196.33,-1847.08"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node18" class="node">
<title>proc~torch_tensor_from_array_int32_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node18"><a xlink:href="../proc/torch_tensor_from_array_int32_4d.html" xlink:title="torch_tensor_from_array_int32_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1830 222,-1830 222,-1806 415,-1806 415,-1830"/>
<text text-anchor="middle" x="318.5" y="-1815.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge17" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.53,-1263.4C75.97,-1337.36 97.49,-1719.82 178,-1797 187.58,-1806.18 199.36,-1812.42 211.97,-1816.55"/>
<polygon fill="#000000" stroke="#000000" points="211.18,-1819.96 221.75,-1819.3 213.08,-1813.22 211.18,-1819.96"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node19" class="node">
<title>proc~torch_tensor_from_array_int32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node19"><a xlink:href="../proc/torch_tensor_from_array_int32_4d_default_layout.html" xlink:title="torch_tensor_from_array_int32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1788 181.5,-1788 181.5,-1764 455.5,-1764 455.5,-1788"/>
<text text-anchor="middle" x="318.5" y="-1773.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge18" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.9,-1263.07C77.82,-1332.43 104.03,-1676.19 178,-1746 184.01,-1751.67 190.86,-1756.22 198.23,-1759.85"/>
<polygon fill="#000000" stroke="#000000" points="197.24,-1763.23 207.81,-1763.98 200.01,-1756.8 197.24,-1763.23"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node20" class="node">
<title>proc~torch_tensor_from_array_int32_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node20"><a xlink:href="../proc/torch_tensor_from_array_int32_5d.html" xlink:title="torch_tensor_from_array_int32_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1746 222,-1746 222,-1722 415,-1722 415,-1746"/>
<text text-anchor="middle" x="318.5" y="-1731.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge19" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.98,-1263.2C78.6,-1329.8 108.89,-1648.96 178,-1713 187.66,-1721.95 199.42,-1728.07 211.97,-1732.15"/>
<polygon fill="#000000" stroke="#000000" points="211.13,-1735.55 221.7,-1734.89 213.02,-1728.81 211.13,-1735.55"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node21" class="node">
<title>proc~torch_tensor_from_array_int32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node21"><a xlink:href="../proc/torch_tensor_from_array_int32_5d_default_layout.html" xlink:title="torch_tensor_from_array_int32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1704 181.5,-1704 181.5,-1680 455.5,-1680 455.5,-1704"/>
<text text-anchor="middle" x="318.5" y="-1689.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge20" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.58,-1263.01C81.09,-1325.05 115.46,-1605.3 178,-1662 184.39,-1667.79 191.66,-1672.39 199.45,-1676.03"/>
<polygon fill="#000000" stroke="#000000" points="198.23,-1679.32 208.81,-1679.89 200.9,-1672.84 198.23,-1679.32"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node22" class="node">
<title>proc~torch_tensor_from_array_int64_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node22"><a xlink:href="../proc/torch_tensor_from_array_int64_1d.html" xlink:title="torch_tensor_from_array_int64_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1662 222,-1662 222,-1638 415,-1638 415,-1662"/>
<text text-anchor="middle" x="318.5" y="-1647.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge21" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.65,-1263.26C81.86,-1322.45 120.27,-1578.02 178,-1629 187.8,-1637.66 199.58,-1643.61 212.09,-1647.62"/>
<polygon fill="#000000" stroke="#000000" points="211.2,-1651.01 221.78,-1650.32 213.08,-1644.27 211.2,-1651.01"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node23" class="node">
<title>proc~torch_tensor_from_array_int64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node23"><a xlink:href="../proc/torch_tensor_from_array_int64_1d_default_layout.html" xlink:title="torch_tensor_from_array_int64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1620 181.5,-1620 181.5,-1596 455.5,-1596 455.5,-1620"/>
<text text-anchor="middle" x="318.5" y="-1605.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge22" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.6,-1263.16C71.15,-1311.97 77.57,-1492.15 178,-1578 185.04,-1584.02 193.05,-1588.72 201.58,-1592.38"/>
<polygon fill="#000000" stroke="#000000" points="200.43,-1595.69 211.02,-1595.97 202.91,-1589.15 200.43,-1595.69"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node24" class="node">
<title>proc~torch_tensor_from_array_int64_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node24"><a xlink:href="../proc/torch_tensor_from_array_int64_2d.html" xlink:title="torch_tensor_from_array_int64_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1578 222,-1578 222,-1554 415,-1554 415,-1578"/>
<text text-anchor="middle" x="318.5" y="-1563.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge23" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.26,-1263.24C73.93,-1308.79 86.35,-1469.8 178,-1545 187.86,-1553.09 199.48,-1558.76 211.74,-1562.65"/>
<polygon fill="#000000" stroke="#000000" points="211.12,-1566.11 221.69,-1565.41 212.99,-1559.37 211.12,-1566.11"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node25" class="node">
<title>proc~torch_tensor_from_array_int64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node25"><a xlink:href="../proc/torch_tensor_from_array_int64_2d_default_layout.html" xlink:title="torch_tensor_from_array_int64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1536 181.5,-1536 181.5,-1512 455.5,-1512 455.5,-1536"/>
<text text-anchor="middle" x="318.5" y="-1521.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge24" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.49,-1263.1C78.6,-1303.68 99.7,-1433.1 178,-1494 186.05,-1500.26 195.17,-1505.04 204.79,-1508.69"/>
<polygon fill="#000000" stroke="#000000" points="203.98,-1512.11 214.57,-1511.98 206.21,-1505.47 203.98,-1512.11"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node26" class="node">
<title>proc~torch_tensor_from_array_int64_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node26"><a xlink:href="../proc/torch_tensor_from_array_int64_3d.html" xlink:title="torch_tensor_from_array_int64_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1494 222,-1494 222,-1470 415,-1470 415,-1494"/>
<text text-anchor="middle" x="318.5" y="-1479.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge25" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.15,-1263.24C81.32,-1300.06 108.02,-1410.37 178,-1461 188.18,-1468.36 199.88,-1473.62 212.08,-1477.32"/>
<polygon fill="#000000" stroke="#000000" points="211.39,-1480.76 221.95,-1479.96 213.2,-1473.99 211.39,-1480.76"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node27" class="node">
<title>proc~torch_tensor_from_array_int64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node27"><a xlink:href="../proc/torch_tensor_from_array_int64_3d_default_layout.html" xlink:title="torch_tensor_from_array_int64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1452 181.5,-1452 181.5,-1428 455.5,-1428 455.5,-1452"/>
<text text-anchor="middle" x="318.5" y="-1437.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge26" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M77.41,-1263.31C89.34,-1294.19 121.41,-1373.03 178,-1410 188.44,-1416.82 200.24,-1421.75 212.44,-1425.36"/>
<polygon fill="#000000" stroke="#000000" points="211.74,-1428.79 222.31,-1427.98 213.54,-1422.03 211.74,-1428.79"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node28" class="node">
<title>proc~torch_tensor_from_array_int64_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node28"><a xlink:href="../proc/torch_tensor_from_array_int64_4d.html" xlink:title="torch_tensor_from_array_int64_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1410 222,-1410 222,-1386 415,-1386 415,-1410"/>
<text text-anchor="middle" x="318.5" y="-1395.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge27" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M78.25,-1263.21C92.21,-1289.1 128.61,-1349.35 178,-1377 188.43,-1382.84 199.96,-1387.22 211.79,-1390.48"/>
<polygon fill="#000000" stroke="#000000" points="211.23,-1393.95 221.78,-1392.96 212.92,-1387.15 211.23,-1393.95"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node29" class="node">
<title>proc~torch_tensor_from_array_int64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node29"><a xlink:href="../proc/torch_tensor_from_array_int64_4d_default_layout.html" xlink:title="torch_tensor_from_array_int64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1368 181.5,-1368 181.5,-1344 455.5,-1344 455.5,-1368"/>
<text text-anchor="middle" x="318.5" y="-1353.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge28" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M89.55,-1263.17C109.11,-1280.5 142.68,-1310.66 178,-1326 196.26,-1333.93 216.98,-1338.94 236.77,-1342.38"/>
<polygon fill="#000000" stroke="#000000" points="236.26,-1345.84 246.7,-1343.99 237.39,-1338.93 236.26,-1345.84"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node30" class="node">
<title>proc~torch_tensor_from_array_int64_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node30"><a xlink:href="../proc/torch_tensor_from_array_int64_5d.html" xlink:title="torch_tensor_from_array_int64_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1326 222,-1326 222,-1302 415,-1302 415,-1326"/>
<text text-anchor="middle" x="318.5" y="-1311.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge29" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M97.58,-1263.05C118.71,-1272.53 149.71,-1285.37 178,-1293 188.88,-1295.93 200.36,-1298.49 211.87,-1300.71"/>
<polygon fill="#000000" stroke="#000000" points="211.5,-1304.21 221.97,-1302.58 212.78,-1297.32 211.5,-1304.21"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node31" class="node">
<title>proc~torch_tensor_from_array_int64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node31"><a xlink:href="../proc/torch_tensor_from_array_int64_5d_default_layout.html" xlink:title="torch_tensor_from_array_int64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1284 181.5,-1284 181.5,-1260 455.5,-1260 455.5,-1284"/>
<text text-anchor="middle" x="318.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge30" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-1250.83C172.07,-1252.69 207.33,-1255.64 238.32,-1258.87"/>
<polygon fill="#000000" stroke="#000000" points="238.34,-1262.39 248.66,-1259.98 239.09,-1255.43 238.34,-1262.39"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node32" class="node">
<title>proc~torch_tensor_from_array_int8_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node32"><a xlink:href="../proc/torch_tensor_from_array_int8_1d.html" xlink:title="torch_tensor_from_array_int8_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1242 225,-1242 225,-1218 412,-1218 412,-1242"/>
<text text-anchor="middle" x="318.5" y="-1227.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge31" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-1245.01C164.69,-1243.07 190.33,-1240.88 214.86,-1238.78"/>
<polygon fill="#000000" stroke="#000000" points="215.26,-1242.26 224.92,-1237.92 214.66,-1235.28 215.26,-1242.26"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node33" class="node">
<title>proc~torch_tensor_from_array_int8_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node33"><a xlink:href="../proc/torch_tensor_from_array_int8_1d_default_layout.html" xlink:title="torch_tensor_from_array_int8_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1200 184.5,-1200 184.5,-1176 452.5,-1176 452.5,-1200"/>
<text text-anchor="middle" x="318.5" y="-1185.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge32" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M85.06,-1238.88C103.13,-1227.48 137.19,-1212.11 174.41,-1201.15"/>
<polygon fill="#000000" stroke="#000000" points="175.77,-1204.4 184.45,-1198.32 173.87,-1197.66 175.77,-1204.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node34" class="node">
<title>proc~torch_tensor_from_array_int8_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node34"><a xlink:href="../proc/torch_tensor_from_array_int8_2d.html" xlink:title="torch_tensor_from_array_int8_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1158 225,-1158 225,-1134 412,-1134 412,-1158"/>
<text text-anchor="middle" x="318.5" y="-1143.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge33" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M83.03,-1238.89C100.95,-1220.08 138.37,-1184.21 178,-1167 189.52,-1162 202.03,-1158.15 214.66,-1155.21"/>
<polygon fill="#000000" stroke="#000000" points="215.75,-1158.55 224.8,-1153.03 214.29,-1151.71 215.75,-1158.55"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node35" class="node">
<title>proc~torch_tensor_from_array_int8_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node35"><a xlink:href="../proc/torch_tensor_from_array_int8_2d_default_layout.html" xlink:title="torch_tensor_from_array_int8_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1116 184.5,-1116 184.5,-1092 452.5,-1092 452.5,-1116"/>
<text text-anchor="middle" x="318.5" y="-1101.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge34" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M76.14,-1238.67C87.59,-1212.12 122.11,-1151.74 175.48,-1117.94"/>
<polygon fill="#000000" stroke="#000000" points="177.4,-1120.87 184.21,-1112.75 173.82,-1114.86 177.4,-1120.87"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node36" class="node">
<title>proc~torch_tensor_from_array_int8_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node36"><a xlink:href="../proc/torch_tensor_from_array_int8_3d.html" xlink:title="torch_tensor_from_array_int8_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1074 225,-1074 225,-1050 412,-1050 412,-1074"/>
<text text-anchor="middle" x="318.5" y="-1059.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge35" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M75.74,-1238.72C86.13,-1206.96 118.52,-1121.85 178,-1083 189.11,-1075.74 201.77,-1070.62 214.82,-1067.04"/>
<polygon fill="#000000" stroke="#000000" points="215.97,-1070.37 224.86,-1064.61 214.31,-1063.56 215.97,-1070.37"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node37" class="node">
<title>proc~torch_tensor_from_array_int8_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node37"><a xlink:href="../proc/torch_tensor_from_array_int8_3d_default_layout.html" xlink:title="torch_tensor_from_array_int8_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1032 184.5,-1032 184.5,-1008 452.5,-1008 452.5,-1032"/>
<text text-anchor="middle" x="318.5" y="-1017.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge36" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.5,-1238.77C79.39,-1201.66 103.9,-1092.37 176.32,-1033.92"/>
<polygon fill="#000000" stroke="#000000" points="178.6,-1036.58 184.43,-1027.74 174.36,-1031.02 178.6,-1036.58"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node38" class="node">
<title>proc~torch_tensor_from_array_int8_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node38"><a xlink:href="../proc/torch_tensor_from_array_int8_4d.html" xlink:title="torch_tensor_from_array_int8_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-990 225,-990 225,-966 412,-966 412,-990"/>
<text text-anchor="middle" x="318.5" y="-975.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge37" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.06,-1238.79C77.34,-1197.44 97.26,-1061.79 178,-999 188.81,-990.59 201.56,-984.85 214.88,-981.02"/>
<polygon fill="#000000" stroke="#000000" points="215.81,-984.4 224.66,-978.56 214.1,-977.61 215.81,-984.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node39" class="node">
<title>proc~torch_tensor_from_array_int8_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node39"><a xlink:href="../proc/torch_tensor_from_array_int8_4d_default_layout.html" xlink:title="torch_tensor_from_array_int8_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-948 184.5,-948 184.5,-924 452.5,-924 452.5,-948"/>
<text text-anchor="middle" x="318.5" y="-933.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge38" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-1238.7C73.4,-1191.62 84.25,-1024.92 178,-948 201.19,-928.98 234.11,-923.35 262.15,-923.64"/>
<polygon fill="#000000" stroke="#000000" points="262.12,-927.14 272.24,-924 262.37,-920.14 262.12,-927.14"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node40" class="node">
<title>proc~torch_tensor_from_array_int8_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node40"><a xlink:href="../proc/torch_tensor_from_array_int8_5d.html" xlink:title="torch_tensor_from_array_int8_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-906 225,-906 225,-882 412,-882 412,-906"/>
<text text-anchor="middle" x="318.5" y="-891.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge39" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.64,-1238.8C70.91,-1189.42 75.25,-1002.84 178,-915 188.64,-905.91 201.47,-899.83 215,-895.87"/>
<polygon fill="#000000" stroke="#000000" points="216.11,-899.2 224.95,-893.35 214.39,-892.41 216.11,-899.2"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node41" class="node">
<title>proc~torch_tensor_from_array_int8_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node41"><a xlink:href="../proc/torch_tensor_from_array_int8_5d_default_layout.html" xlink:title="torch_tensor_from_array_int8_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-864 184.5,-864 184.5,-840 452.5,-840 452.5,-864"/>
<text text-anchor="middle" x="318.5" y="-849.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge40" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-1238.84C80.67,-1178.51 119.38,-915.77 178,-864 202.3,-842.54 238.78,-837.66 268.34,-839.19"/>
<polygon fill="#000000" stroke="#000000" points="268.23,-842.69 278.47,-839.99 268.78,-835.72 268.23,-842.69"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node42" class="node">
<title>proc~torch_tensor_from_array_real32_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node42"><a xlink:href="../proc/torch_tensor_from_array_real32_1d.html" xlink:title="torch_tensor_from_array_real32_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-822 218.5,-822 218.5,-798 418.5,-798 418.5,-822"/>
<text text-anchor="middle" x="318.5" y="-807.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge41" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-1238.68C80.18,-1175.48 114.63,-888.46 178,-831 186.86,-822.97 197.41,-817.23 208.7,-813.22"/>
<polygon fill="#000000" stroke="#000000" points="209.81,-816.54 218.32,-810.23 207.73,-809.85 209.81,-816.54"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node43" class="node">
<title>proc~torch_tensor_from_array_real32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node43"><a xlink:href="../proc/torch_tensor_from_array_real32_1d_default_layout.html" xlink:title="torch_tensor_from_array_real32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-780 178,-780 178,-756 459,-756 459,-780"/>
<text text-anchor="middle" x="318.5" y="-765.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge42" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-1238.99C77.64,-1173.97 105.89,-867.49 170.78,-787.78"/>
<polygon fill="#000000" stroke="#000000" points="173.39,-790.11 177.59,-780.38 168.24,-785.36 173.39,-790.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node44" class="node">
<title>proc~torch_tensor_from_array_real32_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node44"><a xlink:href="../proc/torch_tensor_from_array_real32_2d.html" xlink:title="torch_tensor_from_array_real32_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-738 218.5,-738 218.5,-714 418.5,-714 418.5,-738"/>
<text text-anchor="middle" x="318.5" y="-723.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge43" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-1238.64C77.25,-1168.16 103.22,-817.57 178,-747 186.77,-738.73 197.32,-732.86 208.65,-728.78"/>
<polygon fill="#000000" stroke="#000000" points="209.82,-732.08 218.32,-725.75 207.73,-725.39 209.82,-732.08"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node45" class="node">
<title>proc~torch_tensor_from_array_real32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node45"><a xlink:href="../proc/torch_tensor_from_array_real32_2d_default_layout.html" xlink:title="torch_tensor_from_array_real32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-696 178,-696 178,-672 459,-672 459,-696"/>
<text text-anchor="middle" x="318.5" y="-681.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge44" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.43,-1238.73C75.41,-1166.21 95.36,-797.29 170.79,-703.91"/>
<polygon fill="#000000" stroke="#000000" points="173.41,-706.22 177.52,-696.46 168.22,-701.53 173.41,-706.22"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node46" class="node">
<title>proc~torch_tensor_from_array_real32_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node46"><a xlink:href="../proc/torch_tensor_from_array_real32_3d.html" xlink:title="torch_tensor_from_array_real32_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-654 218.5,-654 218.5,-630 418.5,-630 418.5,-654"/>
<text text-anchor="middle" x="318.5" y="-639.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge45" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.34,-1238.68C74.76,-1161.64 91.69,-746.84 178,-663 186.71,-654.53 197.29,-648.56 208.68,-644.43"/>
<polygon fill="#000000" stroke="#000000" points="209.92,-647.71 218.41,-641.38 207.82,-641.03 209.92,-647.71"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node47" class="node">
<title>proc~torch_tensor_from_array_real32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node47"><a xlink:href="../proc/torch_tensor_from_array_real32_3d_default_layout.html" xlink:title="torch_tensor_from_array_real32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-612 178,-612 178,-588 459,-588 459,-612"/>
<text text-anchor="middle" x="318.5" y="-597.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge46" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.15,-1238.78C73.39,-1160 84.45,-727.04 170.82,-619.96"/>
<polygon fill="#000000" stroke="#000000" points="173.65,-622.05 177.73,-612.27 168.44,-617.37 173.65,-622.05"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node48" class="node">
<title>proc~torch_tensor_from_array_real32_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node48"><a xlink:href="../proc/torch_tensor_from_array_real32_4d.html" xlink:title="torch_tensor_from_array_real32_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-570 218.5,-570 218.5,-546 418.5,-546 418.5,-570"/>
<text text-anchor="middle" x="318.5" y="-555.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge47" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.04,-1238.86C72.6,-1156.17 80.05,-676.27 178,-579 186.62,-570.44 197.14,-564.41 208.5,-560.25"/>
<polygon fill="#000000" stroke="#000000" points="209.73,-563.53 218.21,-557.18 207.62,-556.85 209.73,-563.53"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node49" class="node">
<title>proc~torch_tensor_from_array_real32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node49"><a xlink:href="../proc/torch_tensor_from_array_real32_4d_default_layout.html" xlink:title="torch_tensor_from_array_real32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-528 178,-528 178,-504 459,-504 459,-528"/>
<text text-anchor="middle" x="318.5" y="-513.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge48" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.93,-1238.85C71.6,-1154.28 73.35,-656.87 170.82,-536.03"/>
<polygon fill="#000000" stroke="#000000" points="173.66,-538.11 177.69,-528.31 168.43,-533.45 173.66,-538.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node50" class="node">
<title>proc~torch_tensor_from_array_real32_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node50"><a xlink:href="../proc/torch_tensor_from_array_real32_5d.html" xlink:title="torch_tensor_from_array_real32_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-486 218.5,-486 218.5,-462 418.5,-462 418.5,-486"/>
<text text-anchor="middle" x="318.5" y="-471.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge49" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.81,-1238.81C70.7,-1150.21 68.44,-605.67 178,-495 186.62,-486.3 197.19,-480.19 208.62,-476"/>
<polygon fill="#000000" stroke="#000000" points="209.92,-479.26 218.41,-472.92 207.82,-472.59 209.92,-479.26"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node51" class="node">
<title>proc~torch_tensor_from_array_real32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node51"><a xlink:href="../proc/torch_tensor_from_array_real32_5d_default_layout.html" xlink:title="torch_tensor_from_array_real32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-444 178,-444 178,-420 459,-420 459,-444"/>
<text text-anchor="middle" x="318.5" y="-429.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge50" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.63,-1238.83C77.99,-1145.56 116.76,-548.68 171.76,-452.63"/>
<polygon fill="#000000" stroke="#000000" points="174.7,-454.53 177.66,-444.35 169,-450.46 174.7,-454.53"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node52" class="node">
<title>proc~torch_tensor_from_array_real64_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node52"><a xlink:href="../proc/torch_tensor_from_array_real64_1d.html" xlink:title="torch_tensor_from_array_real64_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-402 218.5,-402 218.5,-378 418.5,-378 418.5,-402"/>
<text text-anchor="middle" x="318.5" y="-387.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge51" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.66,-1238.84C78.12,-1140.19 117.16,-473.31 178,-411 186.56,-402.24 197.09,-396.1 208.5,-391.89"/>
<polygon fill="#000000" stroke="#000000" points="209.8,-395.15 218.28,-388.79 207.69,-388.48 209.8,-395.15"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node53" class="node">
<title>proc~torch_tensor_from_array_real64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node53"><a xlink:href="../proc/torch_tensor_from_array_real64_1d_default_layout.html" xlink:title="torch_tensor_from_array_real64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-360 178,-360 178,-336 459,-336 459,-360"/>
<text text-anchor="middle" x="318.5" y="-345.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge52" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.51,-1238.73C77.01,-1139.45 111.49,-472.45 171.72,-368.64"/>
<polygon fill="#000000" stroke="#000000" points="174.65,-370.56 177.62,-360.39 168.96,-366.49 174.65,-370.56"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node54" class="node">
<title>proc~torch_tensor_from_array_real64_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node54"><a xlink:href="../proc/torch_tensor_from_array_real64_2d.html" xlink:title="torch_tensor_from_array_real64_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-318 218.5,-318 218.5,-294 418.5,-294 418.5,-318"/>
<text text-anchor="middle" x="318.5" y="-303.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge53" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.51,-1238.96C77,-1135.35 111.27,-396.12 178,-327 186.51,-318.19 197.01,-312.02 208.41,-307.8"/>
<polygon fill="#000000" stroke="#000000" points="209.7,-311.06 218.17,-304.69 207.58,-304.39 209.7,-311.06"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node55" class="node">
<title>proc~torch_tensor_from_array_real64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node55"><a xlink:href="../proc/torch_tensor_from_array_real64_2d_default_layout.html" xlink:title="torch_tensor_from_array_real64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-276 178,-276 178,-252 459,-252 459,-276"/>
<text text-anchor="middle" x="318.5" y="-261.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge54" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.39,-1238.76C76.08,-1134.25 106.06,-396.98 171.56,-284.85"/>
<polygon fill="#000000" stroke="#000000" points="174.61,-286.6 177.59,-276.43 168.92,-282.52 174.61,-286.6"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node56" class="node">
<title>proc~torch_tensor_from_array_real64_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node56"><a xlink:href="../proc/torch_tensor_from_array_real64_3d.html" xlink:title="torch_tensor_from_array_real64_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-234 218.5,-234 218.5,-210 418.5,-210 418.5,-234"/>
<text text-anchor="middle" x="318.5" y="-219.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge55" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.39,-1238.92C76.02,-1129.96 105.41,-318.91 178,-243 186.53,-234.08 197.11,-227.86 208.59,-223.62"/>
<polygon fill="#000000" stroke="#000000" points="209.95,-226.86 218.43,-220.51 207.84,-220.19 209.95,-226.86"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node57" class="node">
<title>proc~torch_tensor_from_array_real64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node57"><a xlink:href="../proc/torch_tensor_from_array_real64_3d_default_layout.html" xlink:title="torch_tensor_from_array_real64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-192 178,-192 178,-168 459,-168 459,-192"/>
<text text-anchor="middle" x="318.5" y="-177.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge56" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.29,-1238.91C75.22,-1129.76 100.61,-319.43 171.68,-200.58"/>
<polygon fill="#000000" stroke="#000000" points="174.52,-202.63 177.56,-192.48 168.85,-198.52 174.52,-202.63"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node58" class="node">
<title>proc~torch_tensor_from_array_real64_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node58"><a xlink:href="../proc/torch_tensor_from_array_real64_4d.html" xlink:title="torch_tensor_from_array_real64_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-150 218.5,-150 218.5,-126 418.5,-126 418.5,-150"/>
<text text-anchor="middle" x="318.5" y="-135.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge57" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.29,-1238.65C75.16,-1123.59 99.59,-241.65 178,-159 186.49,-150.05 197.05,-143.8 208.52,-139.55"/>
<polygon fill="#000000" stroke="#000000" points="209.88,-142.79 218.36,-136.43 207.77,-136.12 209.88,-142.79"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node59" class="node">
<title>proc~torch_tensor_from_array_real64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node59"><a xlink:href="../proc/torch_tensor_from_array_real64_4d_default_layout.html" xlink:title="torch_tensor_from_array_real64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-108 178,-108 178,-84 459,-84 459,-108"/>
<text text-anchor="middle" x="318.5" y="-93.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge58" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.21,-1238.81C74.45,-1124.32 95.11,-242.75 171.66,-116.55"/>
<polygon fill="#000000" stroke="#000000" points="174.66,-118.39 177.76,-108.26 169.02,-114.24 174.66,-118.39"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node60" class="node">
<title>proc~torch_tensor_from_array_real64_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node60"><a xlink:href="../proc/torch_tensor_from_array_real64_5d.html" xlink:title="torch_tensor_from_array_real64_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-66 218.5,-66 218.5,-42 418.5,-42 418.5,-66"/>
<text text-anchor="middle" x="318.5" y="-51.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge59" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.2,-1238.84C74.29,-1119.78 93.65,-164.52 178,-75 186.46,-66.02 197,-59.76 208.47,-55.5"/>
<polygon fill="#000000" stroke="#000000" points="209.82,-58.74 218.29,-52.37 207.7,-52.07 209.82,-58.74"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node61" class="node">
<title>proc~torch_tensor_from_array_real64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node61"><a xlink:href="../proc/torch_tensor_from_array_real64_5d_default_layout.html" xlink:title="torch_tensor_from_array_real64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-24 178,-24 178,0 459,0 459,-24"/>
<text text-anchor="middle" x="318.5" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge60" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.14,-1238.8C73.72,-1119.43 89.55,-165.53 171.71,-32.42"/>
<polygon fill="#000000" stroke="#000000" points="174.6,-34.4 177.74,-24.28 168.98,-30.23 174.6,-34.4"/>
</g>
<!-- proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node62" class="node">
<title>proc~torch_tensor_from_blob</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node62"><a xlink:href="../proc/torch_tensor_from_blob.html" xlink:title="torch_tensor_from_blob">
<polygon fill="#d9534f" stroke="#d9534f" points="632,-1284 495,-1284 495,-1260 632,-1260 632,-1284"/>
<text text-anchor="middle" x="563.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_blob</text>
</a>
</g>
</g>
<!-- proc~torch_tensor_from_array_int16_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge61" class="edge">
<title>proc~torch_tensor_from_array_int16_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.19,-2492.56C431.74,-2488.63 447.35,-2481.41 459,-2469 542.57,-2379.98 559.85,-1452.49 562.19,-1294.74"/>
<polygon fill="#000000" stroke="#000000" points="565.7,-1294.42 562.34,-1284.37 558.7,-1294.32 565.7,-1294.42"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge62" class="edge">
<title>proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.6,-2460.04C253.54,-2465.61 205.12,-2464.79 178,-2436 95.37,-2348.3 75.11,-1429.74 72.35,-1273.48"/>
<polygon fill="#000000" stroke="#000000" points="75.85,-1273.14 72.18,-1263.2 68.85,-1273.26 75.85,-1273.14"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge63" class="edge">
<title>proc~torch_tensor_from_array_int16_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.12,-2408.5C431.69,-2404.57 447.31,-2397.37 459,-2385 536.77,-2302.69 558.77,-1445.17 562.04,-1294.53"/>
<polygon fill="#000000" stroke="#000000" points="565.55,-1294.29 562.26,-1284.22 558.55,-1294.15 565.55,-1294.29"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge64" class="edge">
<title>proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.34,-2376.05C253.32,-2381.54 205.14,-2380.61 178,-2352 101.18,-2271.03 76.17,-1422.88 72.5,-1273.38"/>
<polygon fill="#000000" stroke="#000000" points="75.99,-1273.06 72.25,-1263.15 68.99,-1273.23 75.99,-1273.06"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge65" class="edge">
<title>proc~torch_tensor_from_array_int16_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.05,-2324.43C431.62,-2320.51 447.26,-2313.33 459,-2301 530.94,-2225.43 557.57,-1438.68 561.86,-1294.59"/>
<polygon fill="#000000" stroke="#000000" points="565.37,-1294.43 562.16,-1284.33 558.37,-1294.22 565.37,-1294.43"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge66" class="edge">
<title>proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.39,-2292.01C253.4,-2297.46 205.25,-2296.5 178,-2268 106.95,-2193.71 77.29,-1415.21 72.66,-1273.13"/>
<polygon fill="#000000" stroke="#000000" points="76.15,-1272.89 72.34,-1263.01 69.16,-1273.12 76.15,-1272.89"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge67" class="edge">
<title>proc~torch_tensor_from_array_int16_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.32,-2240.26C431.76,-2236.33 447.29,-2229.19 459,-2217 525.16,-2148.11 556.3,-1431.09 561.66,-1294.43"/>
<polygon fill="#000000" stroke="#000000" points="565.16,-1294.44 562.05,-1284.31 558.16,-1294.17 565.16,-1294.44"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge68" class="edge">
<title>proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.14,-2208C253.2,-2213.35 205.3,-2212.28 178,-2184 112.76,-2116.42 78.54,-1408.19 72.85,-1273.12"/>
<polygon fill="#000000" stroke="#000000" points="76.35,-1272.96 72.44,-1263.11 69.35,-1273.25 76.35,-1272.96"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge69" class="edge">
<title>proc~torch_tensor_from_array_int16_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.22,-2156.17C431.67,-2152.24 447.23,-2145.13 459,-2133 519.37,-2070.8 554.88,-1423.71 561.41,-1294.41"/>
<polygon fill="#000000" stroke="#000000" points="564.91,-1294.31 561.92,-1284.15 557.92,-1293.96 564.91,-1294.31"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge70" class="edge">
<title>proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M284.61,-2124.04C252.73,-2129.22 205.29,-2127.95 178,-2100 118.57,-2039.13 79.94,-1401.37 73.09,-1273.26"/>
<polygon fill="#000000" stroke="#000000" points="76.58,-1272.89 72.56,-1263.08 69.59,-1273.25 76.58,-1272.89"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge71" class="edge">
<title>proc~torch_tensor_from_array_int32_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.1,-2072.04C431.56,-2068.13 447.15,-2061.05 459,-2049 513.59,-1993.48 553.29,-1416.21 561.1,-1294.46"/>
<polygon fill="#000000" stroke="#000000" points="564.61,-1294.34 561.75,-1284.14 557.63,-1293.9 564.61,-1294.34"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge72" class="edge">
<title>proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M284.39,-2040C252.57,-2045.07 205.4,-2043.67 178,-2016 71.18,-1908.1 70.66,-1387.76 71.73,-1273.23"/>
<polygon fill="#000000" stroke="#000000" points="75.23,-1273.21 71.84,-1263.17 68.23,-1273.13 75.23,-1273.21"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge73" class="edge">
<title>proc~torch_tensor_from_array_int32_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.3,-1987.81C431.64,-1983.89 447.14,-1976.87 459,-1965 556.14,-1867.74 562.43,-1402.1 562.57,-1294.31"/>
<polygon fill="#000000" stroke="#000000" points="566.07,-1294.24 562.57,-1284.24 559.07,-1294.24 566.07,-1294.24"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge74" class="edge">
<title>proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M283.59,-1956.04C251.87,-1960.86 205.37,-1959.18 178,-1932 82.68,-1837.35 73.06,-1380.37 72.1,-1273.35"/>
<polygon fill="#000000" stroke="#000000" points="75.6,-1273.05 72.03,-1263.08 68.6,-1273.1 75.6,-1273.05"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge75" class="edge">
<title>proc~torch_tensor_from_array_int32_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.11,-1903.62C431.47,-1899.72 447.03,-1892.75 459,-1881 544.68,-1796.92 559.66,-1394.16 562.07,-1294.4"/>
<polygon fill="#000000" stroke="#000000" points="565.57,-1294.32 562.29,-1284.25 558.57,-1294.17 565.57,-1294.32"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge76" class="edge">
<title>proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.82,-1872.04C251.21,-1876.6 205.4,-1874.62 178,-1848 94,-1766.4 75.72,-1371.3 72.57,-1273.04"/>
<polygon fill="#000000" stroke="#000000" points="76.07,-1272.93 72.27,-1263.03 69.07,-1273.13 76.07,-1272.93"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge77" class="edge">
<title>proc~torch_tensor_from_array_int32_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.22,-1819.28C431.47,-1815.38 446.96,-1808.51 459,-1797 533.3,-1725.99 556.48,-1385.51 561.4,-1294.44"/>
<polygon fill="#000000" stroke="#000000" points="564.9,-1294.56 561.93,-1284.39 557.91,-1294.19 564.9,-1294.56"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge78" class="edge">
<title>proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M281.77,-1788.02C250.34,-1792.23 205.43,-1789.89 178,-1764 105.51,-1695.58 78.88,-1364.03 73.22,-1273.65"/>
<polygon fill="#000000" stroke="#000000" points="76.7,-1273.19 72.6,-1263.42 69.71,-1273.61 76.7,-1273.19"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge79" class="edge">
<title>proc~torch_tensor_from_array_int32_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.25,-1734.84C431.4,-1730.96 446.85,-1724.21 459,-1713 522.09,-1654.83 552.83,-1375.35 560.53,-1294.16"/>
<polygon fill="#000000" stroke="#000000" points="564.02,-1294.34 561.46,-1284.06 557.05,-1293.7 564.02,-1294.34"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge80" class="edge">
<title>proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M279.86,-1704.03C248.72,-1707.66 205.31,-1704.76 178,-1680 116.68,-1624.4 82.44,-1353.83 74.05,-1273.41"/>
<polygon fill="#000000" stroke="#000000" points="77.52,-1272.97 73.03,-1263.37 70.55,-1273.67 77.52,-1272.97"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge81" class="edge">
<title>proc~torch_tensor_from_array_int64_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.15,-1650.24C431.21,-1646.4 446.65,-1639.81 459,-1629 510.85,-1583.61 548.22,-1365.48 559.19,-1294.43"/>
<polygon fill="#000000" stroke="#000000" points="562.68,-1294.75 560.72,-1284.33 555.76,-1293.7 562.68,-1294.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge82" class="edge">
<title>proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M276.15,-1620.02C245.6,-1622.7 204.81,-1618.92 178,-1596 79.3,-1511.62 71.4,-1336.13 71.58,-1273.53"/>
<polygon fill="#000000" stroke="#000000" points="75.09,-1273.24 71.69,-1263.2 68.09,-1273.17 75.09,-1273.24"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge83" class="edge">
<title>proc~torch_tensor_from_array_int64_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.18,-1565.24C431.05,-1561.46 446.42,-1555.15 459,-1545 538.92,-1480.52 557.16,-1347.12 561.3,-1294.27"/>
<polygon fill="#000000" stroke="#000000" points="564.79,-1294.48 561.99,-1284.27 557.81,-1294.01 564.79,-1294.48"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge84" class="edge">
<title>proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-1514.4C180.15,-1513.63 179.06,-1512.83 178,-1512 100.69,-1451.87 79.14,-1324.94 73.69,-1273.26"/>
<polygon fill="#000000" stroke="#000000" points="77.16,-1272.78 72.74,-1263.15 70.19,-1273.44 77.16,-1272.78"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge85" class="edge">
<title>proc~torch_tensor_from_array_int64_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.15,-1479.51C430.77,-1475.86 446.05,-1470.04 459,-1461 517.72,-1419.99 546.5,-1334.62 557.28,-1294.17"/>
<polygon fill="#000000" stroke="#000000" points="560.73,-1294.8 559.8,-1284.25 553.94,-1293.08 560.73,-1294.8"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge86" class="edge">
<title>proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.43,-1430.14C180.27,-1429.45 179.13,-1428.74 178,-1428 121.26,-1390.93 89.17,-1311.77 77.32,-1272.92"/>
<polygon fill="#000000" stroke="#000000" points="80.62,-1271.75 74.51,-1263.1 73.89,-1273.67 80.62,-1271.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge87" class="edge">
<title>proc~torch_tensor_from_array_int64_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.1,-1391.97C430.31,-1388.68 445.47,-1383.89 459,-1377 498,-1357.14 531.08,-1316.96 548.75,-1292.47"/>
<polygon fill="#000000" stroke="#000000" points="551.65,-1294.42 554.54,-1284.22 545.93,-1290.4 551.65,-1294.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge88" class="edge">
<title>proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.4,-1345.43C180.26,-1344.96 179.12,-1344.49 178,-1344 139.62,-1327.33 103.3,-1293.15 84.78,-1270.89"/>
<polygon fill="#000000" stroke="#000000" points="87.51,-1268.71 78.58,-1263.01 82.01,-1273.03 87.51,-1268.71"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge89" class="edge">
<title>proc~torch_tensor_from_array_int64_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M404.08,-1301.97C422.23,-1299.19 441.27,-1296.13 459,-1293 470.92,-1290.9 483.57,-1288.48 495.79,-1286.05"/>
<polygon fill="#000000" stroke="#000000" points="496.81,-1289.42 505.93,-1284.02 495.43,-1282.56 496.81,-1289.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge90" class="edge">
<title>proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.2,-1267.05C170.82,-1266.11 160.58,-1265.11 150.77,-1264.09"/>
<polygon fill="#000000" stroke="#000000" points="151.03,-1260.59 140.71,-1263.01 150.28,-1267.55 151.03,-1260.59"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge91" class="edge">
<title>proc~torch_tensor_from_array_int8_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M404.08,-1242.03C422.23,-1244.81 441.27,-1247.87 459,-1251 470.92,-1253.1 483.57,-1255.52 495.79,-1257.95"/>
<polygon fill="#000000" stroke="#000000" points="495.43,-1261.44 505.93,-1259.98 496.81,-1254.58 495.43,-1261.44"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge92" class="edge">
<title>proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.04,-1200C244.51,-1204.39 208.86,-1209.68 178,-1218 160.83,-1222.63 142.65,-1229.19 126.29,-1235.35"/>
<polygon fill="#000000" stroke="#000000" points="124.99,-1232.1 116.88,-1238.92 127.47,-1238.65 124.99,-1232.1"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge93" class="edge">
<title>proc~torch_tensor_from_array_int8_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.16,-1151.41C428.35,-1154.72 444.6,-1159.66 459,-1167 498,-1186.86 531.08,-1227.04 548.75,-1251.53"/>
<polygon fill="#000000" stroke="#000000" points="545.93,-1253.6 554.54,-1259.78 551.65,-1249.58 545.93,-1253.6"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge94" class="edge">
<title>proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M230.57,-1116.04C212.39,-1119.58 193.92,-1125.09 178,-1134 136.72,-1157.11 104.52,-1203 86.9,-1230.12"/>
<polygon fill="#000000" stroke="#000000" points="83.75,-1228.56 81.29,-1238.87 89.64,-1232.34 83.75,-1228.56"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge95" class="edge">
<title>proc~torch_tensor_from_array_int8_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.25,-1063.84C428.86,-1067.43 445.25,-1073.39 459,-1083 517.72,-1124.01 546.5,-1209.38 557.28,-1249.83"/>
<polygon fill="#000000" stroke="#000000" points="553.94,-1250.92 559.8,-1259.75 560.73,-1249.2 553.94,-1250.92"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge96" class="edge">
<title>proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M217.61,-1032.01C203.43,-1035.85 189.71,-1041.53 178,-1050 116.06,-1094.82 88.03,-1186.39 77.43,-1228.84"/>
<polygon fill="#000000" stroke="#000000" points="73.98,-1228.21 75.05,-1238.75 80.79,-1229.85 73.98,-1228.21"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge97" class="edge">
<title>proc~torch_tensor_from_array_int8_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.28,-978.1C429.18,-981.79 445.66,-988.23 459,-999 538.92,-1063.48 557.16,-1196.88 561.3,-1249.73"/>
<polygon fill="#000000" stroke="#000000" points="557.81,-1249.99 561.99,-1259.73 564.79,-1249.52 557.81,-1249.99"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge98" class="edge">
<title>proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M212.39,-948.06C199.89,-952.04 188.04,-957.77 178,-966 94.59,-1034.44 76.8,-1173.95 73.02,-1228.6"/>
<polygon fill="#000000" stroke="#000000" points="69.5,-1228.73 72.4,-1238.92 76.49,-1229.15 69.5,-1228.73"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge99" class="edge">
<title>proc~torch_tensor_from_array_int8_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.26,-893.11C429.36,-896.83 445.92,-903.55 459,-915 510.85,-960.39 548.22,-1178.52 559.19,-1249.57"/>
<polygon fill="#000000" stroke="#000000" points="555.76,-1250.3 560.72,-1259.67 562.68,-1249.25 555.76,-1250.3"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge100" class="edge">
<title>proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M209.72,-864.1C198.09,-868.15 187.18,-873.89 178,-882 124.05,-929.64 86.97,-1155.95 75.65,-1228.65"/>
<polygon fill="#000000" stroke="#000000" points="72.12,-1228.53 74.05,-1238.94 79.04,-1229.6 72.12,-1228.53"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge101" class="edge">
<title>proc~torch_tensor_from_array_real32_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.83,-810.07C433.67,-814.06 447.75,-820.62 459,-831 522.09,-889.17 552.83,-1168.65 560.53,-1249.84"/>
<polygon fill="#000000" stroke="#000000" points="557.05,-1250.3 561.46,-1259.94 564.02,-1249.66 557.05,-1250.3"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge102" class="edge">
<title>proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.3,-780.05C197.13,-784.16 186.71,-789.93 178,-798 112.79,-858.43 82.15,-1145.96 74.17,-1228.78"/>
<polygon fill="#000000" stroke="#000000" points="70.68,-1228.58 73.22,-1238.86 77.65,-1229.24 70.68,-1228.58"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge103" class="edge">
<title>proc~torch_tensor_from_array_real32_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.79,-725.63C433.73,-729.65 447.85,-736.34 459,-747 533.3,-818.01 556.48,-1158.49 561.4,-1249.56"/>
<polygon fill="#000000" stroke="#000000" points="557.91,-1249.81 561.93,-1259.61 564.9,-1249.44 557.91,-1249.81"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge104" class="edge">
<title>proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.34,-696.02C196.48,-700.16 186.4,-705.95 178,-714 101.55,-787.28 78.29,-1135.84 73.19,-1228.48"/>
<polygon fill="#000000" stroke="#000000" points="69.69,-1228.52 72.65,-1238.69 76.68,-1228.9 69.69,-1228.52"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge105" class="edge">
<title>proc~torch_tensor_from_array_real32_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.68,-641.29C433.72,-645.33 447.9,-652.11 459,-663 544.68,-747.08 559.66,-1149.84 562.07,-1249.6"/>
<polygon fill="#000000" stroke="#000000" points="558.57,-1249.83 562.29,-1259.75 565.57,-1249.68 558.57,-1249.83"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge106" class="edge">
<title>proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M206.45,-612.08C195.9,-616.24 186.12,-622.02 178,-630 90.12,-716.37 74.94,-1127.38 72.46,-1228.57"/>
<polygon fill="#000000" stroke="#000000" points="68.95,-1228.77 72.23,-1238.85 75.95,-1228.93 68.95,-1228.77"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge107" class="edge">
<title>proc~torch_tensor_from_array_real32_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.51,-557C433.67,-561.05 447.92,-567.91 459,-579 556.14,-676.26 562.43,-1141.9 562.57,-1249.69"/>
<polygon fill="#000000" stroke="#000000" points="559.07,-1249.76 562.57,-1259.76 566.07,-1249.76 559.07,-1249.76"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge108" class="edge">
<title>proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.96,-528.06C195.56,-532.24 185.96,-538.03 178,-546 78.61,-645.59 72.02,-1119.83 71.91,-1228.76"/>
<polygon fill="#000000" stroke="#000000" points="68.41,-1228.92 71.91,-1238.92 75.41,-1228.92 68.41,-1228.92"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge109" class="edge">
<title>proc~torch_tensor_from_array_real32_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.66,-472.86C433.8,-476.92 448.01,-483.82 459,-495 513.59,-550.52 553.29,-1127.79 561.1,-1249.54"/>
<polygon fill="#000000" stroke="#000000" points="557.63,-1250.1 561.75,-1259.86 564.61,-1249.66 557.63,-1250.1"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge110" class="edge">
<title>proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.5,-444.07C195.25,-448.27 185.81,-454.05 178,-462 122.19,-518.79 81.75,-1106.82 73.54,-1228.95"/>
<polygon fill="#000000" stroke="#000000" points="70.04,-1228.78 72.86,-1238.99 77.02,-1229.25 70.04,-1228.78"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge111" class="edge">
<title>proc~torch_tensor_from_array_real64_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.78,-388.74C433.91,-392.82 448.08,-399.75 459,-411 519.37,-473.2 554.88,-1120.29 561.41,-1249.59"/>
<polygon fill="#000000" stroke="#000000" points="557.92,-1250.04 561.92,-1259.85 564.91,-1249.69 557.92,-1250.04"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge112" class="edge">
<title>proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.06,-360.12C194.96,-364.31 185.68,-370.09 178,-378 116.42,-441.44 80.11,-1098.94 73.21,-1228.85"/>
<polygon fill="#000000" stroke="#000000" points="69.71,-1228.66 72.68,-1238.84 76.7,-1229.03 69.71,-1228.66"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge113" class="edge">
<title>proc~torch_tensor_from_array_real64_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.53,-304.55C433.77,-308.62 448.06,-315.61 459,-327 525.16,-395.89 556.3,-1112.91 561.66,-1249.57"/>
<polygon fill="#000000" stroke="#000000" points="558.16,-1249.83 562.05,-1259.69 565.16,-1249.56 558.16,-1249.83"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge114" class="edge">
<title>proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.98,-276.03C194.9,-280.25 185.64,-286.05 178,-294 110.64,-364.12 78.64,-1091.23 72.94,-1228.71"/>
<polygon fill="#000000" stroke="#000000" points="69.44,-1228.74 72.52,-1238.88 76.43,-1229.03 69.44,-1228.74"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge115" class="edge">
<title>proc~torch_tensor_from_array_real64_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.61,-220.47C433.85,-224.55 448.11,-231.56 459,-243 530.94,-318.57 557.57,-1105.32 561.86,-1249.41"/>
<polygon fill="#000000" stroke="#000000" points="558.37,-1249.78 562.16,-1259.67 565.37,-1249.57 558.37,-1249.78"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge116" class="edge">
<title>proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.57,-192.11C194.63,-196.32 185.52,-202.11 178,-210 104.88,-286.78 77.33,-1083.21 72.72,-1228.41"/>
<polygon fill="#000000" stroke="#000000" points="69.21,-1228.64 72.39,-1238.75 76.21,-1228.86 69.21,-1228.64"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge117" class="edge">
<title>proc~torch_tensor_from_array_real64_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.68,-136.4C433.91,-140.49 448.15,-147.52 459,-159 536.77,-241.31 558.77,-1098.83 562.04,-1249.47"/>
<polygon fill="#000000" stroke="#000000" points="558.55,-1249.85 562.26,-1259.78 565.55,-1249.71 558.55,-1249.85"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge118" class="edge">
<title>proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.51,-108.05C194.59,-112.28 185.49,-118.08 178,-126 99.07,-209.5 76.08,-1076.28 72.52,-1228.35"/>
<polygon fill="#000000" stroke="#000000" points="69.01,-1228.67 72.28,-1238.75 76.01,-1228.83 69.01,-1228.67"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge119" class="edge">
<title>proc~torch_tensor_from_array_real64_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.75,-52.34C433.97,-56.44 448.19,-63.48 459,-75 542.57,-164.02 559.85,-1091.51 562.19,-1249.26"/>
<polygon fill="#000000" stroke="#000000" points="558.7,-1249.68 562.34,-1259.63 565.7,-1249.58 558.7,-1249.68"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge120" class="edge">
<title>proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.46,-24C194.54,-28.24 185.46,-34.06 178,-42 93.2,-132.28 74.92,-1070.45 72.35,-1228.51"/>
<polygon fill="#000000" stroke="#000000" points="68.84,-1228.83 72.19,-1238.88 75.84,-1228.94 68.84,-1228.83"/>
</g>
<!-- interface~torch_from_blob_c -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node63" class="node">
<title>interface~torch_from_blob_c</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node63"><a xlink:href="../interface/torch_from_blob_c.html" xlink:title="torch_from_blob_c">
<polygon fill="#a7506f" stroke="#a7506f" points="777,-1284 668,-1284 668,-1260 777,-1260 777,-1284"/>
<text text-anchor="middle" x="722.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_from_blob_c</text>
</a>
</g>
</g>
<!-- proc~torch_tensor_from_blob&#45;&gt;interface~torch_from_blob_c -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge121" class="edge">
<title>proc~torch_tensor_from_blob&#45;&gt;interface~torch_from_blob_c</title>
<path fill="none" stroke="#000000" d="M632.45,-1272C640.72,-1272 649.16,-1272 657.37,-1272"/>
<polygon fill="#000000" stroke="#000000" points="657.64,-1275.5 667.64,-1272 657.64,-1268.5 657.64,-1275.5"/>
</g>
</g>
</svg>
</div>                <script>
                  var paninterfacetorch_tensor_from_arrayCallsGraph = svgPanZoom('#interfacetorch_tensor_from_arrayCallsGraph',
                    {zoomEnabled: true, controlIconsEnabled: true, fit: true, center: true,}
                  );
                </script>          <div>
            <a type="button" class="graph-help" data-bs-toggle="modal" href="#CallsGraph-help-text">Help</a>
          </div>
          <div class="modal fade" id="CallsGraph-help-text" tabindex="-1" role="dialog">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title" id="-graph-help-label">Graph Key</h4>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
<p>Nodes of different colours represent the following: </p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: Graph Key Pages: 1 -->
<svg width="641pt" height="28pt"
 viewBox="0.00 0.00 641.00 27.51" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(0.86 0.86) rotate(0) translate(4 28)">
<title>Graph Key</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-28 741.5,-28 741.5,4 -4,4"/>
<!-- Subroutine -->
<g id="node1" class="node">
<title>Subroutine</title>
<polygon fill="#d9534f" stroke="#d9534f" points="70,-24 0,-24 0,0 70,0 70,-24"/>
<text text-anchor="middle" x="35" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Subroutine</text>
</g>
<!-- Function -->
<g id="node2" class="node">
<title>Function</title>
<polygon fill="#d94e8f" stroke="#d94e8f" points="146,-24 88,-24 88,0 146,0 146,-24"/>
<text text-anchor="middle" x="117" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Function</text>
</g>
<!-- Interface -->
<g id="node3" class="node">
<title>Interface</title>
<polygon fill="#a7506f" stroke="#a7506f" points="225.5,-24 164.5,-24 164.5,0 225.5,0 225.5,-24"/>
<text text-anchor="middle" x="195" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Interface</text>
</g>
<!-- Type Bound Procedure -->
<g id="node4" class="node">
<title>Type Bound Procedure</title>
<polygon fill="#a7506f" stroke="#a7506f" points="374,-24 244,-24 244,0 374,0 374,-24"/>
<text text-anchor="middle" x="309" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Type Bound Procedure</text>
</g>
<!-- Unknown Procedure Type -->
<g id="node5" class="node">
<title>Unknown Procedure Type</title>
<polygon fill="#777777" stroke="#777777" points="537.5,-24 392.5,-24 392.5,0 537.5,0 537.5,-24"/>
<text text-anchor="middle" x="465" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Unknown Procedure Type</text>
</g>
<!-- Program -->
<g id="node6" class="node">
<title>Program</title>
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="614,-24 556,-24 556,0 614,0 614,-24"/>
<text text-anchor="middle" x="585" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Program</text>
</g>
<!-- This Page&#39;s Entity -->
<g id="node7" class="node">
<title>This Page&#39;s Entity</title>
<polygon fill="none" stroke="black" points="737.5,-24 632.5,-24 632.5,0 737.5,0 737.5,-24"/>
<text text-anchor="middle" x="685" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50">This Page&#39;s Entity</text>
</g>
</g>
</svg>

<p>Solid arrows point from a procedure to one which it calls. Dashed 
arrows point from an interface to procedures which implement that interface.
This could include the module procedures in a generic interface or the
implementation in a submodule of an interface in a parent module.
</p>
 </div>
            </div>
          </div>
        </div>
          </div>
        </div>
        <div class="card">
          <div class="card-header">
            <h3 class="card-title">Called by</h3>
          </div>
          <div class="card-body">
            <div class="depgraph"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: interface~~torch_tensor_from_array~~CalledByGraph Pages: 1 -->
<svg id="interfacetorch_tensor_from_arrayCalledByGraph" width="467pt" height="1252pt"
 viewBox="0.00 0.00 467.00 1251.99" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="interface~~torch_tensor_from_array~~CalledByGraph" class="graph" transform="scale(1 1) rotate(0) translate(4 1247.99)">
<title>interface~~torch_tensor_from_array~~CalledByGraph</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-1247.99 463,-1247.99 463,4 -4,4"/>
<!-- interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node1" class="node">
<title>interface~torch_tensor_from_array</title>
<polygon fill="none" stroke="black" points="142,-633 0,-633 0,-609 142,-609 142,-633"/>
<text text-anchor="middle" x="71" y="-618.6" font-family="Helvetica,sans-Serif" font-size="10.50">torch_tensor_from_array</text>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node2" class="node">
<title>proc~torch_tensor_from_array_int16_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node2"><a xlink:href="../proc/torch_tensor_from_array_int16_1d_default_layout.html" xlink:title="torch_tensor_from_array_int16_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1242 181.5,-1242 181.5,-1218 455.5,-1218 455.5,-1242"/>
<text text-anchor="middle" x="318.5" y="-1227.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge31" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.42,-633.17C75.1,-709.38 92.53,-1116.97 178,-1200 183.81,-1205.64 190.44,-1210.17 197.58,-1213.81"/>
<polygon fill="#000000" stroke="#000000" points="196.33,-1217.08 206.89,-1217.96 199.18,-1210.69 196.33,-1217.08"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node3" class="node">
<title>proc~torch_tensor_from_array_int16_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node3"><a xlink:href="../proc/torch_tensor_from_array_int16_2d_default_layout.html" xlink:title="torch_tensor_from_array_int16_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1200 181.5,-1200 181.5,-1176 455.5,-1176 455.5,-1200"/>
<text text-anchor="middle" x="318.5" y="-1185.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge32" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.65,-633.31C76.44,-706.6 98.36,-1081.66 178,-1158 183.91,-1163.66 190.64,-1168.2 197.9,-1171.84"/>
<polygon fill="#000000" stroke="#000000" points="196.77,-1175.17 207.34,-1175.98 199.59,-1168.76 196.77,-1175.17"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node4" class="node">
<title>proc~torch_tensor_from_array_int16_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node4"><a xlink:href="../proc/torch_tensor_from_array_int16_3d_default_layout.html" xlink:title="torch_tensor_from_array_int16_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1158 181.5,-1158 181.5,-1134 455.5,-1134 455.5,-1158"/>
<text text-anchor="middle" x="318.5" y="-1143.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge33" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.9,-633.07C77.82,-702.43 104.03,-1046.19 178,-1116 184.01,-1121.67 190.86,-1126.22 198.23,-1129.85"/>
<polygon fill="#000000" stroke="#000000" points="197.24,-1133.23 207.81,-1133.98 200.01,-1126.8 197.24,-1133.23"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node5" class="node">
<title>proc~torch_tensor_from_array_int16_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node5"><a xlink:href="../proc/torch_tensor_from_array_int16_4d_default_layout.html" xlink:title="torch_tensor_from_array_int16_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1116 181.5,-1116 181.5,-1092 455.5,-1092 455.5,-1116"/>
<text text-anchor="middle" x="318.5" y="-1101.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge34" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.22,-633.14C79.4,-699.12 109.79,-1010.8 178,-1074 184.26,-1079.8 191.41,-1084.41 199.07,-1088.08"/>
<polygon fill="#000000" stroke="#000000" points="197.72,-1091.3 208.3,-1091.95 200.43,-1084.85 197.72,-1091.3"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node6" class="node">
<title>proc~torch_tensor_from_array_int16_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node6"><a xlink:href="../proc/torch_tensor_from_array_int16_5d_default_layout.html" xlink:title="torch_tensor_from_array_int16_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1074 181.5,-1074 181.5,-1050 455.5,-1050 455.5,-1074"/>
<text text-anchor="middle" x="318.5" y="-1059.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge35" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.58,-633.01C81.09,-695.05 115.46,-975.3 178,-1032 184.39,-1037.79 191.66,-1042.39 199.45,-1046.03"/>
<polygon fill="#000000" stroke="#000000" points="198.23,-1049.32 208.81,-1049.89 200.9,-1042.84 198.23,-1049.32"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node7" class="node">
<title>proc~torch_tensor_from_array_int32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node7"><a xlink:href="../proc/torch_tensor_from_array_int32_1d_default_layout.html" xlink:title="torch_tensor_from_array_int32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1032 181.5,-1032 181.5,-1008 455.5,-1008 455.5,-1032"/>
<text text-anchor="middle" x="318.5" y="-1017.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge36" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.05,-633.06C83.05,-691.32 121.17,-939.81 178,-990 184.67,-995.89 192.25,-1000.53 200.36,-1004.18"/>
<polygon fill="#000000" stroke="#000000" points="199.13,-1007.46 209.72,-1007.9 201.72,-1000.96 199.13,-1007.46"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node8" class="node">
<title>proc~torch_tensor_from_array_int32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node8"><a xlink:href="../proc/torch_tensor_from_array_int32_2d_default_layout.html" xlink:title="torch_tensor_from_array_int32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-990 181.5,-990 181.5,-966 455.5,-966 455.5,-990"/>
<text text-anchor="middle" x="318.5" y="-975.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge37" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.6,-633.16C71.15,-681.97 77.57,-862.15 178,-948 185.04,-954.02 193.05,-958.72 201.58,-962.38"/>
<polygon fill="#000000" stroke="#000000" points="200.43,-965.69 211.02,-965.97 202.91,-959.15 200.43,-965.69"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node9" class="node">
<title>proc~torch_tensor_from_array_int32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node9"><a xlink:href="../proc/torch_tensor_from_array_int32_3d_default_layout.html" xlink:title="torch_tensor_from_array_int32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-948 181.5,-948 181.5,-924 455.5,-924 455.5,-948"/>
<text text-anchor="middle" x="318.5" y="-933.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge38" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.4,-633.08C74.6,-677.85 88.65,-832.7 178,-906 185.45,-912.11 193.9,-916.84 202.87,-920.5"/>
<polygon fill="#000000" stroke="#000000" points="201.8,-923.83 212.39,-923.94 204.18,-917.25 201.8,-923.83"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node10" class="node">
<title>proc~torch_tensor_from_array_int32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node10"><a xlink:href="../proc/torch_tensor_from_array_int32_4d_default_layout.html" xlink:title="torch_tensor_from_array_int32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-906 181.5,-906 181.5,-882 455.5,-882 455.5,-906"/>
<text text-anchor="middle" x="318.5" y="-891.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge39" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.49,-633.1C78.6,-673.68 99.7,-803.1 178,-864 186.05,-870.26 195.17,-875.04 204.79,-878.69"/>
<polygon fill="#000000" stroke="#000000" points="203.98,-882.11 214.57,-881.98 206.21,-875.47 203.98,-882.11"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node11" class="node">
<title>proc~torch_tensor_from_array_int32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node11"><a xlink:href="../proc/torch_tensor_from_array_int32_5d_default_layout.html" xlink:title="torch_tensor_from_array_int32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-864 181.5,-864 181.5,-840 455.5,-840 455.5,-864"/>
<text text-anchor="middle" x="318.5" y="-849.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge40" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M75.05,-633.25C83.4,-669.32 110.67,-773.28 178,-822 186.96,-828.49 197.11,-833.34 207.73,-836.98"/>
<polygon fill="#000000" stroke="#000000" points="207.02,-840.42 217.61,-839.99 209.07,-833.72 207.02,-840.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node12" class="node">
<title>proc~torch_tensor_from_array_int64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node12"><a xlink:href="../proc/torch_tensor_from_array_int64_1d_default_layout.html" xlink:title="torch_tensor_from_array_int64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-822 181.5,-822 181.5,-798 455.5,-798 455.5,-822"/>
<text text-anchor="middle" x="318.5" y="-807.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge41" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M77.41,-633.31C89.34,-664.19 121.41,-743.03 178,-780 188.44,-786.82 200.24,-791.75 212.44,-795.36"/>
<polygon fill="#000000" stroke="#000000" points="211.74,-798.79 222.31,-797.98 213.54,-792.03 211.74,-798.79"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node13" class="node">
<title>proc~torch_tensor_from_array_int64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node13"><a xlink:href="../proc/torch_tensor_from_array_int64_2d_default_layout.html" xlink:title="torch_tensor_from_array_int64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-780 181.5,-780 181.5,-756 455.5,-756 455.5,-780"/>
<text text-anchor="middle" x="318.5" y="-765.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge42" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M81.29,-633.13C97.05,-657.87 131.86,-712.16 178,-738 191.06,-745.31 205.83,-750.33 220.76,-753.85"/>
<polygon fill="#000000" stroke="#000000" points="220.06,-757.28 230.57,-755.96 221.53,-750.44 220.06,-757.28"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node14" class="node">
<title>proc~torch_tensor_from_array_int64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node14"><a xlink:href="../proc/torch_tensor_from_array_int64_3d_default_layout.html" xlink:title="torch_tensor_from_array_int64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-738 181.5,-738 181.5,-714 455.5,-714 455.5,-738"/>
<text text-anchor="middle" x="318.5" y="-723.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge43" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M89.55,-633.17C109.11,-650.5 142.68,-680.66 178,-696 196.26,-703.93 216.98,-708.94 236.77,-712.38"/>
<polygon fill="#000000" stroke="#000000" points="236.26,-715.84 246.7,-713.99 237.39,-708.93 236.26,-715.84"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node15" class="node">
<title>proc~torch_tensor_from_array_int64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node15"><a xlink:href="../proc/torch_tensor_from_array_int64_4d_default_layout.html" xlink:title="torch_tensor_from_array_int64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-696 181.5,-696 181.5,-672 455.5,-672 455.5,-696"/>
<text text-anchor="middle" x="318.5" y="-681.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge44" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M116.88,-633.08C135.47,-640.17 157.45,-648.46 178,-654 205.24,-661.34 236.22,-666.33 262.05,-670.42"/>
<polygon fill="#000000" stroke="#000000" points="261.62,-673.89 272.04,-672 262.71,-666.98 261.62,-673.89"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node16" class="node">
<title>proc~torch_tensor_from_array_int64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node16"><a xlink:href="../proc/torch_tensor_from_array_int64_5d_default_layout.html" xlink:title="torch_tensor_from_array_int64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-654 181.5,-654 181.5,-630 455.5,-630 455.5,-654"/>
<text text-anchor="middle" x="318.5" y="-639.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge45" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-620.83C172.07,-622.69 207.33,-625.64 238.32,-628.87"/>
<polygon fill="#000000" stroke="#000000" points="238.34,-632.39 248.66,-629.98 239.09,-625.43 238.34,-632.39"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node17" class="node">
<title>proc~torch_tensor_from_array_int8_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node17"><a xlink:href="../proc/torch_tensor_from_array_int8_1d_default_layout.html" xlink:title="torch_tensor_from_array_int8_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-612 184.5,-612 184.5,-588 452.5,-588 452.5,-612"/>
<text text-anchor="middle" x="318.5" y="-597.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge46" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M140.71,-608.99C151.35,-607.82 162.67,-606.67 174.24,-605.59"/>
<polygon fill="#000000" stroke="#000000" points="174.82,-609.05 184.46,-604.65 174.19,-602.08 174.82,-609.05"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node18" class="node">
<title>proc~torch_tensor_from_array_int8_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node18"><a xlink:href="../proc/torch_tensor_from_array_int8_2d_default_layout.html" xlink:title="torch_tensor_from_array_int8_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-570 184.5,-570 184.5,-546 452.5,-546 452.5,-570"/>
<text text-anchor="middle" x="318.5" y="-555.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge47" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M85.06,-608.88C103.13,-597.48 137.19,-582.11 174.41,-571.15"/>
<polygon fill="#000000" stroke="#000000" points="175.77,-574.4 184.45,-568.32 173.87,-567.66 175.77,-574.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node19" class="node">
<title>proc~torch_tensor_from_array_int8_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node19"><a xlink:href="../proc/torch_tensor_from_array_int8_3d_default_layout.html" xlink:title="torch_tensor_from_array_int8_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-528 184.5,-528 184.5,-504 452.5,-504 452.5,-528"/>
<text text-anchor="middle" x="318.5" y="-513.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge48" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M78.58,-608.99C93.09,-589.18 129.73,-551.86 175.27,-529.58"/>
<polygon fill="#000000" stroke="#000000" points="176.88,-532.7 184.5,-525.34 173.95,-526.34 176.88,-532.7"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node20" class="node">
<title>proc~torch_tensor_from_array_int8_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node20"><a xlink:href="../proc/torch_tensor_from_array_int8_4d_default_layout.html" xlink:title="torch_tensor_from_array_int8_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-486 184.5,-486 184.5,-462 452.5,-462 452.5,-486"/>
<text text-anchor="middle" x="318.5" y="-471.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge49" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M76.14,-608.67C87.59,-582.12 122.11,-521.74 175.48,-487.94"/>
<polygon fill="#000000" stroke="#000000" points="177.4,-490.87 184.21,-482.75 173.82,-484.86 177.4,-490.87"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node21" class="node">
<title>proc~torch_tensor_from_array_int8_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node21"><a xlink:href="../proc/torch_tensor_from_array_int8_5d_default_layout.html" xlink:title="torch_tensor_from_array_int8_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-444 184.5,-444 184.5,-420 452.5,-420 452.5,-444"/>
<text text-anchor="middle" x="318.5" y="-429.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge50" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.51,-608.9C82.99,-576.86 113.29,-491.91 176.07,-445.88"/>
<polygon fill="#000000" stroke="#000000" points="178.06,-448.76 184.3,-440.2 174.08,-443 178.06,-448.76"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node22" class="node">
<title>proc~torch_tensor_from_array_real32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node22"><a xlink:href="../proc/torch_tensor_from_array_real32_1d_default_layout.html" xlink:title="torch_tensor_from_array_real32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-402 178,-402 178,-378 459,-378 459,-402"/>
<text text-anchor="middle" x="318.5" y="-387.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge51" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.5,-608.77C79.35,-571.88 103.6,-463.68 169.35,-408.74"/>
<polygon fill="#000000" stroke="#000000" points="171.85,-411.22 177.58,-402.31 167.54,-405.71 171.85,-411.22"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node23" class="node">
<title>proc~torch_tensor_from_array_real32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node23"><a xlink:href="../proc/torch_tensor_from_array_real32_2d_default_layout.html" xlink:title="torch_tensor_from_array_real32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-360 178,-360 178,-336 459,-336 459,-360"/>
<text text-anchor="middle" x="318.5" y="-345.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge52" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-608.85C76.15,-567.55 93.72,-434.35 169.5,-367.07"/>
<polygon fill="#000000" stroke="#000000" points="172.08,-369.47 177.51,-360.38 167.6,-364.1 172.08,-369.47"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node24" class="node">
<title>proc~torch_tensor_from_array_real32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node24"><a xlink:href="../proc/torch_tensor_from_array_real32_3d_default_layout.html" xlink:title="torch_tensor_from_array_real32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-318 178,-318 178,-294 459,-294 459,-318"/>
<text text-anchor="middle" x="318.5" y="-303.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge53" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-608.7C73.37,-563 83.62,-404.57 169.98,-324.98"/>
<polygon fill="#000000" stroke="#000000" points="172.49,-327.44 177.73,-318.23 167.89,-322.16 172.49,-327.44"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node25" class="node">
<title>proc~torch_tensor_from_array_real32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node25"><a xlink:href="../proc/torch_tensor_from_array_real32_4d_default_layout.html" xlink:title="torch_tensor_from_array_real32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-276 178,-276 178,-252 459,-252 459,-276"/>
<text text-anchor="middle" x="318.5" y="-261.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge54" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.69,-608.8C70.79,-559.35 73.04,-375.3 170.22,-283.02"/>
<polygon fill="#000000" stroke="#000000" points="172.62,-285.56 177.69,-276.26 167.93,-280.37 172.62,-285.56"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node26" class="node">
<title>proc~torch_tensor_from_array_real32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node26"><a xlink:href="../proc/torch_tensor_from_array_real32_5d_default_layout.html" xlink:title="torch_tensor_from_array_real32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-234 178,-234 178,-210 459,-210 459,-234"/>
<text text-anchor="middle" x="318.5" y="-219.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge55" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-608.84C80.36,-551.1 116.12,-307.93 170.57,-241.79"/>
<polygon fill="#000000" stroke="#000000" points="173.32,-243.97 177.66,-234.31 168.24,-239.16 173.32,-243.97"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node27" class="node">
<title>proc~torch_tensor_from_array_real64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node27"><a xlink:href="../proc/torch_tensor_from_array_real64_1d_default_layout.html" xlink:title="torch_tensor_from_array_real64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-192 178,-192 178,-168 459,-168 459,-192"/>
<text text-anchor="middle" x="318.5" y="-177.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge56" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.03,-608.63C79.03,-546.61 111.14,-272.78 170.62,-199.86"/>
<polygon fill="#000000" stroke="#000000" points="173.37,-202.05 177.62,-192.34 168.25,-197.27 173.37,-202.05"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node28" class="node">
<title>proc~torch_tensor_from_array_real64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node28"><a xlink:href="../proc/torch_tensor_from_array_real64_2d_default_layout.html" xlink:title="torch_tensor_from_array_real64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-150 178,-150 178,-126 459,-126 459,-150"/>
<text text-anchor="middle" x="318.5" y="-135.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge57" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-608.99C77.64,-543.97 105.89,-237.49 170.78,-157.78"/>
<polygon fill="#000000" stroke="#000000" points="173.39,-160.11 177.59,-150.38 168.24,-155.36 173.39,-160.11"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node29" class="node">
<title>proc~torch_tensor_from_array_real64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node29"><a xlink:href="../proc/torch_tensor_from_array_real64_3d_default_layout.html" xlink:title="torch_tensor_from_array_real64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-108 178,-108 178,-84 459,-84 459,-108"/>
<text text-anchor="middle" x="318.5" y="-93.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge58" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.6,-608.58C76.55,-539.19 100.72,-202.72 170.65,-116.02"/>
<polygon fill="#000000" stroke="#000000" points="173.42,-118.17 177.56,-108.42 168.24,-113.46 173.42,-118.17"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node30" class="node">
<title>proc~torch_tensor_from_array_real64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node30"><a xlink:href="../proc/torch_tensor_from_array_real64_4d_default_layout.html" xlink:title="torch_tensor_from_array_real64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-66 178,-66 178,-42 459,-42 459,-66"/>
<text text-anchor="middle" x="318.5" y="-51.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge59" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.43,-608.73C75.41,-536.21 95.36,-167.29 170.79,-73.91"/>
<polygon fill="#000000" stroke="#000000" points="173.41,-76.22 177.52,-66.46 168.22,-71.53 173.41,-76.22"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node31" class="node">
<title>proc~torch_tensor_from_array_real64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node31"><a xlink:href="../proc/torch_tensor_from_array_real64_5d_default_layout.html" xlink:title="torch_tensor_from_array_real64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-24 178,-24 178,0 459,0 459,-24"/>
<text text-anchor="middle" x="318.5" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge60" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.27,-608.97C74.35,-533.73 89.88,-131.59 171.01,-31.69"/>
<polygon fill="#000000" stroke="#000000" points="173.63,-34.01 177.74,-24.25 168.44,-29.31 173.63,-34.01"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge1" class="edge">
<title>proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.82,-1242.04C251.21,-1246.6 205.4,-1244.62 178,-1218 94,-1136.4 75.72,-741.3 72.57,-643.04"/>
<polygon fill="#000000" stroke="#000000" points="76.07,-642.93 72.27,-633.03 69.07,-643.13 76.07,-642.93"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge2" class="edge">
<title>proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.29,-1200.04C250.76,-1204.43 205.41,-1202.27 178,-1176 99.79,-1101.04 77.25,-738.03 72.87,-643.44"/>
<polygon fill="#000000" stroke="#000000" points="76.36,-643.11 72.43,-633.27 69.37,-643.42 76.36,-643.11"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge3" class="edge">
<title>proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M281.77,-1158.02C250.34,-1162.23 205.43,-1159.89 178,-1134 105.51,-1065.58 78.88,-734.03 73.22,-643.65"/>
<polygon fill="#000000" stroke="#000000" points="76.7,-643.19 72.6,-633.42 69.71,-643.61 76.7,-643.19"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge4" class="edge">
<title>proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M280.97,-1116.02C249.66,-1119.98 205.4,-1117.39 178,-1092 110.99,-1029.91 80.48,-727.99 73.56,-643.09"/>
<polygon fill="#000000" stroke="#000000" points="77.04,-642.71 72.77,-633.01 70.07,-643.25 77.04,-642.71"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge5" class="edge">
<title>proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M279.86,-1074.03C248.72,-1077.66 205.31,-1074.76 178,-1050 116.68,-994.4 82.44,-723.83 74.05,-643.41"/>
<polygon fill="#000000" stroke="#000000" points="77.52,-642.97 73.03,-633.37 70.55,-643.67 77.52,-642.97"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge6" class="edge">
<title>proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M278.47,-1032.01C247.55,-1035.26 205.17,-1031.99 178,-1008 122.24,-958.76 84.5,-718.64 74.59,-643.4"/>
<polygon fill="#000000" stroke="#000000" points="78.02,-642.64 73.29,-633.16 71.08,-643.53 78.02,-642.64"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge7" class="edge">
<title>proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M276.15,-990.02C245.6,-992.7 204.81,-988.92 178,-966 79.3,-881.62 71.4,-706.13 71.58,-643.53"/>
<polygon fill="#000000" stroke="#000000" points="75.09,-643.24 71.69,-633.2 68.09,-643.17 75.09,-643.24"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge8" class="edge">
<title>proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.24,-948C242.35,-949.83 204.03,-945.36 178,-924 90.11,-851.89 75.08,-700.87 72.52,-643.48"/>
<polygon fill="#000000" stroke="#000000" points="76.01,-643.17 72.16,-633.3 69.02,-643.42 76.01,-643.17"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge9" class="edge">
<title>proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-884.4C180.15,-883.63 179.06,-882.83 178,-882 100.69,-821.87 79.14,-694.94 73.69,-643.26"/>
<polygon fill="#000000" stroke="#000000" points="77.16,-642.78 72.74,-633.15 70.19,-643.44 77.16,-642.78"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge10" class="edge">
<title>proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.33,-842.3C180.2,-841.56 179.09,-840.79 178,-840 111.21,-791.67 83.85,-688.99 75.26,-643.31"/>
<polygon fill="#000000" stroke="#000000" points="78.67,-642.49 73.5,-633.23 71.77,-643.69 78.67,-642.49"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge11" class="edge">
<title>proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.43,-800.14C180.27,-799.45 179.13,-798.74 178,-798 121.26,-760.93 89.17,-681.77 77.32,-642.92"/>
<polygon fill="#000000" stroke="#000000" points="80.62,-641.75 74.51,-633.1 73.89,-643.67 80.62,-641.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge12" class="edge">
<title>proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-757.75C180.15,-757.18 179.07,-756.6 178,-756 130.96,-729.66 95.7,-673.75 80.39,-642.53"/>
<polygon fill="#000000" stroke="#000000" points="83.51,-640.94 76.14,-633.33 77.16,-643.88 83.51,-640.94"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge13" class="edge">
<title>proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.4,-715.43C180.26,-714.96 179.12,-714.49 178,-714 139.62,-697.33 103.3,-663.15 84.78,-640.89"/>
<polygon fill="#000000" stroke="#000000" points="87.51,-638.71 78.58,-633.01 82.01,-643.03 87.51,-638.71"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge14" class="edge">
<title>proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.21,-672.85C180.13,-672.57 179.06,-672.29 178,-672 148,-663.91 114.94,-649.95 93.85,-638.29"/>
<polygon fill="#000000" stroke="#000000" points="95.45,-635.17 85.06,-633.12 91.9,-641.2 95.45,-635.17"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge15" class="edge">
<title>proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.2,-637.05C170.82,-636.11 160.58,-635.11 150.77,-634.09"/>
<polygon fill="#000000" stroke="#000000" points="151.03,-630.59 140.71,-633.01 150.28,-637.55 151.03,-630.59"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge16" class="edge">
<title>proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M248.66,-612.02C218.75,-615.31 183.5,-618.41 152.4,-620.5"/>
<polygon fill="#000000" stroke="#000000" points="151.78,-617.04 142.02,-621.17 152.23,-624.02 151.78,-617.04"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge17" class="edge">
<title>proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.04,-570C244.51,-574.39 208.86,-579.68 178,-588 160.83,-592.63 142.65,-599.19 126.29,-605.35"/>
<polygon fill="#000000" stroke="#000000" points="124.99,-602.1 116.88,-608.92 127.47,-608.65 124.99,-602.1"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge18" class="edge">
<title>proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M246.7,-528.01C224.05,-531.45 199.34,-536.73 178,-546 146.96,-559.48 117.27,-584.41 97.25,-602.02"/>
<polygon fill="#000000" stroke="#000000" points="94.72,-599.58 89.55,-608.83 99.36,-604.83 94.72,-599.58"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge19" class="edge">
<title>proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M230.57,-486.04C212.39,-489.58 193.92,-495.09 178,-504 136.72,-527.11 104.52,-573 86.9,-600.12"/>
<polygon fill="#000000" stroke="#000000" points="83.75,-598.56 81.29,-608.87 89.64,-602.34 83.75,-598.56"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge20" class="edge">
<title>proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M222.31,-444.02C206.64,-447.74 191.23,-453.36 178,-462 126.49,-495.65 95.3,-563.98 81.12,-599.27"/>
<polygon fill="#000000" stroke="#000000" points="77.82,-598.11 77.41,-608.69 84.33,-600.67 77.82,-598.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge21" class="edge">
<title>proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M217.61,-402.01C203.43,-405.85 189.71,-411.53 178,-420 116.06,-464.82 88.03,-556.39 77.43,-598.84"/>
<polygon fill="#000000" stroke="#000000" points="73.98,-598.21 75.05,-608.75 80.79,-599.85 73.98,-598.21"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge22" class="edge">
<title>proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M214.57,-360.02C201.36,-363.94 188.73,-369.66 178,-378 105.36,-434.5 81.95,-549.98 74.86,-598.77"/>
<polygon fill="#000000" stroke="#000000" points="71.36,-598.52 73.49,-608.9 78.3,-599.46 71.36,-598.52"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge23" class="edge">
<title>proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M212.39,-318.06C199.89,-322.04 188.04,-327.77 178,-336 94.59,-404.44 76.8,-543.95 73.02,-598.6"/>
<polygon fill="#000000" stroke="#000000" points="69.5,-598.73 72.4,-608.92 76.49,-599.15 69.5,-598.73"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge24" class="edge">
<title>proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M211.02,-276.03C198.96,-280.06 187.59,-285.8 178,-294 83.65,-374.65 72.28,-538.56 71.61,-598.58"/>
<polygon fill="#000000" stroke="#000000" points="68.11,-598.83 71.6,-608.84 75.11,-598.84 68.11,-598.83"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge25" class="edge">
<title>proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M209.72,-234.1C198.09,-238.15 187.18,-243.89 178,-252 124.05,-299.64 86.97,-525.95 75.65,-598.65"/>
<polygon fill="#000000" stroke="#000000" points="72.12,-598.53 74.05,-608.94 79.04,-599.6 72.12,-598.53"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge26" class="edge">
<title>proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.81,-192.11C197.49,-196.19 186.89,-201.94 178,-210 118.39,-264.04 84.38,-521.17 74.81,-598.88"/>
<polygon fill="#000000" stroke="#000000" points="71.32,-598.64 73.58,-608.99 78.26,-599.49 71.32,-598.64"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge27" class="edge">
<title>proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.3,-150.05C197.13,-154.16 186.71,-159.93 178,-168 112.79,-228.43 82.15,-515.96 74.17,-598.78"/>
<polygon fill="#000000" stroke="#000000" points="70.68,-598.58 73.22,-608.86 77.65,-599.24 70.68,-598.58"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge28" class="edge">
<title>proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.81,-108.02C196.8,-112.15 186.55,-117.93 178,-126 107.14,-192.88 80.1,-511.18 73.63,-598.78"/>
<polygon fill="#000000" stroke="#000000" points="70.13,-598.7 72.9,-608.93 77.11,-599.21 70.13,-598.7"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge29" class="edge">
<title>proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.34,-66.02C196.48,-70.16 186.4,-75.95 178,-84 101.55,-157.28 78.29,-505.84 73.19,-598.48"/>
<polygon fill="#000000" stroke="#000000" points="69.69,-598.52 72.65,-608.69 76.68,-598.9 69.69,-598.52"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge30" class="edge">
<title>proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M206.89,-24.04C196.18,-28.2 186.26,-33.98 178,-42 95.79,-121.87 76.52,-502.05 72.79,-598.72"/>
<polygon fill="#000000" stroke="#000000" points="69.29,-598.71 72.42,-608.83 76.29,-598.97 69.29,-598.71"/>
</g>
</g>
</svg>
</div>          <div>
            <a type="button" class="graph-help" data-bs-toggle="modal" href="#CalledByGraph-help-text">Help</a>
          </div>
          <div class="modal fade" id="CalledByGraph-help-text" tabindex="-1" role="dialog">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title" id="-graph-help-label">Graph Key</h4>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
<p>Nodes of different colours represent the following: </p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: Graph Key Pages: 1 -->
<svg width="641pt" height="28pt"
 viewBox="0.00 0.00 641.00 27.51" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(0.86 0.86) rotate(0) translate(4 28)">
<title>Graph Key</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-28 741.5,-28 741.5,4 -4,4"/>
<!-- Subroutine -->
<g id="node1" class="node">
<title>Subroutine</title>
<polygon fill="#d9534f" stroke="#d9534f" points="70,-24 0,-24 0,0 70,0 70,-24"/>
<text text-anchor="middle" x="35" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Subroutine</text>
</g>
<!-- Function -->
<g id="node2" class="node">
<title>Function</title>
<polygon fill="#d94e8f" stroke="#d94e8f" points="146,-24 88,-24 88,0 146,0 146,-24"/>
<text text-anchor="middle" x="117" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Function</text>
</g>
<!-- Interface -->
<g id="node3" class="node">
<title>Interface</title>
<polygon fill="#a7506f" stroke="#a7506f" points="225.5,-24 164.5,-24 164.5,0 225.5,0 225.5,-24"/>
<text text-anchor="middle" x="195" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Interface</text>
</g>
<!-- Type Bound Procedure -->
<g id="node4" class="node">
<title>Type Bound Procedure</title>
<polygon fill="#a7506f" stroke="#a7506f" points="374,-24 244,-24 244,0 374,0 374,-24"/>
<text text-anchor="middle" x="309" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Type Bound Procedure</text>
</g>
<!-- Unknown Procedure Type -->
<g id="node5" class="node">
<title>Unknown Procedure Type</title>
<polygon fill="#777777" stroke="#777777" points="537.5,-24 392.5,-24 392.5,0 537.5,0 537.5,-24"/>
<text text-anchor="middle" x="465" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Unknown Procedure Type</text>
</g>
<!-- Program -->
<g id="node6" class="node">
<title>Program</title>
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="614,-24 556,-24 556,0 614,0 614,-24"/>
<text text-anchor="middle" x="585" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Program</text>
</g>
<!-- This Page&#39;s Entity -->
<g id="node7" class="node">
<title>This Page&#39;s Entity</title>
<polygon fill="none" stroke="black" points="737.5,-24 632.5,-24 632.5,0 737.5,0 737.5,-24"/>
<text text-anchor="middle" x="685" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50">This Page&#39;s Entity</text>
</g>
</g>
</svg>

<p>Solid arrows point from a procedure to one which it calls. Dashed 
arrows point from an interface to procedures which implement that interface.
This could include the module procedures in a generic interface or the
implementation in a submodule of an interface in a parent module.
</p>
 </div>
            </div>
          </div>
        </div>
          </div>
        </div>
<br>


        <h2>Module Procedures</h2>
            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_1d.html'>torch_tensor_from_array_int8_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~5"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~2"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~6"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~6"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~7"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_2d.html'>torch_tensor_from_array_int8_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~6"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~2"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~3"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~7"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~7"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~8"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_3d.html'>torch_tensor_from_array_int8_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~7"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~3"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~4"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~8"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~8"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~9"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_4d.html'>torch_tensor_from_array_int8_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~8"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~4"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~5"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~9"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~9"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~10"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_5d.html'>torch_tensor_from_array_int8_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~9"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~5"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~6"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~10"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~10"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~11"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_1d.html'>torch_tensor_from_array_int16_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~10"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~6"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~7"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~11"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~11"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~12"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_2d.html'>torch_tensor_from_array_int16_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~11"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~7"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~8"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~12"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~12"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~13"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_3d.html'>torch_tensor_from_array_int16_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~12"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~8"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~9"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~13"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~13"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~14"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_4d.html'>torch_tensor_from_array_int16_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~13"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~9"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~10"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~14"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~14"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~15"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_5d.html'>torch_tensor_from_array_int16_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~14"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~10"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~11"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~15"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~15"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~16"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_1d.html'>torch_tensor_from_array_int32_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~15"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~11"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~12"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~16"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~16"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~17"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_2d.html'>torch_tensor_from_array_int32_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~16"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~12"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~13"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~17"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~17"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~18"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_3d.html'>torch_tensor_from_array_int32_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~17"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~13"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~14"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~18"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~18"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~19"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_4d.html'>torch_tensor_from_array_int32_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~18"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~14"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~15"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~19"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~19"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~20"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_5d.html'>torch_tensor_from_array_int32_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~19"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~15"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~16"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~20"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~20"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~21"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_1d.html'>torch_tensor_from_array_int64_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~20"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~16"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~17"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~21"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~21"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~22"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_2d.html'>torch_tensor_from_array_int64_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~21"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~17"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~18"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~22"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~22"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~23"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_3d.html'>torch_tensor_from_array_int64_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~22"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~18"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~19"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~23"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~23"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~24"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_4d.html'>torch_tensor_from_array_int64_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~23"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~19"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~20"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~24"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~24"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~25"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_5d.html'>torch_tensor_from_array_int64_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~24"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~20"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~21"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~25"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~25"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~26"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_1d.html'>torch_tensor_from_array_real32_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~25"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~21"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~22"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~26"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~26"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~27"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_2d.html'>torch_tensor_from_array_real32_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~26"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~22"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~23"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~27"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~27"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~28"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_3d.html'>torch_tensor_from_array_real32_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~27"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~23"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~24"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~28"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~28"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~29"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_4d.html'>torch_tensor_from_array_real32_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~28"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~24"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~25"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~29"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~29"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~30"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_5d.html'>torch_tensor_from_array_real32_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~29"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~25"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~26"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~30"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~30"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~31"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_1d.html'>torch_tensor_from_array_real64_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~30"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~26"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~27"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~31"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~31"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~32"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_2d.html'>torch_tensor_from_array_real64_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~31"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~27"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~28"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~32"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~32"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~33"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_3d.html'>torch_tensor_from_array_real64_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~32"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~28"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~29"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~33"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~33"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~34"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_4d.html'>torch_tensor_from_array_real64_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~33"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~29"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~30"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~34"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~34"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~35"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_5d.html'>torch_tensor_from_array_real64_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~34"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~30"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~31"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~35"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~35"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~36"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_1d_default_layout.html'>torch_tensor_from_array_int8_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~35"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~31"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~36"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~36"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~37"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_2d_default_layout.html'>torch_tensor_from_array_int8_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~36"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~32"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~37"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~37"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~38"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_3d_default_layout.html'>torch_tensor_from_array_int8_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~37"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~33"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~38"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~38"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~39"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_4d_default_layout.html'>torch_tensor_from_array_int8_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~38"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~34"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~39"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~39"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~40"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_5d_default_layout.html'>torch_tensor_from_array_int8_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~39"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~35"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~40"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~40"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~41"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_1d_default_layout.html'>torch_tensor_from_array_int16_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~40"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~36"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~41"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~41"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~42"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_2d_default_layout.html'>torch_tensor_from_array_int16_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~41"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~37"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~42"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~42"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~43"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_3d_default_layout.html'>torch_tensor_from_array_int16_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~42"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~38"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~43"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~43"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~44"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_4d_default_layout.html'>torch_tensor_from_array_int16_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~43"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~39"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~44"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~44"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~45"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_5d_default_layout.html'>torch_tensor_from_array_int16_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~44"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~40"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~45"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~45"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~46"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_1d_default_layout.html'>torch_tensor_from_array_int32_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~45"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~41"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~46"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~46"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~47"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_2d_default_layout.html'>torch_tensor_from_array_int32_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~46"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~42"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~47"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~47"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~48"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_3d_default_layout.html'>torch_tensor_from_array_int32_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~47"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~43"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~48"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~48"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~49"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_4d_default_layout.html'>torch_tensor_from_array_int32_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~48"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~44"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~49"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~49"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~50"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_5d_default_layout.html'>torch_tensor_from_array_int32_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~49"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~45"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~50"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~50"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~51"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_1d_default_layout.html'>torch_tensor_from_array_int64_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~50"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~46"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~51"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~51"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~52"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_2d_default_layout.html'>torch_tensor_from_array_int64_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~51"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~47"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~52"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~52"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~53"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_3d_default_layout.html'>torch_tensor_from_array_int64_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~52"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~48"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~53"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~53"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~54"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_4d_default_layout.html'>torch_tensor_from_array_int64_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~53"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~49"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~54"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~54"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~55"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_5d_default_layout.html'>torch_tensor_from_array_int64_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~54"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~50"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~55"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~55"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~56"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_1d_default_layout.html'>torch_tensor_from_array_real32_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~55"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~51"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~56"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~56"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~57"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_2d_default_layout.html'>torch_tensor_from_array_real32_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~56"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~52"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~57"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~57"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~58"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_3d_default_layout.html'>torch_tensor_from_array_real32_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~57"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~53"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~58"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~58"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~59"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_4d_default_layout.html'>torch_tensor_from_array_real32_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~58"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~54"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~59"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~59"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~60"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_5d_default_layout.html'>torch_tensor_from_array_real32_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~59"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~55"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~60"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~60"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~61"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_1d_default_layout.html'>torch_tensor_from_array_real64_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~60"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~56"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~61"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~61"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~62"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_2d_default_layout.html'>torch_tensor_from_array_real64_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~61"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~57"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~62"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~62"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~63"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_3d_default_layout.html'>torch_tensor_from_array_real64_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~62"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~58"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~63"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~63"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~64"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_4d_default_layout.html'>torch_tensor_from_array_real64_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~63"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~59"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~64"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~64"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~65"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_5d_default_layout.html'>torch_tensor_from_array_real64_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~64"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~60"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~65"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~65"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~66"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

</div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2025 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>
  </body>
</html>