<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="FTorch - A library for coupling (Py)Torch machine learning models to Fortran codes.Written in modern Fortran (2008) with source code available on GitHub it has been used in multiple scientific projects.The associated JOSS paper can read here.">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>torch_tensor_from_array &ndash; FTorch</title>

    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <!-- Font Awesome -->
    <link href="../css/fontawesome.min.css" rel="stylesheet">
    <link href="../css/brands.min.css" rel="stylesheet">
    <link href="../css/regular.min.css" rel="stylesheet">
    <link href="../css/solid.min.css" rel="stylesheet">
    <link href="../css/v4-font-face.min.css" rel="stylesheet">
    <link href="../css/v4-shims.min.css" rel="stylesheet">
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } }
      });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async
            integrity="sha256-DViIOMYdwlM/axqoGDPeUyf0urLoHMN4QACBKyB58Uw=" crossorigin="anonymous"></script>
    <!-- Other scripts and stylesheets -->
    <link href="../css/local.css" rel="stylesheet">
    <link href="../css/pygments.css" rel="stylesheet">
      <link href="../css/user.css" rel="stylesheet">
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="../page/index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>torch_tensor_from_array
      <small>Interface</small>
      
    </h1>
      <div class="container p-2 mb-4 bg-light border rounded-3">
    <div class="row align-items-center justify-content-between" id="info-bar">
      <div class="col">
        <ul class="list-inline" style="margin-bottom:0px;display:inline">
            <li class="list-inline-item" id="meta-license"><i class="fa fa-legal"></i> <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a></li>

            <li class="list-inline-item" id="statements"><i class="fa fa-list-ol"></i>
              <a data-bs-toggle="tooltip" data-bs-placement="bottom" data-bs-html="true"
                 title="<p> 2.9% of total for procedures.</p>Including implementation: 992 statements, 47.1% of total for procedures.">62 statements</a>
            </li>

            <li class="list-inline-item" id="source-file">
              <i class="fa fa-code"></i>
              <a href="../src/ftorch.F90"> Source File</a>
            </li>
        </ul>
      </div>
      <div class="col">
        <nav aria-label="breadcrumb">
          <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='../sourcefile/ftorch.f90.html'>ftorch.F90</a></li>
                <li class="breadcrumb-item"><a href='../module/ftorch.html'>ftorch</a></li>
            <li class="breadcrumb-item active" aria-current="page">torch_tensor_from_array</li>
          </ol>
        </nav>
      </div>
    </div>
  </div>
  <script>
    // Enable Bootstrap tooltips
    (function () {
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
    })();
  </script>

  </div>

  <div class="row">
    <div class="col-md-3 hidden-xs hidden-sm visible-md visible-lg">
        <div id="sidebar">
      <h3>Contents</h3>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
      <div class="card mb-4">
      <a data-bs-toggle="collapse" href="#modprocs-0"
         aria-expanded="false" aria-controls="modprocs-0">
         <h4 class="card-header bg-primary text-white">Module Procedures</h4>
      </a>
      <div id="modprocs-0" class="collapse">
        <div class="list-group list-group-flush">
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_1d">torch_tensor_from_array_int8_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_2d">torch_tensor_from_array_int8_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_3d">torch_tensor_from_array_int8_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_4d">torch_tensor_from_array_int8_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_5d">torch_tensor_from_array_int8_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_1d">torch_tensor_from_array_int16_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_2d">torch_tensor_from_array_int16_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_3d">torch_tensor_from_array_int16_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_4d">torch_tensor_from_array_int16_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_5d">torch_tensor_from_array_int16_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_1d">torch_tensor_from_array_int32_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_2d">torch_tensor_from_array_int32_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_3d">torch_tensor_from_array_int32_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_4d">torch_tensor_from_array_int32_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_5d">torch_tensor_from_array_int32_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_1d">torch_tensor_from_array_int64_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_2d">torch_tensor_from_array_int64_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_3d">torch_tensor_from_array_int64_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_4d">torch_tensor_from_array_int64_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_5d">torch_tensor_from_array_int64_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_1d">torch_tensor_from_array_real32_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_2d">torch_tensor_from_array_real32_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_3d">torch_tensor_from_array_real32_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_4d">torch_tensor_from_array_real32_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_5d">torch_tensor_from_array_real32_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_1d">torch_tensor_from_array_real64_1d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_2d">torch_tensor_from_array_real64_2d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_3d">torch_tensor_from_array_real64_3d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_4d">torch_tensor_from_array_real64_4d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_5d">torch_tensor_from_array_real64_5d</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_1d_default_layout">torch_tensor_from_array_int8_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_2d_default_layout">torch_tensor_from_array_int8_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_3d_default_layout">torch_tensor_from_array_int8_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_4d_default_layout">torch_tensor_from_array_int8_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int8_5d_default_layout">torch_tensor_from_array_int8_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_1d_default_layout">torch_tensor_from_array_int16_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_2d_default_layout">torch_tensor_from_array_int16_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_3d_default_layout">torch_tensor_from_array_int16_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_4d_default_layout">torch_tensor_from_array_int16_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int16_5d_default_layout">torch_tensor_from_array_int16_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_1d_default_layout">torch_tensor_from_array_int32_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_2d_default_layout">torch_tensor_from_array_int32_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_3d_default_layout">torch_tensor_from_array_int32_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_4d_default_layout">torch_tensor_from_array_int32_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int32_5d_default_layout">torch_tensor_from_array_int32_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_1d_default_layout">torch_tensor_from_array_int64_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_2d_default_layout">torch_tensor_from_array_int64_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_3d_default_layout">torch_tensor_from_array_int64_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_4d_default_layout">torch_tensor_from_array_int64_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_int64_5d_default_layout">torch_tensor_from_array_int64_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_1d_default_layout">torch_tensor_from_array_real32_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_2d_default_layout">torch_tensor_from_array_real32_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_3d_default_layout">torch_tensor_from_array_real32_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_4d_default_layout">torch_tensor_from_array_real32_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real32_5d_default_layout">torch_tensor_from_array_real32_5d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_1d_default_layout">torch_tensor_from_array_real64_1d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_2d_default_layout">torch_tensor_from_array_real64_2d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_3d_default_layout">torch_tensor_from_array_real64_3d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_4d_default_layout">torch_tensor_from_array_real64_4d_default_layout</a>
            <a class="list-group-item" href="../interface/torch_tensor_from_array.html#moduleprocedure-torch_tensor_from_array_real64_5d_default_layout">torch_tensor_from_array_real64_5d_default_layout</a>
        </div>
      </div>
    </div>

  


  </div>

    </div>

    <div class="col-md-9" id='text'>
      <h2>public interface torch_tensor_from_array</h2>
      <p>Interface for directing <code>torch_tensor_from_array</code> to possible input types and ranks</p>
        <div class="card">
          <div class="card-header">
            <h3 class="card-title">Calls</h3>
          </div>
          <div class="card-body">
            <div class="depgraph"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: interface~~torch_tensor_from_array~~CallsGraph Pages: 1 -->
<svg id="interfacetorch_tensor_from_arrayCallsGraph" width="641pt" height="2050pt"
 viewBox="0.00 0.00 641.00 2049.57" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="interface~~torch_tensor_from_array~~CallsGraph" class="graph" transform="scale(0.82 0.82) rotate(0) translate(4 2506)">
<title>interface~~torch_tensor_from_array~~CallsGraph</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-2506 781,-2506 781,4 -4,4"/>
<!-- interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node1" class="node">
<title>interface~torch_tensor_from_array</title>
<polygon fill="none" stroke="black" points="142,-1263 0,-1263 0,-1239 142,-1239 142,-1263"/>
<text text-anchor="middle" x="71" y="-1248.6" font-family="Helvetica,sans-Serif" font-size="10.50">torch_tensor_from_array</text>
</g>
<!-- proc~torch_tensor_from_array_int16_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node2" class="node">
<title>proc~torch_tensor_from_array_int16_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node2"><a xlink:href="../proc/torch_tensor_from_array_int16_1d.html" xlink:title="torch_tensor_from_array_int16_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2502 222,-2502 222,-2478 415,-2478 415,-2502"/>
<text text-anchor="middle" x="318.5" y="-2487.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge1" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-1263.21C73.9,-1384.83 90.72,-2376.08 178,-2469 187.29,-2478.89 199.08,-2485.48 211.87,-2489.74"/>
<polygon fill="#000000" stroke="#000000" points="211.24,-2493.2 221.82,-2492.56 213.15,-2486.46 211.24,-2493.2"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node3" class="node">
<title>proc~torch_tensor_from_array_int16_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node3"><a xlink:href="../proc/torch_tensor_from_array_int16_1d_default_layout.html" xlink:title="torch_tensor_from_array_int16_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2460 181.5,-2460 181.5,-2436 455.5,-2436 455.5,-2460"/>
<text text-anchor="middle" x="318.5" y="-2445.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge2" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.23,-1263.01C74.46,-1381.16 94.01,-2328.85 178,-2418 183.14,-2423.45 189.04,-2427.9 195.45,-2431.53"/>
<polygon fill="#000000" stroke="#000000" points="193.97,-2434.7 204.48,-2435.97 197.06,-2428.42 193.97,-2434.7"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node4" class="node">
<title>proc~torch_tensor_from_array_int16_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node4"><a xlink:href="../proc/torch_tensor_from_array_int16_2d.html" xlink:title="torch_tensor_from_array_int16_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2418 222,-2418 222,-2394 415,-2394 415,-2418"/>
<text text-anchor="middle" x="318.5" y="-2403.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge3" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.24,-1263.09C74.69,-1379.46 96.58,-2298.87 178,-2385 187.32,-2394.86 199.13,-2401.43 211.93,-2405.68"/>
<polygon fill="#000000" stroke="#000000" points="211.31,-2409.14 221.88,-2408.5 213.21,-2402.41 211.31,-2409.14"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node5" class="node">
<title>proc~torch_tensor_from_array_int16_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node5"><a xlink:href="../proc/torch_tensor_from_array_int16_2d_default_layout.html" xlink:title="torch_tensor_from_array_int16_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2376 181.5,-2376 181.5,-2352 455.5,-2352 455.5,-2376"/>
<text text-anchor="middle" x="318.5" y="-2361.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge4" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.33,-1263.09C75.36,-1376.77 99.92,-2251.69 178,-2334 183.16,-2339.44 189.07,-2343.87 195.49,-2347.49"/>
<polygon fill="#000000" stroke="#000000" points="194.02,-2350.66 204.54,-2351.92 197.1,-2344.38 194.02,-2350.66"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node6" class="node">
<title>proc~torch_tensor_from_array_int16_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node6"><a xlink:href="../proc/torch_tensor_from_array_int16_3d.html" xlink:title="torch_tensor_from_array_int16_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2334 222,-2334 222,-2310 415,-2310 415,-2334"/>
<text text-anchor="middle" x="318.5" y="-2319.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge5" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.34,-1263.23C75.58,-1375.29 102.5,-2221.73 178,-2301 187.35,-2310.82 199.19,-2317.38 212,-2321.62"/>
<polygon fill="#000000" stroke="#000000" points="211.38,-2325.08 221.95,-2324.43 213.28,-2318.35 211.38,-2325.08"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node7" class="node">
<title>proc~torch_tensor_from_array_int16_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node7"><a xlink:href="../proc/torch_tensor_from_array_int16_3d_default_layout.html" xlink:title="torch_tensor_from_array_int16_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2292 181.5,-2292 181.5,-2268 455.5,-2268 455.5,-2292"/>
<text text-anchor="middle" x="318.5" y="-2277.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge6" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.45,-1263.03C76.33,-1371.51 105.79,-2174.49 178,-2250 183.18,-2255.42 189.11,-2259.84 195.55,-2263.44"/>
<polygon fill="#000000" stroke="#000000" points="194.08,-2266.62 204.6,-2267.86 197.15,-2260.33 194.08,-2266.62"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node8" class="node">
<title>proc~torch_tensor_from_array_int16_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node8"><a xlink:href="../proc/torch_tensor_from_array_int16_4d.html" xlink:title="torch_tensor_from_array_int16_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2250 222,-2250 222,-2226 415,-2226 415,-2250"/>
<text text-anchor="middle" x="318.5" y="-2235.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge7" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.45,-1263.24C76.54,-1370.26 108.38,-2144.53 178,-2217 187.33,-2226.71 199.09,-2233.22 211.8,-2237.45"/>
<polygon fill="#000000" stroke="#000000" points="211.1,-2240.89 221.68,-2240.26 213.02,-2234.16 211.1,-2240.89"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node9" class="node">
<title>proc~torch_tensor_from_array_int16_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node9"><a xlink:href="../proc/torch_tensor_from_array_int16_4d_default_layout.html" xlink:title="torch_tensor_from_array_int16_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2208 181.5,-2208 181.5,-2184 455.5,-2184 455.5,-2208"/>
<text text-anchor="middle" x="318.5" y="-2193.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge8" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.6,-1263.17C77.43,-1366.94 111.69,-2097.32 178,-2166 183.26,-2171.45 189.29,-2175.89 195.82,-2179.5"/>
<polygon fill="#000000" stroke="#000000" points="194.49,-2182.74 205.02,-2183.93 197.52,-2176.44 194.49,-2182.74"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node10" class="node">
<title>proc~torch_tensor_from_array_int16_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node10"><a xlink:href="../proc/torch_tensor_from_array_int16_5d.html" xlink:title="torch_tensor_from_array_int16_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2166 222,-2166 222,-2142 415,-2142 415,-2166"/>
<text text-anchor="middle" x="318.5" y="-2151.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge9" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.58,-1263.12C77.55,-1364.37 114.22,-2067.29 178,-2133 187.38,-2142.66 199.16,-2149.14 211.89,-2153.36"/>
<polygon fill="#000000" stroke="#000000" points="211.21,-2156.81 221.78,-2156.17 213.11,-2150.07 211.21,-2156.81"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node11" class="node">
<title>proc~torch_tensor_from_array_int16_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node11"><a xlink:href="../proc/torch_tensor_from_array_int16_5d_default_layout.html" xlink:title="torch_tensor_from_array_int16_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2124 181.5,-2124 181.5,-2100 455.5,-2100 455.5,-2124"/>
<text text-anchor="middle" x="318.5" y="-2109.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge10" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-1263.11C78.61,-1361.23 117.54,-2020.08 178,-2082 183.35,-2087.48 189.48,-2091.94 196.11,-2095.55"/>
<polygon fill="#000000" stroke="#000000" points="194.91,-2098.86 205.44,-2099.98 197.91,-2092.53 194.91,-2098.86"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node12" class="node">
<title>proc~torch_tensor_from_array_int32_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node12"><a xlink:href="../proc/torch_tensor_from_array_int32_1d.html" xlink:title="torch_tensor_from_array_int32_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-2082 222,-2082 222,-2058 415,-2058 415,-2082"/>
<text text-anchor="middle" x="318.5" y="-2067.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge11" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-1263.16C78.71,-1358.96 120.08,-1990.07 178,-2049 187.44,-2058.6 199.26,-2065.05 212,-2069.26"/>
<polygon fill="#000000" stroke="#000000" points="211.33,-2072.7 221.9,-2072.05 213.23,-2065.96 211.33,-2072.7"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node13" class="node">
<title>proc~torch_tensor_from_array_int32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node13"><a xlink:href="../proc/torch_tensor_from_array_int32_1d_default_layout.html" xlink:title="torch_tensor_from_array_int32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-2040 181.5,-2040 181.5,-2016 455.5,-2016 455.5,-2040"/>
<text text-anchor="middle" x="318.5" y="-2025.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge12" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.79,-1263.06C70.68,-1350.87 69.26,-1888.15 178,-1998 183.39,-2003.44 189.55,-2007.87 196.2,-2011.47"/>
<polygon fill="#000000" stroke="#000000" points="195.02,-2014.78 205.56,-2015.87 198,-2008.44 195.02,-2014.78"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node14" class="node">
<title>proc~torch_tensor_from_array_int32_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node14"><a xlink:href="../proc/torch_tensor_from_array_int32_2d.html" xlink:title="torch_tensor_from_array_int32_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1998 222,-1998 222,-1974 415,-1974 415,-1998"/>
<text text-anchor="middle" x="318.5" y="-1983.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge13" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.92,-1263.06C71.62,-1348.42 74.21,-1861 178,-1965 187.44,-1974.46 199.2,-1980.85 211.86,-1985.03"/>
<polygon fill="#000000" stroke="#000000" points="211.12,-1988.46 221.69,-1987.82 213.02,-1981.72 211.12,-1988.46"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node15" class="node">
<title>proc~torch_tensor_from_array_int32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node15"><a xlink:href="../proc/torch_tensor_from_array_int32_2d_default_layout.html" xlink:title="torch_tensor_from_array_int32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1956 181.5,-1956 181.5,-1932 455.5,-1932 455.5,-1956"/>
<text text-anchor="middle" x="318.5" y="-1941.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge14" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.06,-1263.03C72.73,-1345.01 80.89,-1817.57 178,-1914 183.5,-1919.46 189.76,-1923.89 196.53,-1927.48"/>
<polygon fill="#000000" stroke="#000000" points="195.49,-1930.85 206.03,-1931.87 198.42,-1924.5 195.49,-1930.85"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node16" class="node">
<title>proc~torch_tensor_from_array_int32_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node16"><a xlink:href="../proc/torch_tensor_from_array_int32_3d.html" xlink:title="torch_tensor_from_array_int32_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1914 222,-1914 222,-1890 415,-1890 415,-1914"/>
<text text-anchor="middle" x="318.5" y="-1899.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge15" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.18,-1263.15C73.63,-1342.84 85.85,-1790.43 178,-1881 187.53,-1890.37 199.35,-1896.7 212.03,-1900.86"/>
<polygon fill="#000000" stroke="#000000" points="211.3,-1904.29 221.87,-1903.63 213.2,-1897.55 211.3,-1904.29"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node17" class="node">
<title>proc~torch_tensor_from_array_int32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node17"><a xlink:href="../proc/torch_tensor_from_array_int32_3d_default_layout.html" xlink:title="torch_tensor_from_array_int32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1872 181.5,-1872 181.5,-1848 455.5,-1848 455.5,-1872"/>
<text text-anchor="middle" x="318.5" y="-1857.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge16" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.42,-1263.17C75.1,-1339.38 92.53,-1746.97 178,-1830 183.81,-1835.64 190.44,-1840.17 197.58,-1843.81"/>
<polygon fill="#000000" stroke="#000000" points="196.33,-1847.08 206.89,-1847.96 199.18,-1840.69 196.33,-1847.08"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node18" class="node">
<title>proc~torch_tensor_from_array_int32_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node18"><a xlink:href="../proc/torch_tensor_from_array_int32_4d.html" xlink:title="torch_tensor_from_array_int32_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1830 222,-1830 222,-1806 415,-1806 415,-1830"/>
<text text-anchor="middle" x="318.5" y="-1815.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge17" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.53,-1263.4C75.97,-1337.36 97.49,-1719.82 178,-1797 187.58,-1806.18 199.36,-1812.42 211.97,-1816.55"/>
<polygon fill="#000000" stroke="#000000" points="211.18,-1819.96 221.75,-1819.3 213.08,-1813.22 211.18,-1819.96"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node19" class="node">
<title>proc~torch_tensor_from_array_int32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node19"><a xlink:href="../proc/torch_tensor_from_array_int32_4d_default_layout.html" xlink:title="torch_tensor_from_array_int32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1788 181.5,-1788 181.5,-1764 455.5,-1764 455.5,-1788"/>
<text text-anchor="middle" x="318.5" y="-1773.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge18" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.9,-1263.07C77.82,-1332.43 104.03,-1676.19 178,-1746 184.01,-1751.67 190.86,-1756.22 198.23,-1759.85"/>
<polygon fill="#000000" stroke="#000000" points="197.24,-1763.23 207.81,-1763.98 200.01,-1756.8 197.24,-1763.23"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node20" class="node">
<title>proc~torch_tensor_from_array_int32_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node20"><a xlink:href="../proc/torch_tensor_from_array_int32_5d.html" xlink:title="torch_tensor_from_array_int32_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1746 222,-1746 222,-1722 415,-1722 415,-1746"/>
<text text-anchor="middle" x="318.5" y="-1731.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge19" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.98,-1263.2C78.6,-1329.8 108.89,-1648.96 178,-1713 187.66,-1721.95 199.42,-1728.07 211.97,-1732.15"/>
<polygon fill="#000000" stroke="#000000" points="211.13,-1735.55 221.7,-1734.89 213.02,-1728.81 211.13,-1735.55"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node21" class="node">
<title>proc~torch_tensor_from_array_int32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node21"><a xlink:href="../proc/torch_tensor_from_array_int32_5d_default_layout.html" xlink:title="torch_tensor_from_array_int32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1704 181.5,-1704 181.5,-1680 455.5,-1680 455.5,-1704"/>
<text text-anchor="middle" x="318.5" y="-1689.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge20" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.58,-1263.01C81.09,-1325.05 115.46,-1605.3 178,-1662 184.39,-1667.79 191.66,-1672.39 199.45,-1676.03"/>
<polygon fill="#000000" stroke="#000000" points="198.23,-1679.32 208.81,-1679.89 200.9,-1672.84 198.23,-1679.32"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node22" class="node">
<title>proc~torch_tensor_from_array_int64_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node22"><a xlink:href="../proc/torch_tensor_from_array_int64_1d.html" xlink:title="torch_tensor_from_array_int64_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1662 222,-1662 222,-1638 415,-1638 415,-1662"/>
<text text-anchor="middle" x="318.5" y="-1647.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge21" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.65,-1263.26C81.86,-1322.45 120.27,-1578.02 178,-1629 187.8,-1637.66 199.58,-1643.61 212.09,-1647.62"/>
<polygon fill="#000000" stroke="#000000" points="211.2,-1651.01 221.78,-1650.32 213.08,-1644.27 211.2,-1651.01"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node23" class="node">
<title>proc~torch_tensor_from_array_int64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node23"><a xlink:href="../proc/torch_tensor_from_array_int64_1d_default_layout.html" xlink:title="torch_tensor_from_array_int64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1620 181.5,-1620 181.5,-1596 455.5,-1596 455.5,-1620"/>
<text text-anchor="middle" x="318.5" y="-1605.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge22" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.6,-1263.16C71.15,-1311.97 77.57,-1492.15 178,-1578 185.04,-1584.02 193.05,-1588.72 201.58,-1592.38"/>
<polygon fill="#000000" stroke="#000000" points="200.43,-1595.69 211.02,-1595.97 202.91,-1589.15 200.43,-1595.69"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node24" class="node">
<title>proc~torch_tensor_from_array_int64_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node24"><a xlink:href="../proc/torch_tensor_from_array_int64_2d.html" xlink:title="torch_tensor_from_array_int64_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1578 222,-1578 222,-1554 415,-1554 415,-1578"/>
<text text-anchor="middle" x="318.5" y="-1563.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge23" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.26,-1263.24C73.93,-1308.79 86.35,-1469.8 178,-1545 187.86,-1553.09 199.48,-1558.76 211.74,-1562.65"/>
<polygon fill="#000000" stroke="#000000" points="211.12,-1566.11 221.69,-1565.41 212.99,-1559.37 211.12,-1566.11"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node25" class="node">
<title>proc~torch_tensor_from_array_int64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node25"><a xlink:href="../proc/torch_tensor_from_array_int64_2d_default_layout.html" xlink:title="torch_tensor_from_array_int64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1536 181.5,-1536 181.5,-1512 455.5,-1512 455.5,-1536"/>
<text text-anchor="middle" x="318.5" y="-1521.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge24" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.49,-1263.1C78.6,-1303.68 99.7,-1433.1 178,-1494 186.05,-1500.26 195.17,-1505.04 204.79,-1508.69"/>
<polygon fill="#000000" stroke="#000000" points="203.98,-1512.11 214.57,-1511.98 206.21,-1505.47 203.98,-1512.11"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node26" class="node">
<title>proc~torch_tensor_from_array_int64_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node26"><a xlink:href="../proc/torch_tensor_from_array_int64_3d.html" xlink:title="torch_tensor_from_array_int64_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1494 222,-1494 222,-1470 415,-1470 415,-1494"/>
<text text-anchor="middle" x="318.5" y="-1479.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge25" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.15,-1263.24C81.32,-1300.06 108.02,-1410.37 178,-1461 188.18,-1468.36 199.88,-1473.62 212.08,-1477.32"/>
<polygon fill="#000000" stroke="#000000" points="211.39,-1480.76 221.95,-1479.96 213.2,-1473.99 211.39,-1480.76"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node27" class="node">
<title>proc~torch_tensor_from_array_int64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node27"><a xlink:href="../proc/torch_tensor_from_array_int64_3d_default_layout.html" xlink:title="torch_tensor_from_array_int64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1452 181.5,-1452 181.5,-1428 455.5,-1428 455.5,-1452"/>
<text text-anchor="middle" x="318.5" y="-1437.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge26" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M77.41,-1263.31C89.34,-1294.19 121.41,-1373.03 178,-1410 188.44,-1416.82 200.24,-1421.75 212.44,-1425.36"/>
<polygon fill="#000000" stroke="#000000" points="211.74,-1428.79 222.31,-1427.98 213.54,-1422.03 211.74,-1428.79"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node28" class="node">
<title>proc~torch_tensor_from_array_int64_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node28"><a xlink:href="../proc/torch_tensor_from_array_int64_4d.html" xlink:title="torch_tensor_from_array_int64_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1410 222,-1410 222,-1386 415,-1386 415,-1410"/>
<text text-anchor="middle" x="318.5" y="-1395.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge27" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M78.25,-1263.21C92.21,-1289.1 128.61,-1349.35 178,-1377 188.43,-1382.84 199.96,-1387.22 211.79,-1390.48"/>
<polygon fill="#000000" stroke="#000000" points="211.23,-1393.95 221.78,-1392.96 212.92,-1387.15 211.23,-1393.95"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node29" class="node">
<title>proc~torch_tensor_from_array_int64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node29"><a xlink:href="../proc/torch_tensor_from_array_int64_4d_default_layout.html" xlink:title="torch_tensor_from_array_int64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1368 181.5,-1368 181.5,-1344 455.5,-1344 455.5,-1368"/>
<text text-anchor="middle" x="318.5" y="-1353.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge28" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M89.55,-1263.17C109.11,-1280.5 142.68,-1310.66 178,-1326 196.26,-1333.93 216.98,-1338.94 236.77,-1342.38"/>
<polygon fill="#000000" stroke="#000000" points="236.26,-1345.84 246.7,-1343.99 237.39,-1338.93 236.26,-1345.84"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node30" class="node">
<title>proc~torch_tensor_from_array_int64_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node30"><a xlink:href="../proc/torch_tensor_from_array_int64_5d.html" xlink:title="torch_tensor_from_array_int64_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="415,-1326 222,-1326 222,-1302 415,-1302 415,-1326"/>
<text text-anchor="middle" x="318.5" y="-1311.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge29" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M97.58,-1263.05C118.71,-1272.53 149.71,-1285.37 178,-1293 188.88,-1295.93 200.36,-1298.49 211.87,-1300.71"/>
<polygon fill="#000000" stroke="#000000" points="211.5,-1304.21 221.97,-1302.58 212.78,-1297.32 211.5,-1304.21"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node31" class="node">
<title>proc~torch_tensor_from_array_int64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node31"><a xlink:href="../proc/torch_tensor_from_array_int64_5d_default_layout.html" xlink:title="torch_tensor_from_array_int64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1284 181.5,-1284 181.5,-1260 455.5,-1260 455.5,-1284"/>
<text text-anchor="middle" x="318.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge30" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-1250.83C172.07,-1252.69 207.33,-1255.64 238.32,-1258.87"/>
<polygon fill="#000000" stroke="#000000" points="238.34,-1262.39 248.66,-1259.98 239.09,-1255.43 238.34,-1262.39"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node32" class="node">
<title>proc~torch_tensor_from_array_int8_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node32"><a xlink:href="../proc/torch_tensor_from_array_int8_1d.html" xlink:title="torch_tensor_from_array_int8_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1242 225,-1242 225,-1218 412,-1218 412,-1242"/>
<text text-anchor="middle" x="318.5" y="-1227.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge31" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-1245.01C164.69,-1243.07 190.33,-1240.88 214.86,-1238.78"/>
<polygon fill="#000000" stroke="#000000" points="215.26,-1242.26 224.92,-1237.92 214.66,-1235.28 215.26,-1242.26"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node33" class="node">
<title>proc~torch_tensor_from_array_int8_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node33"><a xlink:href="../proc/torch_tensor_from_array_int8_1d_default_layout.html" xlink:title="torch_tensor_from_array_int8_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1200 184.5,-1200 184.5,-1176 452.5,-1176 452.5,-1200"/>
<text text-anchor="middle" x="318.5" y="-1185.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge32" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M85.06,-1238.88C103.13,-1227.48 137.19,-1212.11 174.41,-1201.15"/>
<polygon fill="#000000" stroke="#000000" points="175.77,-1204.4 184.45,-1198.32 173.87,-1197.66 175.77,-1204.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node34" class="node">
<title>proc~torch_tensor_from_array_int8_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node34"><a xlink:href="../proc/torch_tensor_from_array_int8_2d.html" xlink:title="torch_tensor_from_array_int8_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1158 225,-1158 225,-1134 412,-1134 412,-1158"/>
<text text-anchor="middle" x="318.5" y="-1143.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge33" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M83.03,-1238.89C100.95,-1220.08 138.37,-1184.21 178,-1167 189.52,-1162 202.03,-1158.15 214.66,-1155.21"/>
<polygon fill="#000000" stroke="#000000" points="215.75,-1158.55 224.8,-1153.03 214.29,-1151.71 215.75,-1158.55"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node35" class="node">
<title>proc~torch_tensor_from_array_int8_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node35"><a xlink:href="../proc/torch_tensor_from_array_int8_2d_default_layout.html" xlink:title="torch_tensor_from_array_int8_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1116 184.5,-1116 184.5,-1092 452.5,-1092 452.5,-1116"/>
<text text-anchor="middle" x="318.5" y="-1101.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge34" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M76.14,-1238.67C87.59,-1212.12 122.11,-1151.74 175.48,-1117.94"/>
<polygon fill="#000000" stroke="#000000" points="177.4,-1120.87 184.21,-1112.75 173.82,-1114.86 177.4,-1120.87"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node36" class="node">
<title>proc~torch_tensor_from_array_int8_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node36"><a xlink:href="../proc/torch_tensor_from_array_int8_3d.html" xlink:title="torch_tensor_from_array_int8_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-1074 225,-1074 225,-1050 412,-1050 412,-1074"/>
<text text-anchor="middle" x="318.5" y="-1059.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge35" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M75.74,-1238.72C86.13,-1206.96 118.52,-1121.85 178,-1083 189.11,-1075.74 201.77,-1070.62 214.82,-1067.04"/>
<polygon fill="#000000" stroke="#000000" points="215.97,-1070.37 224.86,-1064.61 214.31,-1063.56 215.97,-1070.37"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node37" class="node">
<title>proc~torch_tensor_from_array_int8_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node37"><a xlink:href="../proc/torch_tensor_from_array_int8_3d_default_layout.html" xlink:title="torch_tensor_from_array_int8_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-1032 184.5,-1032 184.5,-1008 452.5,-1008 452.5,-1032"/>
<text text-anchor="middle" x="318.5" y="-1017.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge36" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.5,-1238.77C79.39,-1201.66 103.9,-1092.37 176.32,-1033.92"/>
<polygon fill="#000000" stroke="#000000" points="178.6,-1036.58 184.43,-1027.74 174.36,-1031.02 178.6,-1036.58"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node38" class="node">
<title>proc~torch_tensor_from_array_int8_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node38"><a xlink:href="../proc/torch_tensor_from_array_int8_4d.html" xlink:title="torch_tensor_from_array_int8_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-990 225,-990 225,-966 412,-966 412,-990"/>
<text text-anchor="middle" x="318.5" y="-975.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge37" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.06,-1238.79C77.34,-1197.44 97.26,-1061.79 178,-999 188.81,-990.59 201.56,-984.85 214.88,-981.02"/>
<polygon fill="#000000" stroke="#000000" points="215.81,-984.4 224.66,-978.56 214.1,-977.61 215.81,-984.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node39" class="node">
<title>proc~torch_tensor_from_array_int8_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node39"><a xlink:href="../proc/torch_tensor_from_array_int8_4d_default_layout.html" xlink:title="torch_tensor_from_array_int8_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-948 184.5,-948 184.5,-924 452.5,-924 452.5,-948"/>
<text text-anchor="middle" x="318.5" y="-933.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge38" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-1238.7C73.4,-1191.62 84.25,-1024.92 178,-948 201.19,-928.98 234.11,-923.35 262.15,-923.64"/>
<polygon fill="#000000" stroke="#000000" points="262.12,-927.14 272.24,-924 262.37,-920.14 262.12,-927.14"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node40" class="node">
<title>proc~torch_tensor_from_array_int8_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node40"><a xlink:href="../proc/torch_tensor_from_array_int8_5d.html" xlink:title="torch_tensor_from_array_int8_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="412,-906 225,-906 225,-882 412,-882 412,-906"/>
<text text-anchor="middle" x="318.5" y="-891.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge39" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.64,-1238.8C70.91,-1189.42 75.25,-1002.84 178,-915 188.64,-905.91 201.47,-899.83 215,-895.87"/>
<polygon fill="#000000" stroke="#000000" points="216.11,-899.2 224.95,-893.35 214.39,-892.41 216.11,-899.2"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node41" class="node">
<title>proc~torch_tensor_from_array_int8_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node41"><a xlink:href="../proc/torch_tensor_from_array_int8_5d_default_layout.html" xlink:title="torch_tensor_from_array_int8_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-864 184.5,-864 184.5,-840 452.5,-840 452.5,-864"/>
<text text-anchor="middle" x="318.5" y="-849.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge40" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-1238.84C80.67,-1178.51 119.38,-915.77 178,-864 202.3,-842.54 238.78,-837.66 268.34,-839.19"/>
<polygon fill="#000000" stroke="#000000" points="268.23,-842.69 278.47,-839.99 268.78,-835.72 268.23,-842.69"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node42" class="node">
<title>proc~torch_tensor_from_array_real32_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node42"><a xlink:href="../proc/torch_tensor_from_array_real32_1d.html" xlink:title="torch_tensor_from_array_real32_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-822 218.5,-822 218.5,-798 418.5,-798 418.5,-822"/>
<text text-anchor="middle" x="318.5" y="-807.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge41" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-1238.68C80.18,-1175.48 114.63,-888.46 178,-831 186.86,-822.97 197.41,-817.23 208.7,-813.22"/>
<polygon fill="#000000" stroke="#000000" points="209.81,-816.54 218.32,-810.23 207.73,-809.85 209.81,-816.54"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node43" class="node">
<title>proc~torch_tensor_from_array_real32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node43"><a xlink:href="../proc/torch_tensor_from_array_real32_1d_default_layout.html" xlink:title="torch_tensor_from_array_real32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-780 178,-780 178,-756 459,-756 459,-780"/>
<text text-anchor="middle" x="318.5" y="-765.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge42" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-1238.99C77.64,-1173.97 105.89,-867.49 170.78,-787.78"/>
<polygon fill="#000000" stroke="#000000" points="173.39,-790.11 177.59,-780.38 168.24,-785.36 173.39,-790.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node44" class="node">
<title>proc~torch_tensor_from_array_real32_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node44"><a xlink:href="../proc/torch_tensor_from_array_real32_2d.html" xlink:title="torch_tensor_from_array_real32_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-738 218.5,-738 218.5,-714 418.5,-714 418.5,-738"/>
<text text-anchor="middle" x="318.5" y="-723.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge43" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-1238.64C77.25,-1168.16 103.22,-817.57 178,-747 186.77,-738.73 197.32,-732.86 208.65,-728.78"/>
<polygon fill="#000000" stroke="#000000" points="209.82,-732.08 218.32,-725.75 207.73,-725.39 209.82,-732.08"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node45" class="node">
<title>proc~torch_tensor_from_array_real32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node45"><a xlink:href="../proc/torch_tensor_from_array_real32_2d_default_layout.html" xlink:title="torch_tensor_from_array_real32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-696 178,-696 178,-672 459,-672 459,-696"/>
<text text-anchor="middle" x="318.5" y="-681.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge44" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.43,-1238.73C75.41,-1166.21 95.36,-797.29 170.79,-703.91"/>
<polygon fill="#000000" stroke="#000000" points="173.41,-706.22 177.52,-696.46 168.22,-701.53 173.41,-706.22"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node46" class="node">
<title>proc~torch_tensor_from_array_real32_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node46"><a xlink:href="../proc/torch_tensor_from_array_real32_3d.html" xlink:title="torch_tensor_from_array_real32_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-654 218.5,-654 218.5,-630 418.5,-630 418.5,-654"/>
<text text-anchor="middle" x="318.5" y="-639.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge45" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.34,-1238.68C74.76,-1161.64 91.69,-746.84 178,-663 186.71,-654.53 197.29,-648.56 208.68,-644.43"/>
<polygon fill="#000000" stroke="#000000" points="209.92,-647.71 218.41,-641.38 207.82,-641.03 209.92,-647.71"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node47" class="node">
<title>proc~torch_tensor_from_array_real32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node47"><a xlink:href="../proc/torch_tensor_from_array_real32_3d_default_layout.html" xlink:title="torch_tensor_from_array_real32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-612 178,-612 178,-588 459,-588 459,-612"/>
<text text-anchor="middle" x="318.5" y="-597.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge46" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.15,-1238.78C73.39,-1160 84.45,-727.04 170.82,-619.96"/>
<polygon fill="#000000" stroke="#000000" points="173.65,-622.05 177.73,-612.27 168.44,-617.37 173.65,-622.05"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node48" class="node">
<title>proc~torch_tensor_from_array_real32_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node48"><a xlink:href="../proc/torch_tensor_from_array_real32_4d.html" xlink:title="torch_tensor_from_array_real32_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-570 218.5,-570 218.5,-546 418.5,-546 418.5,-570"/>
<text text-anchor="middle" x="318.5" y="-555.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge47" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.04,-1238.86C72.6,-1156.17 80.05,-676.27 178,-579 186.62,-570.44 197.14,-564.41 208.5,-560.25"/>
<polygon fill="#000000" stroke="#000000" points="209.73,-563.53 218.21,-557.18 207.62,-556.85 209.73,-563.53"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node49" class="node">
<title>proc~torch_tensor_from_array_real32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node49"><a xlink:href="../proc/torch_tensor_from_array_real32_4d_default_layout.html" xlink:title="torch_tensor_from_array_real32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-528 178,-528 178,-504 459,-504 459,-528"/>
<text text-anchor="middle" x="318.5" y="-513.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge48" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.93,-1238.85C71.6,-1154.28 73.35,-656.87 170.82,-536.03"/>
<polygon fill="#000000" stroke="#000000" points="173.66,-538.11 177.69,-528.31 168.43,-533.45 173.66,-538.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node50" class="node">
<title>proc~torch_tensor_from_array_real32_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node50"><a xlink:href="../proc/torch_tensor_from_array_real32_5d.html" xlink:title="torch_tensor_from_array_real32_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-486 218.5,-486 218.5,-462 418.5,-462 418.5,-486"/>
<text text-anchor="middle" x="318.5" y="-471.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge49" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.81,-1238.81C70.7,-1150.21 68.44,-605.67 178,-495 186.62,-486.3 197.19,-480.19 208.62,-476"/>
<polygon fill="#000000" stroke="#000000" points="209.92,-479.26 218.41,-472.92 207.82,-472.59 209.92,-479.26"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node51" class="node">
<title>proc~torch_tensor_from_array_real32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node51"><a xlink:href="../proc/torch_tensor_from_array_real32_5d_default_layout.html" xlink:title="torch_tensor_from_array_real32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-444 178,-444 178,-420 459,-420 459,-444"/>
<text text-anchor="middle" x="318.5" y="-429.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge50" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.63,-1238.83C77.99,-1145.56 116.76,-548.68 171.76,-452.63"/>
<polygon fill="#000000" stroke="#000000" points="174.7,-454.53 177.66,-444.35 169,-450.46 174.7,-454.53"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node52" class="node">
<title>proc~torch_tensor_from_array_real64_1d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node52"><a xlink:href="../proc/torch_tensor_from_array_real64_1d.html" xlink:title="torch_tensor_from_array_real64_1d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-402 218.5,-402 218.5,-378 418.5,-378 418.5,-402"/>
<text text-anchor="middle" x="318.5" y="-387.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge51" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.66,-1238.84C78.12,-1140.19 117.16,-473.31 178,-411 186.56,-402.24 197.09,-396.1 208.5,-391.89"/>
<polygon fill="#000000" stroke="#000000" points="209.8,-395.15 218.28,-388.79 207.69,-388.48 209.8,-395.15"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node53" class="node">
<title>proc~torch_tensor_from_array_real64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node53"><a xlink:href="../proc/torch_tensor_from_array_real64_1d_default_layout.html" xlink:title="torch_tensor_from_array_real64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-360 178,-360 178,-336 459,-336 459,-360"/>
<text text-anchor="middle" x="318.5" y="-345.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge52" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.51,-1238.73C77.01,-1139.45 111.49,-472.45 171.72,-368.64"/>
<polygon fill="#000000" stroke="#000000" points="174.65,-370.56 177.62,-360.39 168.96,-366.49 174.65,-370.56"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node54" class="node">
<title>proc~torch_tensor_from_array_real64_2d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node54"><a xlink:href="../proc/torch_tensor_from_array_real64_2d.html" xlink:title="torch_tensor_from_array_real64_2d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-318 218.5,-318 218.5,-294 418.5,-294 418.5,-318"/>
<text text-anchor="middle" x="318.5" y="-303.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge53" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.51,-1238.96C77,-1135.35 111.27,-396.12 178,-327 186.51,-318.19 197.01,-312.02 208.41,-307.8"/>
<polygon fill="#000000" stroke="#000000" points="209.7,-311.06 218.17,-304.69 207.58,-304.39 209.7,-311.06"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node55" class="node">
<title>proc~torch_tensor_from_array_real64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node55"><a xlink:href="../proc/torch_tensor_from_array_real64_2d_default_layout.html" xlink:title="torch_tensor_from_array_real64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-276 178,-276 178,-252 459,-252 459,-276"/>
<text text-anchor="middle" x="318.5" y="-261.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge54" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.39,-1238.76C76.08,-1134.25 106.06,-396.98 171.56,-284.85"/>
<polygon fill="#000000" stroke="#000000" points="174.61,-286.6 177.59,-276.43 168.92,-282.52 174.61,-286.6"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node56" class="node">
<title>proc~torch_tensor_from_array_real64_3d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node56"><a xlink:href="../proc/torch_tensor_from_array_real64_3d.html" xlink:title="torch_tensor_from_array_real64_3d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-234 218.5,-234 218.5,-210 418.5,-210 418.5,-234"/>
<text text-anchor="middle" x="318.5" y="-219.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge55" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.39,-1238.92C76.02,-1129.96 105.41,-318.91 178,-243 186.53,-234.08 197.11,-227.86 208.59,-223.62"/>
<polygon fill="#000000" stroke="#000000" points="209.95,-226.86 218.43,-220.51 207.84,-220.19 209.95,-226.86"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node57" class="node">
<title>proc~torch_tensor_from_array_real64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node57"><a xlink:href="../proc/torch_tensor_from_array_real64_3d_default_layout.html" xlink:title="torch_tensor_from_array_real64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-192 178,-192 178,-168 459,-168 459,-192"/>
<text text-anchor="middle" x="318.5" y="-177.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge56" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.29,-1238.91C75.22,-1129.76 100.61,-319.43 171.68,-200.58"/>
<polygon fill="#000000" stroke="#000000" points="174.52,-202.63 177.56,-192.48 168.85,-198.52 174.52,-202.63"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node58" class="node">
<title>proc~torch_tensor_from_array_real64_4d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node58"><a xlink:href="../proc/torch_tensor_from_array_real64_4d.html" xlink:title="torch_tensor_from_array_real64_4d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-150 218.5,-150 218.5,-126 418.5,-126 418.5,-150"/>
<text text-anchor="middle" x="318.5" y="-135.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge57" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.29,-1238.65C75.16,-1123.59 99.59,-241.65 178,-159 186.49,-150.05 197.05,-143.8 208.52,-139.55"/>
<polygon fill="#000000" stroke="#000000" points="209.88,-142.79 218.36,-136.43 207.77,-136.12 209.88,-142.79"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node59" class="node">
<title>proc~torch_tensor_from_array_real64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node59"><a xlink:href="../proc/torch_tensor_from_array_real64_4d_default_layout.html" xlink:title="torch_tensor_from_array_real64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-108 178,-108 178,-84 459,-84 459,-108"/>
<text text-anchor="middle" x="318.5" y="-93.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge58" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.21,-1238.81C74.45,-1124.32 95.11,-242.75 171.66,-116.55"/>
<polygon fill="#000000" stroke="#000000" points="174.66,-118.39 177.76,-108.26 169.02,-114.24 174.66,-118.39"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node60" class="node">
<title>proc~torch_tensor_from_array_real64_5d</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node60"><a xlink:href="../proc/torch_tensor_from_array_real64_5d.html" xlink:title="torch_tensor_from_array_real64_5d">
<polygon fill="#d9534f" stroke="#d9534f" points="418.5,-66 218.5,-66 218.5,-42 418.5,-42 418.5,-66"/>
<text text-anchor="middle" x="318.5" y="-51.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge59" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.2,-1238.84C74.29,-1119.78 93.65,-164.52 178,-75 186.46,-66.02 197,-59.76 208.47,-55.5"/>
<polygon fill="#000000" stroke="#000000" points="209.82,-58.74 218.29,-52.37 207.7,-52.07 209.82,-58.74"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node61" class="node">
<title>proc~torch_tensor_from_array_real64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node61"><a xlink:href="../proc/torch_tensor_from_array_real64_5d_default_layout.html" xlink:title="torch_tensor_from_array_real64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-24 178,-24 178,0 459,0 459,-24"/>
<text text-anchor="middle" x="318.5" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge60" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.14,-1238.8C73.72,-1119.43 89.55,-165.53 171.71,-32.42"/>
<polygon fill="#000000" stroke="#000000" points="174.6,-34.4 177.74,-24.28 168.98,-30.23 174.6,-34.4"/>
</g>
<!-- proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node62" class="node">
<title>proc~torch_tensor_from_blob</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node62"><a xlink:href="../proc/torch_tensor_from_blob.html" xlink:title="torch_tensor_from_blob">
<polygon fill="#d9534f" stroke="#d9534f" points="632,-1284 495,-1284 495,-1260 632,-1260 632,-1284"/>
<text text-anchor="middle" x="563.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_blob</text>
</a>
</g>
</g>
<!-- proc~torch_tensor_from_array_int16_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge61" class="edge">
<title>proc~torch_tensor_from_array_int16_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.19,-2492.56C431.74,-2488.63 447.35,-2481.41 459,-2469 542.57,-2379.98 559.85,-1452.49 562.19,-1294.74"/>
<polygon fill="#000000" stroke="#000000" points="565.7,-1294.42 562.34,-1284.37 558.7,-1294.32 565.7,-1294.42"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge62" class="edge">
<title>proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.6,-2460.04C253.54,-2465.61 205.12,-2464.79 178,-2436 95.37,-2348.3 75.11,-1429.74 72.35,-1273.48"/>
<polygon fill="#000000" stroke="#000000" points="75.85,-1273.14 72.18,-1263.2 68.85,-1273.26 75.85,-1273.14"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge63" class="edge">
<title>proc~torch_tensor_from_array_int16_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.12,-2408.5C431.69,-2404.57 447.31,-2397.37 459,-2385 536.77,-2302.69 558.77,-1445.17 562.04,-1294.53"/>
<polygon fill="#000000" stroke="#000000" points="565.55,-1294.29 562.26,-1284.22 558.55,-1294.15 565.55,-1294.29"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge64" class="edge">
<title>proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.34,-2376.05C253.32,-2381.54 205.14,-2380.61 178,-2352 101.18,-2271.03 76.17,-1422.88 72.5,-1273.38"/>
<polygon fill="#000000" stroke="#000000" points="75.99,-1273.06 72.25,-1263.15 68.99,-1273.23 75.99,-1273.06"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge65" class="edge">
<title>proc~torch_tensor_from_array_int16_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.05,-2324.43C431.62,-2320.51 447.26,-2313.33 459,-2301 530.94,-2225.43 557.57,-1438.68 561.86,-1294.59"/>
<polygon fill="#000000" stroke="#000000" points="565.37,-1294.43 562.16,-1284.33 558.37,-1294.22 565.37,-1294.43"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge66" class="edge">
<title>proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.39,-2292.01C253.4,-2297.46 205.25,-2296.5 178,-2268 106.95,-2193.71 77.29,-1415.21 72.66,-1273.13"/>
<polygon fill="#000000" stroke="#000000" points="76.15,-1272.89 72.34,-1263.01 69.16,-1273.12 76.15,-1272.89"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge67" class="edge">
<title>proc~torch_tensor_from_array_int16_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.32,-2240.26C431.76,-2236.33 447.29,-2229.19 459,-2217 525.16,-2148.11 556.3,-1431.09 561.66,-1294.43"/>
<polygon fill="#000000" stroke="#000000" points="565.16,-1294.44 562.05,-1284.31 558.16,-1294.17 565.16,-1294.44"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge68" class="edge">
<title>proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M285.14,-2208C253.2,-2213.35 205.3,-2212.28 178,-2184 112.76,-2116.42 78.54,-1408.19 72.85,-1273.12"/>
<polygon fill="#000000" stroke="#000000" points="76.35,-1272.96 72.44,-1263.11 69.35,-1273.25 76.35,-1272.96"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge69" class="edge">
<title>proc~torch_tensor_from_array_int16_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.22,-2156.17C431.67,-2152.24 447.23,-2145.13 459,-2133 519.37,-2070.8 554.88,-1423.71 561.41,-1294.41"/>
<polygon fill="#000000" stroke="#000000" points="564.91,-1294.31 561.92,-1284.15 557.92,-1293.96 564.91,-1294.31"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge70" class="edge">
<title>proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M284.61,-2124.04C252.73,-2129.22 205.29,-2127.95 178,-2100 118.57,-2039.13 79.94,-1401.37 73.09,-1273.26"/>
<polygon fill="#000000" stroke="#000000" points="76.58,-1272.89 72.56,-1263.08 69.59,-1273.25 76.58,-1272.89"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge71" class="edge">
<title>proc~torch_tensor_from_array_int32_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.1,-2072.04C431.56,-2068.13 447.15,-2061.05 459,-2049 513.59,-1993.48 553.29,-1416.21 561.1,-1294.46"/>
<polygon fill="#000000" stroke="#000000" points="564.61,-1294.34 561.75,-1284.14 557.63,-1293.9 564.61,-1294.34"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge72" class="edge">
<title>proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M284.39,-2040C252.57,-2045.07 205.4,-2043.67 178,-2016 71.18,-1908.1 70.66,-1387.76 71.73,-1273.23"/>
<polygon fill="#000000" stroke="#000000" points="75.23,-1273.21 71.84,-1263.17 68.23,-1273.13 75.23,-1273.21"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge73" class="edge">
<title>proc~torch_tensor_from_array_int32_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.3,-1987.81C431.64,-1983.89 447.14,-1976.87 459,-1965 556.14,-1867.74 562.43,-1402.1 562.57,-1294.31"/>
<polygon fill="#000000" stroke="#000000" points="566.07,-1294.24 562.57,-1284.24 559.07,-1294.24 566.07,-1294.24"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge74" class="edge">
<title>proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M283.59,-1956.04C251.87,-1960.86 205.37,-1959.18 178,-1932 82.68,-1837.35 73.06,-1380.37 72.1,-1273.35"/>
<polygon fill="#000000" stroke="#000000" points="75.6,-1273.05 72.03,-1263.08 68.6,-1273.1 75.6,-1273.05"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge75" class="edge">
<title>proc~torch_tensor_from_array_int32_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.11,-1903.62C431.47,-1899.72 447.03,-1892.75 459,-1881 544.68,-1796.92 559.66,-1394.16 562.07,-1294.4"/>
<polygon fill="#000000" stroke="#000000" points="565.57,-1294.32 562.29,-1284.25 558.57,-1294.17 565.57,-1294.32"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge76" class="edge">
<title>proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.82,-1872.04C251.21,-1876.6 205.4,-1874.62 178,-1848 94,-1766.4 75.72,-1371.3 72.57,-1273.04"/>
<polygon fill="#000000" stroke="#000000" points="76.07,-1272.93 72.27,-1263.03 69.07,-1273.13 76.07,-1272.93"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge77" class="edge">
<title>proc~torch_tensor_from_array_int32_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.22,-1819.28C431.47,-1815.38 446.96,-1808.51 459,-1797 533.3,-1725.99 556.48,-1385.51 561.4,-1294.44"/>
<polygon fill="#000000" stroke="#000000" points="564.9,-1294.56 561.93,-1284.39 557.91,-1294.19 564.9,-1294.56"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge78" class="edge">
<title>proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M281.77,-1788.02C250.34,-1792.23 205.43,-1789.89 178,-1764 105.51,-1695.58 78.88,-1364.03 73.22,-1273.65"/>
<polygon fill="#000000" stroke="#000000" points="76.7,-1273.19 72.6,-1263.42 69.71,-1273.61 76.7,-1273.19"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge79" class="edge">
<title>proc~torch_tensor_from_array_int32_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.25,-1734.84C431.4,-1730.96 446.85,-1724.21 459,-1713 522.09,-1654.83 552.83,-1375.35 560.53,-1294.16"/>
<polygon fill="#000000" stroke="#000000" points="564.02,-1294.34 561.46,-1284.06 557.05,-1293.7 564.02,-1294.34"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge80" class="edge">
<title>proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M279.86,-1704.03C248.72,-1707.66 205.31,-1704.76 178,-1680 116.68,-1624.4 82.44,-1353.83 74.05,-1273.41"/>
<polygon fill="#000000" stroke="#000000" points="77.52,-1272.97 73.03,-1263.37 70.55,-1273.67 77.52,-1272.97"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge81" class="edge">
<title>proc~torch_tensor_from_array_int64_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.15,-1650.24C431.21,-1646.4 446.65,-1639.81 459,-1629 510.85,-1583.61 548.22,-1365.48 559.19,-1294.43"/>
<polygon fill="#000000" stroke="#000000" points="562.68,-1294.75 560.72,-1284.33 555.76,-1293.7 562.68,-1294.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge82" class="edge">
<title>proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M276.15,-1620.02C245.6,-1622.7 204.81,-1618.92 178,-1596 79.3,-1511.62 71.4,-1336.13 71.58,-1273.53"/>
<polygon fill="#000000" stroke="#000000" points="75.09,-1273.24 71.69,-1263.2 68.09,-1273.17 75.09,-1273.24"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge83" class="edge">
<title>proc~torch_tensor_from_array_int64_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.18,-1565.24C431.05,-1561.46 446.42,-1555.15 459,-1545 538.92,-1480.52 557.16,-1347.12 561.3,-1294.27"/>
<polygon fill="#000000" stroke="#000000" points="564.79,-1294.48 561.99,-1284.27 557.81,-1294.01 564.79,-1294.48"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge84" class="edge">
<title>proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-1514.4C180.15,-1513.63 179.06,-1512.83 178,-1512 100.69,-1451.87 79.14,-1324.94 73.69,-1273.26"/>
<polygon fill="#000000" stroke="#000000" points="77.16,-1272.78 72.74,-1263.15 70.19,-1273.44 77.16,-1272.78"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge85" class="edge">
<title>proc~torch_tensor_from_array_int64_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.15,-1479.51C430.77,-1475.86 446.05,-1470.04 459,-1461 517.72,-1419.99 546.5,-1334.62 557.28,-1294.17"/>
<polygon fill="#000000" stroke="#000000" points="560.73,-1294.8 559.8,-1284.25 553.94,-1293.08 560.73,-1294.8"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge86" class="edge">
<title>proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.43,-1430.14C180.27,-1429.45 179.13,-1428.74 178,-1428 121.26,-1390.93 89.17,-1311.77 77.32,-1272.92"/>
<polygon fill="#000000" stroke="#000000" points="80.62,-1271.75 74.51,-1263.1 73.89,-1273.67 80.62,-1271.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge87" class="edge">
<title>proc~torch_tensor_from_array_int64_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M415.1,-1391.97C430.31,-1388.68 445.47,-1383.89 459,-1377 498,-1357.14 531.08,-1316.96 548.75,-1292.47"/>
<polygon fill="#000000" stroke="#000000" points="551.65,-1294.42 554.54,-1284.22 545.93,-1290.4 551.65,-1294.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge88" class="edge">
<title>proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.4,-1345.43C180.26,-1344.96 179.12,-1344.49 178,-1344 139.62,-1327.33 103.3,-1293.15 84.78,-1270.89"/>
<polygon fill="#000000" stroke="#000000" points="87.51,-1268.71 78.58,-1263.01 82.01,-1273.03 87.51,-1268.71"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge89" class="edge">
<title>proc~torch_tensor_from_array_int64_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M404.08,-1301.97C422.23,-1299.19 441.27,-1296.13 459,-1293 470.92,-1290.9 483.57,-1288.48 495.79,-1286.05"/>
<polygon fill="#000000" stroke="#000000" points="496.81,-1289.42 505.93,-1284.02 495.43,-1282.56 496.81,-1289.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge90" class="edge">
<title>proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.2,-1267.05C170.82,-1266.11 160.58,-1265.11 150.77,-1264.09"/>
<polygon fill="#000000" stroke="#000000" points="151.03,-1260.59 140.71,-1263.01 150.28,-1267.55 151.03,-1260.59"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge91" class="edge">
<title>proc~torch_tensor_from_array_int8_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M404.08,-1242.03C422.23,-1244.81 441.27,-1247.87 459,-1251 470.92,-1253.1 483.57,-1255.52 495.79,-1257.95"/>
<polygon fill="#000000" stroke="#000000" points="495.43,-1261.44 505.93,-1259.98 496.81,-1254.58 495.43,-1261.44"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge92" class="edge">
<title>proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.04,-1200C244.51,-1204.39 208.86,-1209.68 178,-1218 160.83,-1222.63 142.65,-1229.19 126.29,-1235.35"/>
<polygon fill="#000000" stroke="#000000" points="124.99,-1232.1 116.88,-1238.92 127.47,-1238.65 124.99,-1232.1"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge93" class="edge">
<title>proc~torch_tensor_from_array_int8_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.16,-1151.41C428.35,-1154.72 444.6,-1159.66 459,-1167 498,-1186.86 531.08,-1227.04 548.75,-1251.53"/>
<polygon fill="#000000" stroke="#000000" points="545.93,-1253.6 554.54,-1259.78 551.65,-1249.58 545.93,-1253.6"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge94" class="edge">
<title>proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M230.57,-1116.04C212.39,-1119.58 193.92,-1125.09 178,-1134 136.72,-1157.11 104.52,-1203 86.9,-1230.12"/>
<polygon fill="#000000" stroke="#000000" points="83.75,-1228.56 81.29,-1238.87 89.64,-1232.34 83.75,-1228.56"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge95" class="edge">
<title>proc~torch_tensor_from_array_int8_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.25,-1063.84C428.86,-1067.43 445.25,-1073.39 459,-1083 517.72,-1124.01 546.5,-1209.38 557.28,-1249.83"/>
<polygon fill="#000000" stroke="#000000" points="553.94,-1250.92 559.8,-1259.75 560.73,-1249.2 553.94,-1250.92"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge96" class="edge">
<title>proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M217.61,-1032.01C203.43,-1035.85 189.71,-1041.53 178,-1050 116.06,-1094.82 88.03,-1186.39 77.43,-1228.84"/>
<polygon fill="#000000" stroke="#000000" points="73.98,-1228.21 75.05,-1238.75 80.79,-1229.85 73.98,-1228.21"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge97" class="edge">
<title>proc~torch_tensor_from_array_int8_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.28,-978.1C429.18,-981.79 445.66,-988.23 459,-999 538.92,-1063.48 557.16,-1196.88 561.3,-1249.73"/>
<polygon fill="#000000" stroke="#000000" points="557.81,-1249.99 561.99,-1259.73 564.79,-1249.52 557.81,-1249.99"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge98" class="edge">
<title>proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M212.39,-948.06C199.89,-952.04 188.04,-957.77 178,-966 94.59,-1034.44 76.8,-1173.95 73.02,-1228.6"/>
<polygon fill="#000000" stroke="#000000" points="69.5,-1228.73 72.4,-1238.92 76.49,-1229.15 69.5,-1228.73"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge99" class="edge">
<title>proc~torch_tensor_from_array_int8_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M412.26,-893.11C429.36,-896.83 445.92,-903.55 459,-915 510.85,-960.39 548.22,-1178.52 559.19,-1249.57"/>
<polygon fill="#000000" stroke="#000000" points="555.76,-1250.3 560.72,-1259.67 562.68,-1249.25 555.76,-1250.3"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge100" class="edge">
<title>proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M209.72,-864.1C198.09,-868.15 187.18,-873.89 178,-882 124.05,-929.64 86.97,-1155.95 75.65,-1228.65"/>
<polygon fill="#000000" stroke="#000000" points="72.12,-1228.53 74.05,-1238.94 79.04,-1229.6 72.12,-1228.53"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge101" class="edge">
<title>proc~torch_tensor_from_array_real32_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.83,-810.07C433.67,-814.06 447.75,-820.62 459,-831 522.09,-889.17 552.83,-1168.65 560.53,-1249.84"/>
<polygon fill="#000000" stroke="#000000" points="557.05,-1250.3 561.46,-1259.94 564.02,-1249.66 557.05,-1250.3"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge102" class="edge">
<title>proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.3,-780.05C197.13,-784.16 186.71,-789.93 178,-798 112.79,-858.43 82.15,-1145.96 74.17,-1228.78"/>
<polygon fill="#000000" stroke="#000000" points="70.68,-1228.58 73.22,-1238.86 77.65,-1229.24 70.68,-1228.58"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge103" class="edge">
<title>proc~torch_tensor_from_array_real32_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.79,-725.63C433.73,-729.65 447.85,-736.34 459,-747 533.3,-818.01 556.48,-1158.49 561.4,-1249.56"/>
<polygon fill="#000000" stroke="#000000" points="557.91,-1249.81 561.93,-1259.61 564.9,-1249.44 557.91,-1249.81"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge104" class="edge">
<title>proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.34,-696.02C196.48,-700.16 186.4,-705.95 178,-714 101.55,-787.28 78.29,-1135.84 73.19,-1228.48"/>
<polygon fill="#000000" stroke="#000000" points="69.69,-1228.52 72.65,-1238.69 76.68,-1228.9 69.69,-1228.52"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge105" class="edge">
<title>proc~torch_tensor_from_array_real32_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.68,-641.29C433.72,-645.33 447.9,-652.11 459,-663 544.68,-747.08 559.66,-1149.84 562.07,-1249.6"/>
<polygon fill="#000000" stroke="#000000" points="558.57,-1249.83 562.29,-1259.75 565.57,-1249.68 558.57,-1249.83"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge106" class="edge">
<title>proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M206.45,-612.08C195.9,-616.24 186.12,-622.02 178,-630 90.12,-716.37 74.94,-1127.38 72.46,-1228.57"/>
<polygon fill="#000000" stroke="#000000" points="68.95,-1228.77 72.23,-1238.85 75.95,-1228.93 68.95,-1228.77"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge107" class="edge">
<title>proc~torch_tensor_from_array_real32_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.51,-557C433.67,-561.05 447.92,-567.91 459,-579 556.14,-676.26 562.43,-1141.9 562.57,-1249.69"/>
<polygon fill="#000000" stroke="#000000" points="559.07,-1249.76 562.57,-1259.76 566.07,-1249.76 559.07,-1249.76"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge108" class="edge">
<title>proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.96,-528.06C195.56,-532.24 185.96,-538.03 178,-546 78.61,-645.59 72.02,-1119.83 71.91,-1228.76"/>
<polygon fill="#000000" stroke="#000000" points="68.41,-1228.92 71.91,-1238.92 75.41,-1228.92 68.41,-1228.92"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge109" class="edge">
<title>proc~torch_tensor_from_array_real32_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.66,-472.86C433.8,-476.92 448.01,-483.82 459,-495 513.59,-550.52 553.29,-1127.79 561.1,-1249.54"/>
<polygon fill="#000000" stroke="#000000" points="557.63,-1250.1 561.75,-1259.86 564.61,-1249.66 557.63,-1250.1"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge110" class="edge">
<title>proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.5,-444.07C195.25,-448.27 185.81,-454.05 178,-462 122.19,-518.79 81.75,-1106.82 73.54,-1228.95"/>
<polygon fill="#000000" stroke="#000000" points="70.04,-1228.78 72.86,-1238.99 77.02,-1229.25 70.04,-1228.78"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge111" class="edge">
<title>proc~torch_tensor_from_array_real64_1d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.78,-388.74C433.91,-392.82 448.08,-399.75 459,-411 519.37,-473.2 554.88,-1120.29 561.41,-1249.59"/>
<polygon fill="#000000" stroke="#000000" points="557.92,-1250.04 561.92,-1259.85 564.91,-1249.69 557.92,-1250.04"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge112" class="edge">
<title>proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M205.06,-360.12C194.96,-364.31 185.68,-370.09 178,-378 116.42,-441.44 80.11,-1098.94 73.21,-1228.85"/>
<polygon fill="#000000" stroke="#000000" points="69.71,-1228.66 72.68,-1238.84 76.7,-1229.03 69.71,-1228.66"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge113" class="edge">
<title>proc~torch_tensor_from_array_real64_2d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.53,-304.55C433.77,-308.62 448.06,-315.61 459,-327 525.16,-395.89 556.3,-1112.91 561.66,-1249.57"/>
<polygon fill="#000000" stroke="#000000" points="558.16,-1249.83 562.05,-1259.69 565.16,-1249.56 558.16,-1249.83"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge114" class="edge">
<title>proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.98,-276.03C194.9,-280.25 185.64,-286.05 178,-294 110.64,-364.12 78.64,-1091.23 72.94,-1228.71"/>
<polygon fill="#000000" stroke="#000000" points="69.44,-1228.74 72.52,-1238.88 76.43,-1229.03 69.44,-1228.74"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge115" class="edge">
<title>proc~torch_tensor_from_array_real64_3d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.61,-220.47C433.85,-224.55 448.11,-231.56 459,-243 530.94,-318.57 557.57,-1105.32 561.86,-1249.41"/>
<polygon fill="#000000" stroke="#000000" points="558.37,-1249.78 562.16,-1259.67 565.37,-1249.57 558.37,-1249.78"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge116" class="edge">
<title>proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.57,-192.11C194.63,-196.32 185.52,-202.11 178,-210 104.88,-286.78 77.33,-1083.21 72.72,-1228.41"/>
<polygon fill="#000000" stroke="#000000" points="69.21,-1228.64 72.39,-1238.75 76.21,-1228.86 69.21,-1228.64"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge117" class="edge">
<title>proc~torch_tensor_from_array_real64_4d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.68,-136.4C433.91,-140.49 448.15,-147.52 459,-159 536.77,-241.31 558.77,-1098.83 562.04,-1249.47"/>
<polygon fill="#000000" stroke="#000000" points="558.55,-1249.85 562.26,-1259.78 565.55,-1249.71 558.55,-1249.85"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge118" class="edge">
<title>proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.51,-108.05C194.59,-112.28 185.49,-118.08 178,-126 99.07,-209.5 76.08,-1076.28 72.52,-1228.35"/>
<polygon fill="#000000" stroke="#000000" points="69.01,-1228.67 72.28,-1238.75 76.01,-1228.83 69.01,-1228.67"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d&#45;&gt;proc~torch_tensor_from_blob -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge119" class="edge">
<title>proc~torch_tensor_from_array_real64_5d&#45;&gt;proc~torch_tensor_from_blob</title>
<path fill="none" stroke="#000000" d="M418.75,-52.34C433.97,-56.44 448.19,-63.48 459,-75 542.57,-164.02 559.85,-1091.51 562.19,-1249.26"/>
<polygon fill="#000000" stroke="#000000" points="558.7,-1249.68 562.34,-1259.63 565.7,-1249.58 558.7,-1249.68"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge120" class="edge">
<title>proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M204.46,-24C194.54,-28.24 185.46,-34.06 178,-42 93.2,-132.28 74.92,-1070.45 72.35,-1228.51"/>
<polygon fill="#000000" stroke="#000000" points="68.84,-1228.83 72.19,-1238.88 75.84,-1228.94 68.84,-1228.83"/>
</g>
<!-- interface~torch_from_blob_c -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_node63" class="node">
<title>interface~torch_from_blob_c</title>
<g id="a_interface~~torch_tensor_from_array~~CallsGraph_node63"><a xlink:href="../interface/torch_from_blob_c.html" xlink:title="torch_from_blob_c">
<polygon fill="#a7506f" stroke="#a7506f" points="777,-1284 668,-1284 668,-1260 777,-1260 777,-1284"/>
<text text-anchor="middle" x="722.5" y="-1269.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_from_blob_c</text>
</a>
</g>
</g>
<!-- proc~torch_tensor_from_blob&#45;&gt;interface~torch_from_blob_c -->
<g id="interface~~torch_tensor_from_array~~CallsGraph_edge121" class="edge">
<title>proc~torch_tensor_from_blob&#45;&gt;interface~torch_from_blob_c</title>
<path fill="none" stroke="#000000" d="M632.45,-1272C640.72,-1272 649.16,-1272 657.37,-1272"/>
<polygon fill="#000000" stroke="#000000" points="657.64,-1275.5 667.64,-1272 657.64,-1268.5 657.64,-1275.5"/>
</g>
</g>
</svg>
</div>                <script>
                  var paninterfacetorch_tensor_from_arrayCallsGraph = svgPanZoom('#interfacetorch_tensor_from_arrayCallsGraph',
                    {zoomEnabled: true, controlIconsEnabled: true, fit: true, center: true,}
                  );
                </script>          <div>
            <a type="button" class="graph-help" data-bs-toggle="modal" href="#CallsGraph-help-text">Help</a>
          </div>
          <div class="modal fade" id="CallsGraph-help-text" tabindex="-1" role="dialog">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title" id="-graph-help-label">Graph Key</h4>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
<p>Nodes of different colours represent the following: </p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: Graph Key Pages: 1 -->
<svg width="641pt" height="28pt"
 viewBox="0.00 0.00 641.00 27.51" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(0.86 0.86) rotate(0) translate(4 28)">
<title>Graph Key</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-28 741.5,-28 741.5,4 -4,4"/>
<!-- Subroutine -->
<g id="node1" class="node">
<title>Subroutine</title>
<polygon fill="#d9534f" stroke="#d9534f" points="70,-24 0,-24 0,0 70,0 70,-24"/>
<text text-anchor="middle" x="35" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Subroutine</text>
</g>
<!-- Function -->
<g id="node2" class="node">
<title>Function</title>
<polygon fill="#d94e8f" stroke="#d94e8f" points="146,-24 88,-24 88,0 146,0 146,-24"/>
<text text-anchor="middle" x="117" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Function</text>
</g>
<!-- Interface -->
<g id="node3" class="node">
<title>Interface</title>
<polygon fill="#a7506f" stroke="#a7506f" points="225.5,-24 164.5,-24 164.5,0 225.5,0 225.5,-24"/>
<text text-anchor="middle" x="195" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Interface</text>
</g>
<!-- Type Bound Procedure -->
<g id="node4" class="node">
<title>Type Bound Procedure</title>
<polygon fill="#a7506f" stroke="#a7506f" points="374,-24 244,-24 244,0 374,0 374,-24"/>
<text text-anchor="middle" x="309" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Type Bound Procedure</text>
</g>
<!-- Unknown Procedure Type -->
<g id="node5" class="node">
<title>Unknown Procedure Type</title>
<polygon fill="#777777" stroke="#777777" points="537.5,-24 392.5,-24 392.5,0 537.5,0 537.5,-24"/>
<text text-anchor="middle" x="465" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Unknown Procedure Type</text>
</g>
<!-- Program -->
<g id="node6" class="node">
<title>Program</title>
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="614,-24 556,-24 556,0 614,0 614,-24"/>
<text text-anchor="middle" x="585" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Program</text>
</g>
<!-- This Page&#39;s Entity -->
<g id="node7" class="node">
<title>This Page&#39;s Entity</title>
<polygon fill="none" stroke="black" points="737.5,-24 632.5,-24 632.5,0 737.5,0 737.5,-24"/>
<text text-anchor="middle" x="685" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50">This Page&#39;s Entity</text>
</g>
</g>
</svg>

<p>Solid arrows point from a procedure to one which it calls. Dashed 
arrows point from an interface to procedures which implement that interface.
This could include the module procedures in a generic interface or the
implementation in a submodule of an interface in a parent module.
</p>
 </div>
            </div>
          </div>
        </div>
          </div>
        </div>
        <div class="card">
          <div class="card-header">
            <h3 class="card-title">Called by</h3>
          </div>
          <div class="card-body">
            <div class="depgraph"><?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: interface~~torch_tensor_from_array~~CalledByGraph Pages: 1 -->
<svg id="interfacetorch_tensor_from_arrayCalledByGraph" width="467pt" height="1252pt"
 viewBox="0.00 0.00 467.00 1251.99" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="interface~~torch_tensor_from_array~~CalledByGraph" class="graph" transform="scale(1 1) rotate(0) translate(4 1247.99)">
<title>interface~~torch_tensor_from_array~~CalledByGraph</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-1247.99 463,-1247.99 463,4 -4,4"/>
<!-- interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node1" class="node">
<title>interface~torch_tensor_from_array</title>
<polygon fill="none" stroke="black" points="142,-633 0,-633 0,-609 142,-609 142,-633"/>
<text text-anchor="middle" x="71" y="-618.6" font-family="Helvetica,sans-Serif" font-size="10.50">torch_tensor_from_array</text>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node2" class="node">
<title>proc~torch_tensor_from_array_int16_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node2"><a xlink:href="../proc/torch_tensor_from_array_int16_1d_default_layout.html" xlink:title="torch_tensor_from_array_int16_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1242 181.5,-1242 181.5,-1218 455.5,-1218 455.5,-1242"/>
<text text-anchor="middle" x="318.5" y="-1227.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge31" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.42,-633.17C75.1,-709.38 92.53,-1116.97 178,-1200 183.81,-1205.64 190.44,-1210.17 197.58,-1213.81"/>
<polygon fill="#000000" stroke="#000000" points="196.33,-1217.08 206.89,-1217.96 199.18,-1210.69 196.33,-1217.08"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node3" class="node">
<title>proc~torch_tensor_from_array_int16_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node3"><a xlink:href="../proc/torch_tensor_from_array_int16_2d_default_layout.html" xlink:title="torch_tensor_from_array_int16_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1200 181.5,-1200 181.5,-1176 455.5,-1176 455.5,-1200"/>
<text text-anchor="middle" x="318.5" y="-1185.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge32" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.65,-633.31C76.44,-706.6 98.36,-1081.66 178,-1158 183.91,-1163.66 190.64,-1168.2 197.9,-1171.84"/>
<polygon fill="#000000" stroke="#000000" points="196.77,-1175.17 207.34,-1175.98 199.59,-1168.76 196.77,-1175.17"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node4" class="node">
<title>proc~torch_tensor_from_array_int16_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node4"><a xlink:href="../proc/torch_tensor_from_array_int16_3d_default_layout.html" xlink:title="torch_tensor_from_array_int16_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1158 181.5,-1158 181.5,-1134 455.5,-1134 455.5,-1158"/>
<text text-anchor="middle" x="318.5" y="-1143.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge33" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.9,-633.07C77.82,-702.43 104.03,-1046.19 178,-1116 184.01,-1121.67 190.86,-1126.22 198.23,-1129.85"/>
<polygon fill="#000000" stroke="#000000" points="197.24,-1133.23 207.81,-1133.98 200.01,-1126.8 197.24,-1133.23"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node5" class="node">
<title>proc~torch_tensor_from_array_int16_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node5"><a xlink:href="../proc/torch_tensor_from_array_int16_4d_default_layout.html" xlink:title="torch_tensor_from_array_int16_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1116 181.5,-1116 181.5,-1092 455.5,-1092 455.5,-1116"/>
<text text-anchor="middle" x="318.5" y="-1101.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge34" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.22,-633.14C79.4,-699.12 109.79,-1010.8 178,-1074 184.26,-1079.8 191.41,-1084.41 199.07,-1088.08"/>
<polygon fill="#000000" stroke="#000000" points="197.72,-1091.3 208.3,-1091.95 200.43,-1084.85 197.72,-1091.3"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node6" class="node">
<title>proc~torch_tensor_from_array_int16_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node6"><a xlink:href="../proc/torch_tensor_from_array_int16_5d_default_layout.html" xlink:title="torch_tensor_from_array_int16_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1074 181.5,-1074 181.5,-1050 455.5,-1050 455.5,-1074"/>
<text text-anchor="middle" x="318.5" y="-1059.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int16_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge35" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int16_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.58,-633.01C81.09,-695.05 115.46,-975.3 178,-1032 184.39,-1037.79 191.66,-1042.39 199.45,-1046.03"/>
<polygon fill="#000000" stroke="#000000" points="198.23,-1049.32 208.81,-1049.89 200.9,-1042.84 198.23,-1049.32"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node7" class="node">
<title>proc~torch_tensor_from_array_int32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node7"><a xlink:href="../proc/torch_tensor_from_array_int32_1d_default_layout.html" xlink:title="torch_tensor_from_array_int32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-1032 181.5,-1032 181.5,-1008 455.5,-1008 455.5,-1032"/>
<text text-anchor="middle" x="318.5" y="-1017.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge36" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.05,-633.06C83.05,-691.32 121.17,-939.81 178,-990 184.67,-995.89 192.25,-1000.53 200.36,-1004.18"/>
<polygon fill="#000000" stroke="#000000" points="199.13,-1007.46 209.72,-1007.9 201.72,-1000.96 199.13,-1007.46"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node8" class="node">
<title>proc~torch_tensor_from_array_int32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node8"><a xlink:href="../proc/torch_tensor_from_array_int32_2d_default_layout.html" xlink:title="torch_tensor_from_array_int32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-990 181.5,-990 181.5,-966 455.5,-966 455.5,-990"/>
<text text-anchor="middle" x="318.5" y="-975.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge37" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.6,-633.16C71.15,-681.97 77.57,-862.15 178,-948 185.04,-954.02 193.05,-958.72 201.58,-962.38"/>
<polygon fill="#000000" stroke="#000000" points="200.43,-965.69 211.02,-965.97 202.91,-959.15 200.43,-965.69"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node9" class="node">
<title>proc~torch_tensor_from_array_int32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node9"><a xlink:href="../proc/torch_tensor_from_array_int32_3d_default_layout.html" xlink:title="torch_tensor_from_array_int32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-948 181.5,-948 181.5,-924 455.5,-924 455.5,-948"/>
<text text-anchor="middle" x="318.5" y="-933.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge38" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.4,-633.08C74.6,-677.85 88.65,-832.7 178,-906 185.45,-912.11 193.9,-916.84 202.87,-920.5"/>
<polygon fill="#000000" stroke="#000000" points="201.8,-923.83 212.39,-923.94 204.18,-917.25 201.8,-923.83"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node10" class="node">
<title>proc~torch_tensor_from_array_int32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node10"><a xlink:href="../proc/torch_tensor_from_array_int32_4d_default_layout.html" xlink:title="torch_tensor_from_array_int32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-906 181.5,-906 181.5,-882 455.5,-882 455.5,-906"/>
<text text-anchor="middle" x="318.5" y="-891.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge39" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.49,-633.1C78.6,-673.68 99.7,-803.1 178,-864 186.05,-870.26 195.17,-875.04 204.79,-878.69"/>
<polygon fill="#000000" stroke="#000000" points="203.98,-882.11 214.57,-881.98 206.21,-875.47 203.98,-882.11"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node11" class="node">
<title>proc~torch_tensor_from_array_int32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node11"><a xlink:href="../proc/torch_tensor_from_array_int32_5d_default_layout.html" xlink:title="torch_tensor_from_array_int32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-864 181.5,-864 181.5,-840 455.5,-840 455.5,-864"/>
<text text-anchor="middle" x="318.5" y="-849.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge40" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M75.05,-633.25C83.4,-669.32 110.67,-773.28 178,-822 186.96,-828.49 197.11,-833.34 207.73,-836.98"/>
<polygon fill="#000000" stroke="#000000" points="207.02,-840.42 217.61,-839.99 209.07,-833.72 207.02,-840.42"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node12" class="node">
<title>proc~torch_tensor_from_array_int64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node12"><a xlink:href="../proc/torch_tensor_from_array_int64_1d_default_layout.html" xlink:title="torch_tensor_from_array_int64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-822 181.5,-822 181.5,-798 455.5,-798 455.5,-822"/>
<text text-anchor="middle" x="318.5" y="-807.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge41" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M77.41,-633.31C89.34,-664.19 121.41,-743.03 178,-780 188.44,-786.82 200.24,-791.75 212.44,-795.36"/>
<polygon fill="#000000" stroke="#000000" points="211.74,-798.79 222.31,-797.98 213.54,-792.03 211.74,-798.79"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node13" class="node">
<title>proc~torch_tensor_from_array_int64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node13"><a xlink:href="../proc/torch_tensor_from_array_int64_2d_default_layout.html" xlink:title="torch_tensor_from_array_int64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-780 181.5,-780 181.5,-756 455.5,-756 455.5,-780"/>
<text text-anchor="middle" x="318.5" y="-765.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge42" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M81.29,-633.13C97.05,-657.87 131.86,-712.16 178,-738 191.06,-745.31 205.83,-750.33 220.76,-753.85"/>
<polygon fill="#000000" stroke="#000000" points="220.06,-757.28 230.57,-755.96 221.53,-750.44 220.06,-757.28"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node14" class="node">
<title>proc~torch_tensor_from_array_int64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node14"><a xlink:href="../proc/torch_tensor_from_array_int64_3d_default_layout.html" xlink:title="torch_tensor_from_array_int64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-738 181.5,-738 181.5,-714 455.5,-714 455.5,-738"/>
<text text-anchor="middle" x="318.5" y="-723.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge43" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M89.55,-633.17C109.11,-650.5 142.68,-680.66 178,-696 196.26,-703.93 216.98,-708.94 236.77,-712.38"/>
<polygon fill="#000000" stroke="#000000" points="236.26,-715.84 246.7,-713.99 237.39,-708.93 236.26,-715.84"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node15" class="node">
<title>proc~torch_tensor_from_array_int64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node15"><a xlink:href="../proc/torch_tensor_from_array_int64_4d_default_layout.html" xlink:title="torch_tensor_from_array_int64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-696 181.5,-696 181.5,-672 455.5,-672 455.5,-696"/>
<text text-anchor="middle" x="318.5" y="-681.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge44" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M116.88,-633.08C135.47,-640.17 157.45,-648.46 178,-654 205.24,-661.34 236.22,-666.33 262.05,-670.42"/>
<polygon fill="#000000" stroke="#000000" points="261.62,-673.89 272.04,-672 262.71,-666.98 261.62,-673.89"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node16" class="node">
<title>proc~torch_tensor_from_array_int64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node16"><a xlink:href="../proc/torch_tensor_from_array_int64_5d_default_layout.html" xlink:title="torch_tensor_from_array_int64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="455.5,-654 181.5,-654 181.5,-630 455.5,-630 455.5,-654"/>
<text text-anchor="middle" x="318.5" y="-639.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge45" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M142.02,-620.83C172.07,-622.69 207.33,-625.64 238.32,-628.87"/>
<polygon fill="#000000" stroke="#000000" points="238.34,-632.39 248.66,-629.98 239.09,-625.43 238.34,-632.39"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node17" class="node">
<title>proc~torch_tensor_from_array_int8_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node17"><a xlink:href="../proc/torch_tensor_from_array_int8_1d_default_layout.html" xlink:title="torch_tensor_from_array_int8_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-612 184.5,-612 184.5,-588 452.5,-588 452.5,-612"/>
<text text-anchor="middle" x="318.5" y="-597.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge46" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M140.71,-608.99C151.35,-607.82 162.67,-606.67 174.24,-605.59"/>
<polygon fill="#000000" stroke="#000000" points="174.82,-609.05 184.46,-604.65 174.19,-602.08 174.82,-609.05"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node18" class="node">
<title>proc~torch_tensor_from_array_int8_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node18"><a xlink:href="../proc/torch_tensor_from_array_int8_2d_default_layout.html" xlink:title="torch_tensor_from_array_int8_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-570 184.5,-570 184.5,-546 452.5,-546 452.5,-570"/>
<text text-anchor="middle" x="318.5" y="-555.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge47" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M85.06,-608.88C103.13,-597.48 137.19,-582.11 174.41,-571.15"/>
<polygon fill="#000000" stroke="#000000" points="175.77,-574.4 184.45,-568.32 173.87,-567.66 175.77,-574.4"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node19" class="node">
<title>proc~torch_tensor_from_array_int8_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node19"><a xlink:href="../proc/torch_tensor_from_array_int8_3d_default_layout.html" xlink:title="torch_tensor_from_array_int8_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-528 184.5,-528 184.5,-504 452.5,-504 452.5,-528"/>
<text text-anchor="middle" x="318.5" y="-513.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge48" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M78.58,-608.99C93.09,-589.18 129.73,-551.86 175.27,-529.58"/>
<polygon fill="#000000" stroke="#000000" points="176.88,-532.7 184.5,-525.34 173.95,-526.34 176.88,-532.7"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node20" class="node">
<title>proc~torch_tensor_from_array_int8_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node20"><a xlink:href="../proc/torch_tensor_from_array_int8_4d_default_layout.html" xlink:title="torch_tensor_from_array_int8_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-486 184.5,-486 184.5,-462 452.5,-462 452.5,-486"/>
<text text-anchor="middle" x="318.5" y="-471.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge49" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M76.14,-608.67C87.59,-582.12 122.11,-521.74 175.48,-487.94"/>
<polygon fill="#000000" stroke="#000000" points="177.4,-490.87 184.21,-482.75 173.82,-484.86 177.4,-490.87"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node21" class="node">
<title>proc~torch_tensor_from_array_int8_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node21"><a xlink:href="../proc/torch_tensor_from_array_int8_5d_default_layout.html" xlink:title="torch_tensor_from_array_int8_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="452.5,-444 184.5,-444 184.5,-420 452.5,-420 452.5,-444"/>
<text text-anchor="middle" x="318.5" y="-429.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_int8_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge50" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_int8_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M74.51,-608.9C82.99,-576.86 113.29,-491.91 176.07,-445.88"/>
<polygon fill="#000000" stroke="#000000" points="178.06,-448.76 184.3,-440.2 174.08,-443 178.06,-448.76"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node22" class="node">
<title>proc~torch_tensor_from_array_real32_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node22"><a xlink:href="../proc/torch_tensor_from_array_real32_1d_default_layout.html" xlink:title="torch_tensor_from_array_real32_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-402 178,-402 178,-378 459,-378 459,-402"/>
<text text-anchor="middle" x="318.5" y="-387.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge51" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.5,-608.77C79.35,-571.88 103.6,-463.68 169.35,-408.74"/>
<polygon fill="#000000" stroke="#000000" points="171.85,-411.22 177.58,-402.31 167.54,-405.71 171.85,-411.22"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node23" class="node">
<title>proc~torch_tensor_from_array_real32_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node23"><a xlink:href="../proc/torch_tensor_from_array_real32_2d_default_layout.html" xlink:title="torch_tensor_from_array_real32_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-360 178,-360 178,-336 459,-336 459,-360"/>
<text text-anchor="middle" x="318.5" y="-345.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge52" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.74,-608.85C76.15,-567.55 93.72,-434.35 169.5,-367.07"/>
<polygon fill="#000000" stroke="#000000" points="172.08,-369.47 177.51,-360.38 167.6,-364.1 172.08,-369.47"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node24" class="node">
<title>proc~torch_tensor_from_array_real32_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node24"><a xlink:href="../proc/torch_tensor_from_array_real32_3d_default_layout.html" xlink:title="torch_tensor_from_array_real32_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-318 178,-318 178,-294 459,-294 459,-318"/>
<text text-anchor="middle" x="318.5" y="-303.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge53" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.16,-608.7C73.37,-563 83.62,-404.57 169.98,-324.98"/>
<polygon fill="#000000" stroke="#000000" points="172.49,-327.44 177.73,-318.23 167.89,-322.16 172.49,-327.44"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node25" class="node">
<title>proc~torch_tensor_from_array_real32_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node25"><a xlink:href="../proc/torch_tensor_from_array_real32_4d_default_layout.html" xlink:title="torch_tensor_from_array_real32_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-276 178,-276 178,-252 459,-252 459,-276"/>
<text text-anchor="middle" x="318.5" y="-261.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge54" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M71.69,-608.8C70.79,-559.35 73.04,-375.3 170.22,-283.02"/>
<polygon fill="#000000" stroke="#000000" points="172.62,-285.56 177.69,-276.26 167.93,-280.37 172.62,-285.56"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node26" class="node">
<title>proc~torch_tensor_from_array_real32_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node26"><a xlink:href="../proc/torch_tensor_from_array_real32_5d_default_layout.html" xlink:title="torch_tensor_from_array_real32_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-234 178,-234 178,-210 459,-210 459,-234"/>
<text text-anchor="middle" x="318.5" y="-219.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real32_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge55" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real32_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.29,-608.84C80.36,-551.1 116.12,-307.93 170.57,-241.79"/>
<polygon fill="#000000" stroke="#000000" points="173.32,-243.97 177.66,-234.31 168.24,-239.16 173.32,-243.97"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node27" class="node">
<title>proc~torch_tensor_from_array_real64_1d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node27"><a xlink:href="../proc/torch_tensor_from_array_real64_1d_default_layout.html" xlink:title="torch_tensor_from_array_real64_1d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-192 178,-192 178,-168 459,-168 459,-192"/>
<text text-anchor="middle" x="318.5" y="-177.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_1d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge56" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_1d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M73.03,-608.63C79.03,-546.61 111.14,-272.78 170.62,-199.86"/>
<polygon fill="#000000" stroke="#000000" points="173.37,-202.05 177.62,-192.34 168.25,-197.27 173.37,-202.05"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node28" class="node">
<title>proc~torch_tensor_from_array_real64_2d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node28"><a xlink:href="../proc/torch_tensor_from_array_real64_2d_default_layout.html" xlink:title="torch_tensor_from_array_real64_2d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-150 178,-150 178,-126 459,-126 459,-150"/>
<text text-anchor="middle" x="318.5" y="-135.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_2d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge57" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_2d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.77,-608.99C77.64,-543.97 105.89,-237.49 170.78,-157.78"/>
<polygon fill="#000000" stroke="#000000" points="173.39,-160.11 177.59,-150.38 168.24,-155.36 173.39,-160.11"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node29" class="node">
<title>proc~torch_tensor_from_array_real64_3d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node29"><a xlink:href="../proc/torch_tensor_from_array_real64_3d_default_layout.html" xlink:title="torch_tensor_from_array_real64_3d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-108 178,-108 178,-84 459,-84 459,-108"/>
<text text-anchor="middle" x="318.5" y="-93.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_3d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge58" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_3d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.6,-608.58C76.55,-539.19 100.72,-202.72 170.65,-116.02"/>
<polygon fill="#000000" stroke="#000000" points="173.42,-118.17 177.56,-108.42 168.24,-113.46 173.42,-118.17"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node30" class="node">
<title>proc~torch_tensor_from_array_real64_4d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node30"><a xlink:href="../proc/torch_tensor_from_array_real64_4d_default_layout.html" xlink:title="torch_tensor_from_array_real64_4d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-66 178,-66 178,-42 459,-42 459,-66"/>
<text text-anchor="middle" x="318.5" y="-51.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_4d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge59" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_4d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.43,-608.73C75.41,-536.21 95.36,-167.29 170.79,-73.91"/>
<polygon fill="#000000" stroke="#000000" points="173.41,-76.22 177.52,-66.46 168.22,-71.53 173.41,-76.22"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_node31" class="node">
<title>proc~torch_tensor_from_array_real64_5d_default_layout</title>
<g id="a_interface~~torch_tensor_from_array~~CalledByGraph_node31"><a xlink:href="../proc/torch_tensor_from_array_real64_5d_default_layout.html" xlink:title="torch_tensor_from_array_real64_5d_default_layout">
<polygon fill="#d9534f" stroke="#d9534f" points="459,-24 178,-24 178,0 459,0 459,-24"/>
<text text-anchor="middle" x="318.5" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">torch_tensor_from_array_real64_5d_default_layout</text>
</a>
</g>
</g>
<!-- interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge60" class="edge">
<title>interface~torch_tensor_from_array&#45;&gt;proc~torch_tensor_from_array_real64_5d_default_layout</title>
<path fill="none" stroke="#000000" stroke-dasharray="5,2" d="M72.27,-608.97C74.35,-533.73 89.88,-131.59 171.01,-31.69"/>
<polygon fill="#000000" stroke="#000000" points="173.63,-34.01 177.74,-24.25 168.44,-29.31 173.63,-34.01"/>
</g>
<!-- proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge1" class="edge">
<title>proc~torch_tensor_from_array_int16_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.82,-1242.04C251.21,-1246.6 205.4,-1244.62 178,-1218 94,-1136.4 75.72,-741.3 72.57,-643.04"/>
<polygon fill="#000000" stroke="#000000" points="76.07,-642.93 72.27,-633.03 69.07,-643.13 76.07,-642.93"/>
</g>
<!-- proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge2" class="edge">
<title>proc~torch_tensor_from_array_int16_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M282.29,-1200.04C250.76,-1204.43 205.41,-1202.27 178,-1176 99.79,-1101.04 77.25,-738.03 72.87,-643.44"/>
<polygon fill="#000000" stroke="#000000" points="76.36,-643.11 72.43,-633.27 69.37,-643.42 76.36,-643.11"/>
</g>
<!-- proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge3" class="edge">
<title>proc~torch_tensor_from_array_int16_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M281.77,-1158.02C250.34,-1162.23 205.43,-1159.89 178,-1134 105.51,-1065.58 78.88,-734.03 73.22,-643.65"/>
<polygon fill="#000000" stroke="#000000" points="76.7,-643.19 72.6,-633.42 69.71,-643.61 76.7,-643.19"/>
</g>
<!-- proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge4" class="edge">
<title>proc~torch_tensor_from_array_int16_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M280.97,-1116.02C249.66,-1119.98 205.4,-1117.39 178,-1092 110.99,-1029.91 80.48,-727.99 73.56,-643.09"/>
<polygon fill="#000000" stroke="#000000" points="77.04,-642.71 72.77,-633.01 70.07,-643.25 77.04,-642.71"/>
</g>
<!-- proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge5" class="edge">
<title>proc~torch_tensor_from_array_int16_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M279.86,-1074.03C248.72,-1077.66 205.31,-1074.76 178,-1050 116.68,-994.4 82.44,-723.83 74.05,-643.41"/>
<polygon fill="#000000" stroke="#000000" points="77.52,-642.97 73.03,-633.37 70.55,-643.67 77.52,-642.97"/>
</g>
<!-- proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge6" class="edge">
<title>proc~torch_tensor_from_array_int32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M278.47,-1032.01C247.55,-1035.26 205.17,-1031.99 178,-1008 122.24,-958.76 84.5,-718.64 74.59,-643.4"/>
<polygon fill="#000000" stroke="#000000" points="78.02,-642.64 73.29,-633.16 71.08,-643.53 78.02,-642.64"/>
</g>
<!-- proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge7" class="edge">
<title>proc~torch_tensor_from_array_int32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M276.15,-990.02C245.6,-992.7 204.81,-988.92 178,-966 79.3,-881.62 71.4,-706.13 71.58,-643.53"/>
<polygon fill="#000000" stroke="#000000" points="75.09,-643.24 71.69,-633.2 68.09,-643.17 75.09,-643.24"/>
</g>
<!-- proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge8" class="edge">
<title>proc~torch_tensor_from_array_int32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.24,-948C242.35,-949.83 204.03,-945.36 178,-924 90.11,-851.89 75.08,-700.87 72.52,-643.48"/>
<polygon fill="#000000" stroke="#000000" points="76.01,-643.17 72.16,-633.3 69.02,-643.42 76.01,-643.17"/>
</g>
<!-- proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge9" class="edge">
<title>proc~torch_tensor_from_array_int32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-884.4C180.15,-883.63 179.06,-882.83 178,-882 100.69,-821.87 79.14,-694.94 73.69,-643.26"/>
<polygon fill="#000000" stroke="#000000" points="77.16,-642.78 72.74,-633.15 70.19,-643.44 77.16,-642.78"/>
</g>
<!-- proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge10" class="edge">
<title>proc~torch_tensor_from_array_int32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.33,-842.3C180.2,-841.56 179.09,-840.79 178,-840 111.21,-791.67 83.85,-688.99 75.26,-643.31"/>
<polygon fill="#000000" stroke="#000000" points="78.67,-642.49 73.5,-633.23 71.77,-643.69 78.67,-642.49"/>
</g>
<!-- proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge11" class="edge">
<title>proc~torch_tensor_from_array_int64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.43,-800.14C180.27,-799.45 179.13,-798.74 178,-798 121.26,-760.93 89.17,-681.77 77.32,-642.92"/>
<polygon fill="#000000" stroke="#000000" points="80.62,-641.75 74.51,-633.1 73.89,-643.67 80.62,-641.75"/>
</g>
<!-- proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge12" class="edge">
<title>proc~torch_tensor_from_array_int64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.24,-757.75C180.15,-757.18 179.07,-756.6 178,-756 130.96,-729.66 95.7,-673.75 80.39,-642.53"/>
<polygon fill="#000000" stroke="#000000" points="83.51,-640.94 76.14,-633.33 77.16,-643.88 83.51,-640.94"/>
</g>
<!-- proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge13" class="edge">
<title>proc~torch_tensor_from_array_int64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.4,-715.43C180.26,-714.96 179.12,-714.49 178,-714 139.62,-697.33 103.3,-663.15 84.78,-640.89"/>
<polygon fill="#000000" stroke="#000000" points="87.51,-638.71 78.58,-633.01 82.01,-643.03 87.51,-638.71"/>
</g>
<!-- proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge14" class="edge">
<title>proc~torch_tensor_from_array_int64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.21,-672.85C180.13,-672.57 179.06,-672.29 178,-672 148,-663.91 114.94,-649.95 93.85,-638.29"/>
<polygon fill="#000000" stroke="#000000" points="95.45,-635.17 85.06,-633.12 91.9,-641.2 95.45,-635.17"/>
</g>
<!-- proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge15" class="edge">
<title>proc~torch_tensor_from_array_int64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M181.2,-637.05C170.82,-636.11 160.58,-635.11 150.77,-634.09"/>
<polygon fill="#000000" stroke="#000000" points="151.03,-630.59 140.71,-633.01 150.28,-637.55 151.03,-630.59"/>
</g>
<!-- proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge16" class="edge">
<title>proc~torch_tensor_from_array_int8_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M248.66,-612.02C218.75,-615.31 183.5,-618.41 152.4,-620.5"/>
<polygon fill="#000000" stroke="#000000" points="151.78,-617.04 142.02,-621.17 152.23,-624.02 151.78,-617.04"/>
</g>
<!-- proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge17" class="edge">
<title>proc~torch_tensor_from_array_int8_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M272.04,-570C244.51,-574.39 208.86,-579.68 178,-588 160.83,-592.63 142.65,-599.19 126.29,-605.35"/>
<polygon fill="#000000" stroke="#000000" points="124.99,-602.1 116.88,-608.92 127.47,-608.65 124.99,-602.1"/>
</g>
<!-- proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge18" class="edge">
<title>proc~torch_tensor_from_array_int8_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M246.7,-528.01C224.05,-531.45 199.34,-536.73 178,-546 146.96,-559.48 117.27,-584.41 97.25,-602.02"/>
<polygon fill="#000000" stroke="#000000" points="94.72,-599.58 89.55,-608.83 99.36,-604.83 94.72,-599.58"/>
</g>
<!-- proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge19" class="edge">
<title>proc~torch_tensor_from_array_int8_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M230.57,-486.04C212.39,-489.58 193.92,-495.09 178,-504 136.72,-527.11 104.52,-573 86.9,-600.12"/>
<polygon fill="#000000" stroke="#000000" points="83.75,-598.56 81.29,-608.87 89.64,-602.34 83.75,-598.56"/>
</g>
<!-- proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge20" class="edge">
<title>proc~torch_tensor_from_array_int8_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M222.31,-444.02C206.64,-447.74 191.23,-453.36 178,-462 126.49,-495.65 95.3,-563.98 81.12,-599.27"/>
<polygon fill="#000000" stroke="#000000" points="77.82,-598.11 77.41,-608.69 84.33,-600.67 77.82,-598.11"/>
</g>
<!-- proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge21" class="edge">
<title>proc~torch_tensor_from_array_real32_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M217.61,-402.01C203.43,-405.85 189.71,-411.53 178,-420 116.06,-464.82 88.03,-556.39 77.43,-598.84"/>
<polygon fill="#000000" stroke="#000000" points="73.98,-598.21 75.05,-608.75 80.79,-599.85 73.98,-598.21"/>
</g>
<!-- proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge22" class="edge">
<title>proc~torch_tensor_from_array_real32_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M214.57,-360.02C201.36,-363.94 188.73,-369.66 178,-378 105.36,-434.5 81.95,-549.98 74.86,-598.77"/>
<polygon fill="#000000" stroke="#000000" points="71.36,-598.52 73.49,-608.9 78.3,-599.46 71.36,-598.52"/>
</g>
<!-- proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge23" class="edge">
<title>proc~torch_tensor_from_array_real32_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M212.39,-318.06C199.89,-322.04 188.04,-327.77 178,-336 94.59,-404.44 76.8,-543.95 73.02,-598.6"/>
<polygon fill="#000000" stroke="#000000" points="69.5,-598.73 72.4,-608.92 76.49,-599.15 69.5,-598.73"/>
</g>
<!-- proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge24" class="edge">
<title>proc~torch_tensor_from_array_real32_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M211.02,-276.03C198.96,-280.06 187.59,-285.8 178,-294 83.65,-374.65 72.28,-538.56 71.61,-598.58"/>
<polygon fill="#000000" stroke="#000000" points="68.11,-598.83 71.6,-608.84 75.11,-598.84 68.11,-598.83"/>
</g>
<!-- proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge25" class="edge">
<title>proc~torch_tensor_from_array_real32_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M209.72,-234.1C198.09,-238.15 187.18,-243.89 178,-252 124.05,-299.64 86.97,-525.95 75.65,-598.65"/>
<polygon fill="#000000" stroke="#000000" points="72.12,-598.53 74.05,-608.94 79.04,-599.6 72.12,-598.53"/>
</g>
<!-- proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge26" class="edge">
<title>proc~torch_tensor_from_array_real64_1d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.81,-192.11C197.49,-196.19 186.89,-201.94 178,-210 118.39,-264.04 84.38,-521.17 74.81,-598.88"/>
<polygon fill="#000000" stroke="#000000" points="71.32,-598.64 73.58,-608.99 78.26,-599.49 71.32,-598.64"/>
</g>
<!-- proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge27" class="edge">
<title>proc~torch_tensor_from_array_real64_2d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M208.3,-150.05C197.13,-154.16 186.71,-159.93 178,-168 112.79,-228.43 82.15,-515.96 74.17,-598.78"/>
<polygon fill="#000000" stroke="#000000" points="70.68,-598.58 73.22,-608.86 77.65,-599.24 70.68,-598.58"/>
</g>
<!-- proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge28" class="edge">
<title>proc~torch_tensor_from_array_real64_3d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.81,-108.02C196.8,-112.15 186.55,-117.93 178,-126 107.14,-192.88 80.1,-511.18 73.63,-598.78"/>
<polygon fill="#000000" stroke="#000000" points="70.13,-598.7 72.9,-608.93 77.11,-599.21 70.13,-598.7"/>
</g>
<!-- proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge29" class="edge">
<title>proc~torch_tensor_from_array_real64_4d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M207.34,-66.02C196.48,-70.16 186.4,-75.95 178,-84 101.55,-157.28 78.29,-505.84 73.19,-598.48"/>
<polygon fill="#000000" stroke="#000000" points="69.69,-598.52 72.65,-608.69 76.68,-598.9 69.69,-598.52"/>
</g>
<!-- proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array -->
<g id="interface~~torch_tensor_from_array~~CalledByGraph_edge30" class="edge">
<title>proc~torch_tensor_from_array_real64_5d_default_layout&#45;&gt;interface~torch_tensor_from_array</title>
<path fill="none" stroke="#000000" d="M206.89,-24.04C196.18,-28.2 186.26,-33.98 178,-42 95.79,-121.87 76.52,-502.05 72.79,-598.72"/>
<polygon fill="#000000" stroke="#000000" points="69.29,-598.71 72.42,-608.83 76.29,-598.97 69.29,-598.71"/>
</g>
</g>
</svg>
</div>          <div>
            <a type="button" class="graph-help" data-bs-toggle="modal" href="#CalledByGraph-help-text">Help</a>
          </div>
          <div class="modal fade" id="CalledByGraph-help-text" tabindex="-1" role="dialog">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h4 class="modal-title" id="-graph-help-label">Graph Key</h4>
                  <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
<p>Nodes of different colours represent the following: </p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: Graph Key Pages: 1 -->
<svg width="641pt" height="28pt"
 viewBox="0.00 0.00 641.00 27.51" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(0.86 0.86) rotate(0) translate(4 28)">
<title>Graph Key</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-28 741.5,-28 741.5,4 -4,4"/>
<!-- Subroutine -->
<g id="node1" class="node">
<title>Subroutine</title>
<polygon fill="#d9534f" stroke="#d9534f" points="70,-24 0,-24 0,0 70,0 70,-24"/>
<text text-anchor="middle" x="35" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Subroutine</text>
</g>
<!-- Function -->
<g id="node2" class="node">
<title>Function</title>
<polygon fill="#d94e8f" stroke="#d94e8f" points="146,-24 88,-24 88,0 146,0 146,-24"/>
<text text-anchor="middle" x="117" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Function</text>
</g>
<!-- Interface -->
<g id="node3" class="node">
<title>Interface</title>
<polygon fill="#a7506f" stroke="#a7506f" points="225.5,-24 164.5,-24 164.5,0 225.5,0 225.5,-24"/>
<text text-anchor="middle" x="195" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Interface</text>
</g>
<!-- Type Bound Procedure -->
<g id="node4" class="node">
<title>Type Bound Procedure</title>
<polygon fill="#a7506f" stroke="#a7506f" points="374,-24 244,-24 244,0 374,0 374,-24"/>
<text text-anchor="middle" x="309" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Type Bound Procedure</text>
</g>
<!-- Unknown Procedure Type -->
<g id="node5" class="node">
<title>Unknown Procedure Type</title>
<polygon fill="#777777" stroke="#777777" points="537.5,-24 392.5,-24 392.5,0 537.5,0 537.5,-24"/>
<text text-anchor="middle" x="465" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Unknown Procedure Type</text>
</g>
<!-- Program -->
<g id="node6" class="node">
<title>Program</title>
<polygon fill="#f0ad4e" stroke="#f0ad4e" points="614,-24 556,-24 556,0 614,0 614,-24"/>
<text text-anchor="middle" x="585" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50" fill="white">Program</text>
</g>
<!-- This Page&#39;s Entity -->
<g id="node7" class="node">
<title>This Page&#39;s Entity</title>
<polygon fill="none" stroke="black" points="737.5,-24 632.5,-24 632.5,0 737.5,0 737.5,-24"/>
<text text-anchor="middle" x="685" y="-9.6" font-family="Helvetica,sans-Serif" font-size="10.50">This Page&#39;s Entity</text>
</g>
</g>
</svg>

<p>Solid arrows point from a procedure to one which it calls. Dashed 
arrows point from an interface to procedures which implement that interface.
This could include the module procedures in a generic interface or the
implementation in a submodule of an interface in a parent module.
</p>
 </div>
            </div>
          </div>
        </div>
          </div>
        </div>
<br>


        <h2>Module Procedures</h2>
            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_1d.html'>torch_tensor_from_array_int8_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~5"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~2"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~6"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~6"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~7"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_2d.html'>torch_tensor_from_array_int8_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~6"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~2"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~3"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~7"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~7"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~8"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_3d.html'>torch_tensor_from_array_int8_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~7"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~3"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~4"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~8"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~8"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~9"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_4d.html'>torch_tensor_from_array_int8_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~8"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~4"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~5"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~9"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~9"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~10"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_5d.html'>torch_tensor_from_array_int8_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int8</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~9"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~5"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~6"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~10"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~10"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~11"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_1d.html'>torch_tensor_from_array_int16_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~10"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~6"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~7"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~11"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~11"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~12"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_2d.html'>torch_tensor_from_array_int16_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~11"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~7"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~8"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~12"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~12"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~13"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_3d.html'>torch_tensor_from_array_int16_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~12"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~8"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~9"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~13"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~13"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~14"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_4d.html'>torch_tensor_from_array_int16_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~13"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~9"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~10"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~14"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~14"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~15"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_5d.html'>torch_tensor_from_array_int16_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int16</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~14"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~10"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~11"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~15"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~15"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~16"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_1d.html'>torch_tensor_from_array_int32_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~15"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~11"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~12"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~16"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~16"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~17"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_2d.html'>torch_tensor_from_array_int32_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~16"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~12"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~13"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~17"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~17"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~18"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_3d.html'>torch_tensor_from_array_int32_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~17"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~13"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~14"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~18"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~18"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~19"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_4d.html'>torch_tensor_from_array_int32_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~18"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~14"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~15"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~19"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~19"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~20"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_5d.html'>torch_tensor_from_array_int32_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~19"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~15"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~16"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~20"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~20"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~21"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_1d.html'>torch_tensor_from_array_int64_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~20"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~16"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~17"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~21"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~21"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~22"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_2d.html'>torch_tensor_from_array_int64_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~21"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~17"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~18"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~22"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~22"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~23"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_3d.html'>torch_tensor_from_array_int64_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~22"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~18"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~19"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~23"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~23"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~24"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_4d.html'>torch_tensor_from_array_int64_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~23"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~19"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~20"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~24"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~24"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~25"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_5d.html'>torch_tensor_from_array_int64_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~24"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~20"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~21"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~25"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~25"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~26"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_1d.html'>torch_tensor_from_array_real32_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~25"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~21"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~22"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~26"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~26"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~27"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_2d.html'>torch_tensor_from_array_real32_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~26"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~22"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~23"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~27"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~27"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~28"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_3d.html'>torch_tensor_from_array_real32_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~27"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~23"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~24"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~28"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~28"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~29"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_4d.html'>torch_tensor_from_array_real32_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~28"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~24"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~25"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~29"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~29"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~30"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_5d.html'>torch_tensor_from_array_real32_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real32</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~29"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~25"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~26"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~30"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~30"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~31"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_1d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_1d.html'>torch_tensor_from_array_real64_1d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~30"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~26"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~27"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(1)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~31"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~31"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~32"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_2d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_2d.html'>torch_tensor_from_array_real64_2d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~31"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~27"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~28"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(2)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~32"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~32"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~33"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_3d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_3d.html'>torch_tensor_from_array_real64_3d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~32"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~28"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~29"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(3)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~33"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~33"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~34"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_4d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_4d.html'>torch_tensor_from_array_real64_4d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~33"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~29"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~30"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(4)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~34"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~34"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~35"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_5d"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_5d.html'>torch_tensor_from_array_real64_5d</a>(tensor, data_in, layout, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real64</code></p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~34"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~30"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-layout~31"></span>
              integer(kind=ftorch_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>layout</strong>(5)</td>
            <td>
<p>Control order of indices</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~35"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~35"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~36"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_1d_default_layout.html'>torch_tensor_from_array_int8_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~35"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~31"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~36"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~36"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~37"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_2d_default_layout.html'>torch_tensor_from_array_int8_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~36"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~32"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~37"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~37"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~38"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_3d_default_layout.html'>torch_tensor_from_array_int8_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~37"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~33"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~38"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~38"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~39"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_4d_default_layout.html'>torch_tensor_from_array_int8_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~38"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~34"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~39"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~39"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~40"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int8_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int8_5d_default_layout.html'>torch_tensor_from_array_int8_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int8</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~39"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~35"></span>
              integer(kind=int8),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~40"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~40"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~41"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_1d_default_layout.html'>torch_tensor_from_array_int16_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~40"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~36"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~41"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~41"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~42"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_2d_default_layout.html'>torch_tensor_from_array_int16_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~41"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~37"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~42"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~42"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~43"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_3d_default_layout.html'>torch_tensor_from_array_int16_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~42"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~38"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~43"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~43"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~44"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_4d_default_layout.html'>torch_tensor_from_array_int16_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~43"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~39"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~44"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~44"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~45"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int16_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int16_5d_default_layout.html'>torch_tensor_from_array_int16_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int16</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~44"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~40"></span>
              integer(kind=int16),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~45"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~45"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~46"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_1d_default_layout.html'>torch_tensor_from_array_int32_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~45"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~41"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~46"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~46"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~47"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_2d_default_layout.html'>torch_tensor_from_array_int32_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~46"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~42"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~47"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~47"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~48"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_3d_default_layout.html'>torch_tensor_from_array_int32_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~47"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~43"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~48"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~48"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~49"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_4d_default_layout.html'>torch_tensor_from_array_int32_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~48"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~44"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~49"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~49"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~50"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int32_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int32_5d_default_layout.html'>torch_tensor_from_array_int32_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~49"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~45"></span>
              integer(kind=int32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~50"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~50"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~51"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_1d_default_layout.html'>torch_tensor_from_array_int64_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~50"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~46"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~51"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~51"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~52"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_2d_default_layout.html'>torch_tensor_from_array_int64_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~51"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~47"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~52"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~52"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~53"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_3d_default_layout.html'>torch_tensor_from_array_int64_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~52"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~48"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~53"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~53"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~54"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_4d_default_layout.html'>torch_tensor_from_array_int64_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~53"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~49"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~54"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~54"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~55"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_int64_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_int64_5d_default_layout.html'>torch_tensor_from_array_int64_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>int64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~54"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~50"></span>
              integer(kind=int64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~55"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~55"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~56"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_1d_default_layout.html'>torch_tensor_from_array_real32_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~55"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~51"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~56"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~56"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~57"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_2d_default_layout.html'>torch_tensor_from_array_real32_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~56"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~52"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~57"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~57"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~58"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_3d_default_layout.html'>torch_tensor_from_array_real32_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~57"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~53"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~58"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~58"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~59"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_4d_default_layout.html'>torch_tensor_from_array_real32_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~58"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~54"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~59"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~59"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~60"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real32_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real32_5d_default_layout.html'>torch_tensor_from_array_real32_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real32</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~59"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~55"></span>
              real(kind=real32),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~60"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~60"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~61"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_1d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_1d_default_layout.html'>torch_tensor_from_array_real64_1d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 1 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~60"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~56"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~61"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~61"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~62"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_2d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_2d_default_layout.html'>torch_tensor_from_array_real64_2d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 2 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~61"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~57"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~62"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~62"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~63"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_3d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_3d_default_layout.html'>torch_tensor_from_array_real64_3d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 3 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~62"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~58"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~63"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~63"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~64"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_4d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_4d_default_layout.html'>torch_tensor_from_array_real64_4d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 4 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~63"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~59"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~64"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~64"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~65"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

            <div class="card">
    <div class="card-header codesum"><span class="anchor" id="proc-torch_tensor_from_array_real64_5d_default_layout"></span> <h3>public  subroutine <a href='../proc/torch_tensor_from_array_real64_5d_default_layout.html'>torch_tensor_from_array_real64_5d_default_layout</a>(tensor, data_in, device_type, device_index, requires_grad)  
</h3></div>
    <div class="card-body">
          
  <p>Return a Torch tensor pointing to data_in array of rank 5 containing data of type <code>real64</code> with default layout [1, 2, ..., n].</p>

  <h4>Arguments</h4>
      <table class="table table-striped varlist">
    <thead>
      <tr>
        <th scope="col">Type</th>
<th scope="col">Intent</th><th scope="col">Optional</th>        <th scope="col">Attributes</th>
        <th scope="col"></th>
        <th scope="col">Name</th>
        <th scope="col"></th>
    </thead>
    <tbody>
        <tr>
            <td>
              <span class="anchor" id="variable-tensor~64"></span>
              type(<a href='../type/torch_tensor.html'>torch_tensor</a>),
            </td>
<td>intent(out)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>tensor</strong></td>
            <td>
<p>Returned tensor</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-data_in~60"></span>
              real(kind=real64),
            </td>
<td>intent(in),</td>
              <td></td>            <td>
              target
            </td>
            <td>::</td>
            <td><strong>data_in</strong>(:,:,:,:,:)</td>
            <td>
<p>Input data that tensor will point at</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_type~65"></span>
              integer(kind=c_int),
            </td>
<td>intent(in)</td>
              <td></td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_type</strong></td>
            <td>
<p>Device type the tensor will live on (<code>torch_kCPU</code> or <code>torch_kCUDA</code>)</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-device_index~65"></span>
              integer,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>device_index</strong></td>
            <td>
<p>Device index to use for <code>torch_kCUDA</code> case</p>
            </td>
        </tr>
        <tr>
            <td>
              <span class="anchor" id="variable-requires_grad~66"></span>
              logical,
            </td>
<td>intent(in),</td>
              <td>optional</td>            <td>
              
            </td>
            <td>::</td>
            <td><strong>requires_grad</strong></td>
            <td>
<p>Whether gradients need to be computed for the created tensor</p>
            </td>
        </tr>
    </tbody>
  </table>


    </div>
  </div>

</div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2026 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>
  </body>
</html>