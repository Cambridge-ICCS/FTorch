<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>GPU Support &ndash; FTorch</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>GPU Support</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='index.html'>User Guide</a></li>
              <li class="breadcrumb-item active" aria-current="page">GPU Support</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="index.html">User Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="LICENSE.html">FTorch License</a>
              <a class="nav-link" href="cmake.html">Installation and Build Process</a>
              <a class="nav-link" href="developer.html">Developer Guide</a>
              <a class="nav-link" href="examples.html">Examples</a>
              <a class="nav-link active disabled" href="gpu.html">GPU Support</a>
              <a class="nav-link" href="testing.html">FTorch test suite</a>
              <a class="nav-link" href="transposing.html">When to transpose data</a>
              <a class="nav-link" href="troubleshooting.html">Troubleshooting</a>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <div class="toc">
<ul>
<li><a href="#gpu-support">GPU Support</a><ul>
<li><a href="#multi-gpu-runs">Multi-GPU runs</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="gpu-support">GPU Support</h2>
<p>In order to run a model on GPU, two main changes are required:</p>
<p>1) When saving your TorchScript model, ensure that it is on the GPU.
For example, when using
<a href="https://github.com/Cambridge-ICCS/FTorch/blob/main/utils/pt2ts.py"><code>pt2ts.py</code></a>,
this can be done by uncommenting the following lines:</p>
<div class="codehilite"><pre><span></span><code><span class="n">device_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">trained_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_type</span><span class="p">)</span>
<span class="n">trained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">trained_model_dummy_input_1</span> <span class="o">=</span> <span class="n">trained_model_dummy_input_1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_type</span><span class="p">)</span>
<span class="n">trained_model_dummy_input_2</span> <span class="o">=</span> <span class="n">trained_model_dummy_input_2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_type</span><span class="p">)</span>
</code></pre></div>

<blockquote>
<p>Note: <em>This code also moves the dummy input tensors to the GPU.
Whilst not necessary for saving the model, but the tensors must also be on the GPU
to test that the models runs.</em></p>
</blockquote>
<p>2) When calling <code>torch_tensor_from_array</code> in Fortran, the device type for the input
   tensor(s) should be set to <code>torch_kCUDA</code>, rather than <code>torch_kCPU</code>.
   This ensures that the inputs are on the same device type as the model.</p>
<blockquote>
<p>Note: <em>You do <strong>not</strong> need to change the device type for the output tensors as we
want them to be on the CPU for subsequent use in Fortran.</em></p>
</blockquote>
<h3 id="multi-gpu-runs">Multi-GPU runs</h3>
<p>In the case of having multiple GPU devices, as well as setting <code>torch_kCUDA</code> as the
device type for any input tensors and models, you should also specify their device index
as the GPU device to be targeted. This argument is optional and will default to device
index 0 if unset.</p>
<p>For example, the following code snippet sets up a Torch tensor with GPU device index 2:</p>
<div class="codehilite"><pre><span></span><code><span class="n">device_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span>
<span class="n">in_tensors</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCUDA</span><span class="p">,</span><span class="w">    </span><span class="p">&amp;</span>
<span class="w">                                       </span><span class="n">device_index</span><span class="o">=</span><span class="n">device_index</span><span class="p">)</span>
</code></pre></div>

<p>Whereas the following code snippet sets up a Torch tensor with (default) device index 0:</p>
<div class="codehilite"><pre><span></span><code><span class="n">in_tensors</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCUDA</span><span class="p">)</span>
</code></pre></div>

<p>See the
<a href="https://github.com/Cambridge-ICCS/FTorch/tree/main/examples/3_MultiGPU">MultiGPU example</a>
for a worked example of running with multiple GPUs.</p>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2024 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>