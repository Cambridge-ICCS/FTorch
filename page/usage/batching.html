<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="FTorch - A library for coupling (Py)Torch machine learning models to Fortran codes.Written in modern Fortran (2008) with source code available on GitHub it has been used in multiple scientific projects.The associated JOSS paper can read here.">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../../favicon.png">

    <title>Batching &ndash; FTorch</title>

    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <!-- Font Awesome -->
    <link href="../../css/fontawesome.min.css" rel="stylesheet">
    <link href="../../css/brands.min.css" rel="stylesheet">
    <link href="../../css/regular.min.css" rel="stylesheet">
    <link href="../../css/solid.min.css" rel="stylesheet">
    <link href="../../css/v4-font-face.min.css" rel="stylesheet">
    <link href="../../css/v4-shims.min.css" rel="stylesheet">
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } }
      });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async
            integrity="sha256-DViIOMYdwlM/axqoGDPeUyf0urLoHMN4QACBKyB58Uw=" crossorigin="anonymous"></script>
    <!-- Other scripts and stylesheets -->
    <link href="../../css/local.css" rel="stylesheet">
    <link href="../../css/pygments.css" rel="stylesheet">
      <link href="../../css/user.css" rel="stylesheet">
    <script src="../../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="../index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>Batching</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
              <li class="list-inline-item" id="author"><i class="fa fa-pencil"></i> Jack Atkinson</li>
              <li class="list-inline-item" id="date"><i class="fa fa-calendar-o"></i> Last Updated: January 2026</li>
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='../index.html'>User Guide</a></li>
                <li class="breadcrumb-item"><a href='index.html'>Usage</a></li>
              <li class="breadcrumb-item active" aria-current="page">Batching</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="../index.html">User Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="../installation/index.html">Installation</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../installation/general.html">Installation and Build</a>
              <a class="nav-link" href="../installation/systems.html">System-Specific Guidance</a>
              <a class="nav-link" href="../installation/gpu.html">GPU Support</a>
              <a class="nav-link" href="../installation/hpc.html">HPC Support</a>

                </nav>
              <a class="nav-link" href="index.html">Usage</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="generic_example.html">Generic Example</a>
              <a class="nav-link" href="worked_examples.html">Worked Examples</a>
              <a class="nav-link" href="tensor.html">Tensor API</a>
              <a class="nav-link" href="transposing.html">When to transpose data</a>
              <a class="nav-link active disabled" href="batching.html">Batching</a>
              <a class="nav-link" href="offline.html">Offline training</a>
              <a class="nav-link" href="online.html">Online training</a>
              <a class="nav-link" href="troubleshooting.html">Troubleshooting</a>

                </nav>
              <a class="nav-link" href="../community/index.html">Community</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../community/news_archive.html">News archive</a>
              <a class="nav-link" href="../community/presentations.html">Presentations</a>
              <a class="nav-link" href="../community/case_studies.html">FTorch Case Studies</a>
              <a class="nav-link" href="../community/changelog.html">FTorch Changelog</a>

                </nav>
              <a class="nav-link" href="../developer/index.html">Developer Guide</a>
                <nav class="nav nav-pills flex-column">
                                <a class="nav-link" href="../developer/developer.html">Developer Guide</a>
              <a class="nav-link" href="../developer/testing.html">FTorch test suite</a>

                </nav>
              <a class="nav-link" href="../LICENSE.html">FTorch License</a>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <h2 id="batching-in-ftorch">Batching in FTorch</h2>
<p>Batching in FTorch works much the same as it does in PyTorch;
if your model supports batched inference in Python, it will do so in
Fortran via FTorch with no special changes required.</p>
<p>To leverage batching simply add a leading batch dimension to your (Fortran) input
arrays, and FTorch will apply the model independently to each batch element,
preserving the batch structure in the output.</p>
<h3 id="example">Example</h3>
<p>See the <a href="worked_examples.html">Batching worked example</a>
for a complete demonstration.
This illustrates how to use a model trained on 1D vectors for batched and
higher-dimensional inference, both in Python and Fortran, and highlights common
pitfalls.</p>
<p>The following code snippet illustrates the process of using the same net for both
single and batched inference by adding batching dimensions to the front of the Fortran
arrays before casting to torch tensors:</p>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="k">use</span><span class="p">,</span><span class="w"> </span><span class="k">intrinsic</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">iso_fortran_env</span><span class="p">,</span><span class="w"> </span><span class="k">only</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">sp</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">real32</span>
<span class="w">  </span><span class="k">use </span><span class="n">ftorch</span><span class="p">,</span><span class="w"> </span><span class="k">only</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">torch_model</span><span class="p">,</span><span class="w"> </span><span class="n">torch_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">,</span><span class="w"> </span><span class="n">torch_delete</span><span class="p">,</span><span class="w"> </span><span class="p">&amp;</span>
<span class="w">                     </span><span class="n">torch_tensor_from_array</span><span class="p">,</span><span class="w"> </span><span class="n">torch_model_load</span><span class="p">,</span><span class="w"> </span><span class="n">torch_model_forward</span>

<span class="w">  </span><span class="c">! Single input and output</span>
<span class="w">  </span><span class="kt">real</span><span class="p">(</span><span class="n">sp</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span><span class="w"> </span><span class="k">target</span><span class="w">   </span><span class="kd">::</span><span class="w"> </span><span class="n">in_data_single</span><span class="p">,</span><span class="w"> </span><span class="n">out_data_single</span>
<span class="w">  </span><span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">in_tensors_single</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors_single</span>

<span class="w">  </span><span class="c">! Multidimensional batched input and output</span>
<span class="w">  </span><span class="kt">real</span><span class="p">(</span><span class="n">sp</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="w"> </span><span class="k">target</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">in_data_batch</span><span class="p">,</span><span class="w"> </span><span class="n">out_data_batch</span>
<span class="w">  </span><span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">   </span><span class="kd">::</span><span class="w"> </span><span class="n">in_tensors_batch</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors_batch</span>

<span class="w">  </span><span class="c">! Load a single torch model to be used for both regular and batched inference</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_model_load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;path/to/saved/model.pt&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>

<span class="w">  </span><span class="c">! Regular inference on a single input</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">in_tensors_single</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">in_data_single</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">out_tensors_single</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">out_data_single</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>

<span class="w">  </span><span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors_single</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors_single</span><span class="p">)</span>

<span class="w">  </span><span class="k">call </span><span class="n">torch_delete</span><span class="p">(</span><span class="n">in_tensors_single</span><span class="p">)</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_delete</span><span class="p">(</span><span class="n">out_tensors_single</span><span class="p">)</span>

<span class="w">  </span><span class="c">! Multidimensional batched inference</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">in_tensors_batch</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">in_data_batch</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">out_tensors_batch</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">out_data_batch</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>

<span class="w">  </span><span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors_batch</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors_batch</span><span class="p">)</span>

<span class="w">  </span><span class="k">call </span><span class="n">torch_delete</span><span class="p">(</span><span class="n">in_tensors_batch</span><span class="p">)</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_delete</span><span class="p">(</span><span class="n">out_tensors_batch</span><span class="p">)</span>

<span class="w">  </span><span class="c">! Delete model after using for both single and batched inference</span>
<span class="w">  </span><span class="k">call </span><span class="n">torch_delete</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>

<p>Batching for nets with multiple inputs and outputs is also supported, provided the
batching dimensions are the same for all inputs (and outputs) and the net architecture
is designed in a way that does not interfere with batching (see below).
This can be explored as an extension to the
<a href="worked_examples.html">Multiple input/output worked example</a>.</p>
<h3 id="key-points">Key Points</h3>
<p>There are a few key points to be aware of when extending your code to make use of
batching. These are also true in PyTorch, but we repeat them here for reinforcement:</p>
<ul>
<li><strong>Shape matters:</strong> The last dimension of your input array <em>must</em> match
  the modelâ€™s expected feature size. Any number of leading batch
  (or time) dimensions are supported.</li>
<li><strong>Multiple inputs:</strong> If your model takes multiple input tensors, all
  must have the same batch dimensions.</li>
<li><strong>Output:</strong> The output shape must mirror the input batch structure.
  This is also true in PyTorch, but in Fortran we need to specify the dimension of our
  output arrays in advance.</li>
<li><strong>Error handling:</strong> Shape mismatches or incorrect batch placement
  will result in matrix multiplication runtime errors, as in PyTorch.</li>
<li><strong>Architectural gotchas:</strong> Avoid models that flatten, permute, or concatenate inputs
  in a way that destroys the batch dimension, or that mix batch and feature dimensions
  incorrectly, just as with PyTorch. If in doubt test batching in PyTorch before trying
  it with FTorch.</li>
</ul>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2026 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>
  </body>
</html>