<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>When to transpose data &ndash; FTorch</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>When to transpose data</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='index.html'>User Guide</a></li>
              <li class="breadcrumb-item active" aria-current="page">When to transpose data</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="index.html">User Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="LICENSE.html">FTorch License</a>
              <a class="nav-link" href="cmake.html">Installation and Build Process</a>
              <a class="nav-link" href="developer.html">Developer Guide</a>
              <a class="nav-link" href="examples.html">Examples</a>
              <a class="nav-link" href="gpu.html">GPU Support</a>
              <a class="nav-link" href="testing.html">FTorch test suite</a>
              <a class="nav-link active disabled" href="transposing.html">When to transpose data</a>
              <a class="nav-link" href="troubleshooting.html">Troubleshooting</a>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <p>Transposition of data between Fortran and C can lead to a lot of unneccessary confusion.
The FTorch library looks after this for you with the
<a href="../interface/torch_tensor_from_array.html"><code>torch_tensor_from_array()</code></a> function which
allows you to index a tensor in Torch in <strong>exactly the same way</strong> as you would in Fortran.</p>
<p>If you wish to do something different to this then there are more complex functions
available and we describe here how and when to use them.</p>
<div class="toc">
<ul>
<li><a href="#introduction-row-vs-column-major">Introduction - row- vs. column-major</a></li>
<li><a href="#why-does-this-matter">Why does this matter?</a></li>
<li><a href="#what-can-we-do">What can we do?</a><ul>
<li><a href="#1-transpose-before-passing">1) Transpose before passing</a></li>
<li><a href="#2-design-nets-to-use-transpose">2) Design nets to use transpose</a></li>
<li><a href="#3-use-the-layout-argument-in-torch_tensor_from_array">3) Use the layout argument in torch_tensor_from_array</a></li>
</ul>
</li>
<li><a href="#advanced-use-with-torch_tensor_from_blob">Advanced use with torch_tensor_from_blob</a></li>
</ul>
</div>
<h2 id="introduction-row-vs-column-major">Introduction - row- vs. column-major</h2>
<p>Astute users will note that Fortran is a
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major</a>
language whilst C, C++, and Python are 
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">row-major</a>.</p>
<p>This means that the matrix/tensor in Fortran
<script type="math/tex; mode=display">
\begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}
=
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
</script>
will appear in
<a href="https://en.wikipedia.org/wiki/Memory_management_(operating_systems)">contiguous memory</a>
on the computer as 
<script type="math/tex; mode=display">
\begin{pmatrix}
a_{11} & a_{21} & a_{12} & a_{22}
\end{pmatrix}
=
\begin{pmatrix}
a & c & b & d
\end{pmatrix}
</script>
with the order of elements decided by moving down the columns before progressing in the
row dimension.<br>
In contrast, the same matrix/tensor defined in a row-major language will appear in
contiguous memory as
<script type="math/tex; mode=display">
\begin{pmatrix}
a_{11} & a_{12} & a_{21} & a_{22}
\end{pmatrix}
=
\begin{pmatrix}
a & b & c & d
\end{pmatrix}
</script>
reading along each row before progressing down the column dimension.</p>
<h2 id="why-does-this-matter">Why does this matter?</h2>
<p>This matters for FTorch because a key feature is no-copy memory transfer between Fortran
and Torch.
To do this the Fortran data that will be used in Torch is stored in memory and a
<a href="https://en.wikipedia.org/wiki/Pointer_(computer_programming)">pointer</a> to the first
element, <script type="math/tex">a</script> provided to Torch.</p>
<p>Now, if Torch were to take this block of memory and interpret it as as a 2x2 matrix it
would be read in as
<script type="math/tex; mode=display">
\begin{pmatrix}
a & c \\
b & d
\end{pmatrix}
</script>
which is the <a href="https://en.wikipedia.org/wiki/Transpose">transpose</a> of the
matrix we had in Fortran; likely not what we were expecting!</p>
<p>This means we need to be careful when passing data to make sure that what we read in
to our Torch net is correct as we expect.</p>
<h2 id="what-can-we-do">What can we do?</h2>
<p>There are a few approaches we can take to address this.<br>
The first two of these are listed for conceptual purposes, whilst in practice we
advise handling this using the <code>torch_tensor_from_array</code> function described in 
<a href="#3-use-the-layout-argument-in-torch_tensor_from_array">3) below</a>.</p>
<h4 id="1-transpose-before-passing">1) Transpose before passing</h4>
<p>As seen from the above example, writing out from Fortran and reading directly in to
Torch results in us recieving the transpose.</p>
<p>Therefore we could transpose out Fortran data immediately before passing it to Torch.
As a result we will read in to Torch indexed the same as in Fortran pre-transposition.</p>
<p>For arrays of dimension 2 this can be done using the intrinsic
<a href="https://gcc.gnu.org/onlinedocs/gcc-12.1.0/gfortran/TRANSPOSE.html"><code>transpose()</code></a>
function.</p>
<p>For larger arrays we are required to use the
<a href="https://gcc.gnu.org/onlinedocs/gfortran/RESHAPE.html">'reshape()'</a> intrinsic to swap
the order of the indices.<br>
For example, if we had a 3x4x5 matrix <script type="math/tex">A</script> we would need to call</p>
<div class="codehilite"><pre><span></span><code>A_to_torch = reshape(A, shape=[5, 4, 3], order=[3, 2, 1])
</code></pre></div>

<p>which could then be read by Torch as a 3x4x5 tensor.</p>
<p>We would, of course, need to remember to transpose/reshape any output of the model
as required.</p>
<p>However, the transposition process involves creating a copy of the Fortran data.
For large matrices/tensors this can become expensive.
It would be better if we can pass data without having to transpose beforehand.</p>
<h4 id="2-design-nets-to-use-transpose">2) Design nets to use transpose</h4>
<p>Alternatively we could design our net to use
<script type="math/tex; mode=display">
\begin{pmatrix}
a & c \\
b & d
\end{pmatrix}
</script>
as its input tensor meaning we can simply write from Fortran and read to Torch.</p>
<p>However, this requires foresight and may not be intuitive - we would like to be indexing
data in the same way in both Fortran and Torch.
Not doing so could leave us open to introducing bugs.</p>
<h4 id="3-use-the-layout-argument-in-torch_tensor_from_array">3) Use the <code>layout</code> argument in <code>torch_tensor_from_array</code></h4>
<p>By far the easiest way to deal with the issue is not to worry about it at all!</p>
<p>As described at the top of this page, by using the
<a href="../interface/torch_tensor_from_array.html">torch_tensor_from_array</a> function
we can make use of the <code>layout</code> argument.
This allows us to take data from Fortran and send it to Torch to be indexed in exactly
the same way by using strided access based on the shape of the array.</p>
<p>It takes the form of an array specifying which order to read the indices in.
i.e. <code>[1, 2]</code> will read <code>i</code> then <code>j</code>.
By passing <code>layout = [1, 2]</code> the data will be read into the correct indices by
Torch.</p>
<p>This is achieved by wrapping the <code>torch_tensor_from_blob</code> function to automatically
generate strides assuming that a straightforward conversion between
row- and column-major is what should happen.</p>
<p>i.e. if the Fortran array <code>A</code>
<script type="math/tex; mode=display">
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
</script>
is passed as <code>torch_tensor_from_array(A, [1, 2], torch_device)</code>
the resulting Tensor will be read by Torch as 
<script type="math/tex; mode=display">
\begin{pmatrix}
a & b \\
c & d
\end{pmatrix}
</script>
</p>
<blockquote>
<p>Note: <em>If, for some reason, we did want a different, transposed layout in Torch we
could use <code>torch_tensor_from_array(A, [2, 1], torch_device)</code> to get:</em>
<script type="math/tex; mode=display">
\begin{pmatrix}
a & c \\
b & d
\end{pmatrix}
</script>
</p>
</blockquote>
<h2 id="advanced-use-with-torch_tensor_from_blob">Advanced use with <code>torch_tensor_from_blob</code></h2>
<p>For more advanced options for manipulating and controlling data access when passing
between Fortran and Torch see the more powerful but more complex
<a href="../proc/torch_tensor_from_blob.html">torch_tensor_from_blob function</a></p>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2024 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>