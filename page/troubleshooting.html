<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>Troubleshooting &ndash; FTorch</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>Troubleshooting</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='index.html'>User Guide</a></li>
              <li class="breadcrumb-item active" aria-current="page">Troubleshooting</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="index.html">User Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="LICENSE.html">FTorch License</a>
              <a class="nav-link" href="cmake.html">Installation and Build Process</a>
              <a class="nav-link" href="developer.html">Developer Guide</a>
              <a class="nav-link" href="examples.html">Examples</a>
              <a class="nav-link" href="gpu.html">GPU Support</a>
              <a class="nav-link" href="testing.html">FTorch test suite</a>
              <a class="nav-link" href="transposing.html">When to transpose data</a>
              <a class="nav-link active disabled" href="troubleshooting.html">Troubleshooting</a>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <p>If you are experiencing problems building or using FTorch please see below for guidance on common problems.</p>
<div class="toc">
<ul>
<li><a href="#windows">Windows</a><ul>
<li><a href="#visual-studio">Visual Studio</a></li>
<li><a href="#mingw">MinGW</a></li>
</ul>
</li>
<li><a href="#apple-silicon">Apple Silicon</a></li>
<li><a href="#faq">FAQ</a><ul>
<li><a href="#why-are-inputs-to-torch-models-an-array">Why are inputs to torch models an array?</a></li>
<li><a href="#do-i-need-to-set-torchno_grad-or-torcheval-somewhere-like-in-pytorch">Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch?</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="windows">Windows</h2>
<p>If possible we recommend using the <a href="https://learn.microsoft.com/en-us/windows/wsl/">Windows Subsystem for Linux</a> (WSL) to build the library.
In this case the build process is the same as for a Linux environment.</p>
<p>If you need to build in native Windows please read the following information:</p>
<h3 id="visual-studio">Visual Studio</h3>
<p>It is possible to build using Visual Studio and the Intel Fortran Compiler<br>
In this case you must install </p>
<ul>
<li><a href="https://visualstudio.microsoft.com/">Visual Studio</a></li>
<li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html">Intel OneAPI Base and HPC toolkit</a> (ensure that the Intel Fortran compiler and VS integration is selected).</li>
</ul>
<p>You will then need to load the intel Fortran compilers using <code>setvars.bat</code>
which is found in the Intel compiler install directory (see the 
<a href="https://www.intel.com/content/www/us/en/docs/oneapi/programming-guide/2023-2/use-the-setvars-script-with-windows.html">intel docs</a>)
for more details.<br>
From CMD this can be done with:</p>
<div class="codehilite"><pre><span></span><code><span class="s2">&quot;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&quot;</span>
</code></pre></div>

<p>Finally you will need to add <code>-G "NMake Makefiles"</code> to the <code>cmake</code> command in the
<a href="cmake.html">regular install instructions</a>.<br>
So the basic command to build from CMD becomes:</p>
<div class="codehilite"><pre><span></span><code><span class="n">cmake</span><span class="w"> </span><span class="o">-</span><span class="n">G</span><span class="w"> </span><span class="s2">&quot;NMake Makefiles&quot;</span><span class="w"> </span><span class="o">-</span><span class="n">DCMAKE_PREFIX_PATH</span><span class="o">=</span><span class="s2">&quot;C:\Users\melt\Downloads\libtorch-win-shared-with-deps-2.1.0+cpu\libtorch&quot;</span><span class="w"> </span><span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span><span class="w"> </span><span class="o">..</span>
<span class="n">cmake</span><span class="w"> </span><span class="o">--</span><span class="n">build</span><span class="w"> </span><span class="o">.</span>
<span class="n">cmake</span><span class="w"> </span><span class="o">--</span><span class="n">install</span><span class="w"> </span><span class="o">.</span>
</code></pre></div>

<p>If using powershell the setvars and build commands become:</p>
<div class="codehilite"><pre><span></span><code><span class="n">cmd</span><span class="w"> </span><span class="o">/</span><span class="n">k</span><span class="w"> </span><span class="s1">&#39;&quot;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&quot; &amp;&amp; powershell&#39;</span>
<span class="n">cmake</span><span class="w"> </span><span class="o">-</span><span class="n">G</span><span class="w"> </span><span class="s2">&quot;NMake Makefiles&quot;</span><span class="w"> </span><span class="o">-</span><span class="n">DCMAKE_PREFIX_PATH</span><span class="o">=</span><span class="s2">&quot;C:\Users\melt\Downloads\libtorch-win-shared-with-deps-2.1.0+cpu\libtorch&quot;</span><span class="w"> </span><span class="o">-</span><span class="n">DCMAKE_BUILD_TYPE</span><span class="o">=</span><span class="n">Release</span><span class="w"> </span><span class="o">..</span>
<span class="n">cmake</span><span class="w"> </span><span class="o">--</span><span class="n">build</span><span class="w"> </span><span class="o">.</span>
<span class="n">cmake</span><span class="w"> </span><span class="o">--</span><span class="n">install</span><span class="w"> </span><span class="o">.</span>
</code></pre></div>

<h3 id="mingw">MinGW</h3>
<p>It may be tempting to build on Windows using MinGW.
However, <a href="https://github.com/pytorch/pytorch/issues/15099">libtorch does not currently support MinGW</a>.
Instead please build using Visual Studio and the intel Fortran compiler (ifort) as
detailed in the project README.</p>
<h2 id="apple-silicon">Apple Silicon</h2>
<p>At the time of writing, libtorch is currently only officially available for x86
architectures (according to <a href="https://pytorch.org/">pytorch.org</a>).
However, the version of PyTorch provided by pip install provides an ARM binary
for libtorch which works on Apple Silicon.
Therefore you should <code>pip install torch</code> in this situation and follow the guidance
on locating Torch within a virtual environment (venv) for CMake.</p>
<h2 id="faq">FAQ</h2>
<h3 id="why-are-inputs-to-torch-models-an-array">Why are inputs to torch models an array?</h3>
<p>The reason input and output tensors to <a href="../proc/torch_module_forward.html">torch_module_forward</a> are
contained in arrays is because it is possible to pass multiple input tensors to
the <code>forward()</code> method of a torch net, and it is possible for the net to return
multiple output arrays.<br>
The nature of Fortran means that it is not possible to set an arbitrary number
of inputs to the <code>torch_module_forward</code> subroutine, so instead we use a single
array of input tensors which <em>can</em> have an arbitrary length. Similarly, a single
array of output tensors is used.</p>
<p>Note that this does not refer to batching data.
This should be done in the same way as in Torch; by extending the dimensionality of
the input tensors.</p>
<h3 id="do-i-need-to-set-torchno_grad-or-torcheval-somewhere-like-in-pytorch">Do I need to set torch.no_grad() or torch.eval() somewhere like in PyTorch?</h3>
<p>By default we disable gradient calculations for tensors and models and place models in
evaluation mode for efficiency.
These can be adjusted using the <code>requires_grad</code> and <code>is_training</code> optional arguments
in the Fortran interface. See the <a href="lists/procedures.html">API procedures documentation</a>
for details.</p>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2024 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>