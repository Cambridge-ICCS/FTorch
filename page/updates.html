<!-- -*- mode: jinja2 -*- -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="A library for coupling (Py)Torch machine learning models to Fortran">
    <meta name="author" content="ICCS Cambridge" >
    <link rel="icon" href="../favicon.png">

    <title>Recent API Changes &ndash; FTorch</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
      <link  href="../tipuesearch/tipuesearch.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>
  </head>

  <body>

    <!-- Fixed navbar -->
    <div class="container-fluid mb-sm-4 mb-xl-2">
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container">
          <a class="navbar-brand" href="../index.html">FTorch </a>
          <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar"
                  aria-expanded="false" aria-controls="navbar" aria-label="Toggle navigation">
                  <span class="navbar-toggler-icon">
          </button>

          <div id="navbar" class="navbar-collapse collapse">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link" href="index.html">User Guide</a></li>
                  <li class="nav-item">
                    <a class="nav-link" href="../lists/files.html">Source Files</a>
                  </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/modules.html">Modules</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/procedures.html">Procedures</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="../lists/types.html">Derived Types</a>
                </li>
            </ul>
              <div class="d-flex align-items-end flex-grow-1">
                <form action="../search.html" role="search" class="ms-auto">
                  <input type="text" class="form-control" aria-label="Search" placeholder="Search" name="q" id="tipue_search_input" autocomplete="off" required>
                </form>
              </div>
          </div><!--/.nav-collapse -->
        </div>
      </nav>
    </div>

    <div class="container">
  <div class="row">
    <h1>Recent API Changes</h1>
    <div class="container p-2 mb-4 bg-light border rounded-3">
      <div class="row align-items-center justify-content-between">
        <div class="col">
          <ul class="list-inline" style="margin-bottom:0px; display:inline">
          </ul>
        </div>
        <div class="col">
          <nav aria-label="breadcrumb">
            <ol class="breadcrumb justify-content-end mb-0">
                <li class="breadcrumb-item"><a href='index.html'>User Guide</a></li>
              <li class="breadcrumb-item active" aria-current="page">Recent API Changes</li>
            </ol>
          </nav>
        </div>
      </div>
    </div>
  </div>

  <div class="row">
      <div class="col-3">
        <div class="card card-body bg-light" id="sidebar-toc">
          <ul class="nav flex-column align-items">
            <li class="nav-item">
              <a class="nav-link" href="index.html">User Guide</a>
            </li>
          </ul>
          <hr>
          <nav class="nav nav-pills flex-column">
              <a class="nav-link" href="LICENSE.html">FTorch License</a>
              <a class="nav-link" href="cmake.html">Installation and Build Process</a>
              <a class="nav-link" href="developer.html">Developer Guide</a>
              <a class="nav-link" href="examples.html">Examples</a>
              <a class="nav-link" href="gpu.html">GPU Support</a>
              <a class="nav-link" href="testing.html">FTorch test suite</a>
              <a class="nav-link" href="transposing.html">When to transpose data</a>
              <a class="nav-link" href="troubleshooting.html">Troubleshooting</a>
              <a class="nav-link active disabled" href="updates.html">Recent API Changes</a>
          </nav>
        </div>
      </div>

    <div class="col-9" id='text'>
      <div class="toc">
<ul>
<li><a href="#why">Why?</a></li>
<li><a href="#changes-and-how-to-update-your-code">Changes and how to update your code</a><ul>
<li><a href="#torch_tensors-are-created-using-a-subroutine-call-not-a-function">torch_tensors are created using a subroutine call, not a function</a></li>
<li><a href="#module-becomes-model-and-loading-becomes-a-subroutine-call-not-a-function">module becomes model and loading becomes a subroutine call, not a function</a></li>
<li><a href="#n_inputs-is-no-longer-required">n_inputs is no longer required</a></li>
<li><a href="#outputs-now-need-to-be-an-array-of-torch_tensors">Outputs now need to be an array of torch_tensors</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="why">Why?</h2>
<p>Recently we made a number of breaking changes to the FTorch API.</p>
<p>We realise that this forms an inconvenience to those of you who are actively
using FTorch and is not something we did lightly.
These changes were neccessary to improve functionality and we have made them in one go
as we move towards a stable API and first release in the very near future.
Once the first release is set then the API becomes standardised then changes like this
will be avoided. We hope that this is the last time we have such a shift.</p>
<p>The changes allow us to implement two new features:</p>
<ol>
<li>Multiple output tensors
   Previously you could pass an array of several input tensors to a Torch model, but
   only recieve a single output tensor back. Now you can use models that return several
   output tensors by passing an array of output tensors instead.</li>
<li>Preparation for autograd functionality
   We hope to make it easier to access the autograd features of PyTorch from within Fortran.
   To do this we needed to change how data was assigned from a Fortran array to a Torch tensor.
   This is now done via a subroutine call rather than a function.</li>
</ol>
<p><br></p>
<h2 id="changes-and-how-to-update-your-code">Changes and how to update your code</h2>
<p><br></p>
<h4 id="torch_tensors-are-created-using-a-subroutine-call-not-a-function"><code>torch_tensor</code>s are created using a subroutine call, not a function</h4>
<p>Previously you would have created a Torch tensor and assigned some fortran data to it as follows:</p>
<div class="codehilite"><pre><span></span><code><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span><span class="w"> </span><span class="k">target</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">fortran_data</span>
<span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">my_tensor</span>
<span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">my_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">fortran_data</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>
</code></pre></div>

<p><br>
Now a call is made to a subroutine with the tensor as the first argument:</p>
<div class="codehilite"><pre><span></span><code><span class="kt">real</span><span class="p">,</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span><span class="w"> </span><span class="k">target</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">fortran_data</span>
<span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">my_tensor</span>
<span class="kt">integer</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">call </span><span class="n">torch_tensor_from_array</span><span class="p">(</span><span class="n">my_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">fortran_data</span><span class="p">,</span><span class="w"> </span><span class="n">tensor_layout</span><span class="p">,</span><span class="w"> </span><span class="n">torch_kCPU</span><span class="p">)</span>
</code></pre></div>

<p><br></p>
<h4 id="module-becomes-model-and-loading-becomes-a-subroutine-call-not-a-function"><code>module</code> becomes <code>model</code> and loading becomes a subroutine call, not a function</h4>
<p>Previously a neural net was referred to as a '<code>module</code>' and loaded using appropriately
named functions and types.</p>
<div class="codehilite"><pre><span></span><code><span class="k">type</span><span class="p">(</span><span class="n">torch_module</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">model</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch_module_load</span><span class="p">(</span><span class="n">args</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">call </span><span class="n">torch_module_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">)</span>
</code></pre></div>

<p><br>
Following user feedback we now refer to a neural net and its associated types and calls
as a '<code>model</code>'.
The process of loading a net is also now a subroutine call for consistency with the
tensor creation operations:</p>
<div class="codehilite"><pre><span></span><code><span class="k">type</span><span class="p">(</span><span class="n">torch_model</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">model</span>
<span class="k">call </span><span class="n">torch_model_load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;path_to_saved_net.pt&#39;</span><span class="p">)</span>
<span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">)</span>
</code></pre></div>

<p><br></p>
<h4 id="n_inputs-is-no-longer-required"><code>n_inputs</code> is no longer required</h4>
<p>Previously when you called the forward method on a net you had to specify the number of tensors
in the array of inputs:</p>
<div class="codehilite"><pre><span></span><code><span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">n_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">)</span>
</code></pre></div>

<p><br>
Now all that is supplied to the forward call is the model, and the arrays of input and
output tensors. No need for <code>n_inputs</code> (or <code>n_outputs</code>)!</p>
<div class="codehilite"><pre><span></span><code><span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">in_tensors</span><span class="p">,</span><span class="w"> </span><span class="n">out_tensors</span><span class="p">)</span>
</code></pre></div>

<p><br></p>
<h4 id="outputs-now-need-to-be-an-array-of-torch_tensors">Outputs now need to be an array of <code>torch_tensor</code>s</h4>
<p>Previously you passed an array of <code>torch_tensor</code> types as inputs, and a single <code>torch_tensor</code>
to the forward method:</p>
<div class="codehilite"><pre><span></span><code><span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">input_tensor_array</span>
<span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">output_tensor</span>
<span class="p">...</span>
<span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">input_tensor_array</span><span class="p">,</span><span class="w"> </span><span class="n">n_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">output_tensor</span><span class="p">)</span>
</code></pre></div>

<p><br>
Now both the inputs and the outputs need to be an array of <code>torch_tensor</code> types:</p>
<div class="codehilite"><pre><span></span><code><span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">)</span><span class="w">  </span><span class="kd">::</span><span class="w"> </span><span class="n">input_tensor_array</span>
<span class="k">type</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">),</span><span class="w"> </span><span class="k">dimension</span><span class="p">(</span><span class="n">n_outputs</span><span class="p">)</span><span class="w"> </span><span class="kd">::</span><span class="w"> </span><span class="n">output_tensor_array</span>
<span class="p">...</span>
<span class="k">call </span><span class="n">torch_model_forward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">input_tensor_array</span><span class="p">,</span><span class="w"> </span><span class="n">output_tensor_array</span><span class="p">)</span>
</code></pre></div>
    </div>
  </div>
      <hr>
    </div> <!-- /container -->
    <footer>
      <div class="container">
        <div class="row justify-content-between">
          <div class="col">
            <p>
              FTorch
 was developed by ICCS Cambridge<br>              &copy; 2024 <a rel="license" href="https://opensource.org/licenses/MIT">MIT</a>
</p>
          </div>
          <div class="col">
            <p class="text-end">
              Documentation generated by
              <a href="https://github.com/Fortran-FOSS-Programmers/ford">FORD</a>
            </p>
          </div>
        </div>
        <br>
      </div> <!-- /container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>    

    <!-- MathJax JavaScript
             ================================================== -->
             <!-- Placed at the end of the document so the pages load faster -->
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({
          TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
          jax: ['input/TeX','input/MathML','output/HTML-CSS'],
          extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
          });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

          <script src="../tipuesearch/tipuesearch_content.js"></script>
          <script src="../tipuesearch/tipuesearch_set.js"></script>
          <script src="../tipuesearch/tipuesearch.js"></script>

  </body>
</html>